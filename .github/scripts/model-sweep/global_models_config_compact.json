{
  "generated_at": "2025-06-27T13:40:48.688873",
  "source_report": "model_sweep_report 12.json",
  "config_file": "config.json",
  "total_tests_run": 2512,
  "summary": {
    "failed": 1179,
    "passed": 1333,
    "total": 2512,
    "collected": 2512
  },
  "models": {
    "letta/letta-free": {
      "provider_name": "letta",
      "model_name": "letta-free",
      "model_endpoint_type": "openai",
      "model_endpoint": "https://inference.letta.com",
      "provider_category": "base",
      "context_window": 8192,
      "handle": "letta/letta-free",
      "temperature": 0.7,
      "max_tokens": 4096,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": false,
        "Multimodal": false
      }
    },
    "openai/o4-mini-2025-04-16": {
      "provider_name": "openai",
      "model_name": "o4-mini-2025-04-16",
      "model_endpoint_type": "openai",
      "model_endpoint": "https://api.openai.com/v1",
      "provider_category": "base",
      "context_window": 30000,
      "handle": "openai/o4-mini-2025-04-16",
      "temperature": 0.7,
      "max_tokens": 4096,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": false,
        "Multimodal": true
      }
    },
    "openai/o4-mini": {
      "provider_name": "openai",
      "model_name": "o4-mini",
      "model_endpoint_type": "openai",
      "model_endpoint": "https://api.openai.com/v1",
      "provider_category": "base",
      "context_window": 30000,
      "handle": "openai/o4-mini",
      "temperature": 0.7,
      "max_tokens": 4096,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": false,
        "Multimodal": true
      }
    },
    "openai/o3-pro-2025-06-10": {
      "provider_name": "openai",
      "model_name": "o3-pro-2025-06-10",
      "model_endpoint_type": "openai",
      "model_endpoint": "https://api.openai.com/v1",
      "provider_category": "base",
      "context_window": 30000,
      "handle": "openai/o3-pro-2025-06-10",
      "temperature": 0.7,
      "max_tokens": 4096,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": false,
        "Multimodal": false
      }
    },
    "openai/o3-pro": {
      "provider_name": "openai",
      "model_name": "o3-pro",
      "model_endpoint_type": "openai",
      "model_endpoint": "https://api.openai.com/v1",
      "provider_category": "base",
      "context_window": 30000,
      "handle": "openai/o3-pro",
      "temperature": 0.7,
      "max_tokens": 4096,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": false,
        "Multimodal": false
      }
    },
    "openai/o3-mini-2025-01-31": {
      "provider_name": "openai",
      "model_name": "o3-mini-2025-01-31",
      "model_endpoint_type": "openai",
      "model_endpoint": "https://api.openai.com/v1",
      "provider_category": "base",
      "context_window": 200000,
      "handle": "openai/o3-mini-2025-01-31",
      "temperature": 0.7,
      "max_tokens": 4096,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": false,
        "Multimodal": false
      }
    },
    "openai/o3-mini": {
      "provider_name": "openai",
      "model_name": "o3-mini",
      "model_endpoint_type": "openai",
      "model_endpoint": "https://api.openai.com/v1",
      "provider_category": "base",
      "context_window": 200000,
      "handle": "openai/o3-mini",
      "temperature": 0.7,
      "max_tokens": 4096,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": false,
        "Multimodal": false
      }
    },
    "openai/o3-2025-04-16": {
      "provider_name": "openai",
      "model_name": "o3-2025-04-16",
      "model_endpoint_type": "openai",
      "model_endpoint": "https://api.openai.com/v1",
      "provider_category": "base",
      "context_window": 200000,
      "handle": "openai/o3-2025-04-16",
      "temperature": 0.7,
      "max_tokens": 4096,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": false,
        "Multimodal": true
      }
    },
    "openai/o3": {
      "provider_name": "openai",
      "model_name": "o3",
      "model_endpoint_type": "openai",
      "model_endpoint": "https://api.openai.com/v1",
      "provider_category": "base",
      "context_window": 200000,
      "handle": "openai/o3",
      "temperature": 0.7,
      "max_tokens": 4096,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": false,
        "Multimodal": true
      }
    },
    "openai/o1-2024-12-17": {
      "provider_name": "openai",
      "model_name": "o1-2024-12-17",
      "model_endpoint_type": "openai",
      "model_endpoint": "https://api.openai.com/v1",
      "provider_category": "base",
      "context_window": 200000,
      "handle": "openai/o1-2024-12-17",
      "temperature": 0.7,
      "max_tokens": 4096,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": false,
        "Multimodal": true
      }
    },
    "openai/o1": {
      "provider_name": "openai",
      "model_name": "o1",
      "model_endpoint_type": "openai",
      "model_endpoint": "https://api.openai.com/v1",
      "provider_category": "base",
      "context_window": 200000,
      "handle": "openai/o1",
      "temperature": 0.7,
      "max_tokens": 4096,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": false,
        "Multimodal": true
      }
    },
    "openai/gpt-4o-mini-jul": {
      "provider_name": "openai",
      "model_name": "gpt-4o-mini-2024-07-18",
      "model_endpoint_type": "openai",
      "model_endpoint": "https://api.openai.com/v1",
      "provider_category": "base",
      "context_window": 128000,
      "handle": "openai/gpt-4o-mini-jul",
      "temperature": 0.7,
      "max_tokens": 4096,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": true,
        "Token Streaming": true,
        "Multimodal": true
      }
    },
    "openai/gpt-4o-mini": {
      "provider_name": "openai",
      "model_name": "gpt-4o-mini",
      "model_endpoint_type": "openai",
      "model_endpoint": "https://api.openai.com/v1",
      "provider_category": "base",
      "context_window": 128000,
      "handle": "openai/gpt-4o-mini",
      "temperature": 0.7,
      "max_tokens": 4096,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": true,
        "Token Streaming": true,
        "Multimodal": true
      }
    },
    "openai/gpt-4o-2024-11-20": {
      "provider_name": "openai",
      "model_name": "gpt-4o-2024-11-20",
      "model_endpoint_type": "openai",
      "model_endpoint": "https://api.openai.com/v1",
      "provider_category": "base",
      "context_window": 128000,
      "handle": "openai/gpt-4o-2024-11-20",
      "temperature": 0.7,
      "max_tokens": 4096,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": true,
        "Token Streaming": true,
        "Multimodal": true
      }
    },
    "openai/gpt-4o-aug": {
      "provider_name": "openai",
      "model_name": "gpt-4o-2024-08-06",
      "model_endpoint_type": "openai",
      "model_endpoint": "https://api.openai.com/v1",
      "provider_category": "base",
      "context_window": 128000,
      "handle": "openai/gpt-4o-aug",
      "temperature": 0.7,
      "max_tokens": 4096,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": true,
        "Token Streaming": true,
        "Multimodal": true
      }
    },
    "openai/gpt-4o-may": {
      "provider_name": "openai",
      "model_name": "gpt-4o-2024-05-13",
      "model_endpoint_type": "openai",
      "model_endpoint": "https://api.openai.com/v1",
      "provider_category": "base",
      "context_window": 128000,
      "handle": "openai/gpt-4o-may",
      "temperature": 0.7,
      "max_tokens": 4096,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": true,
        "Token Streaming": true,
        "Multimodal": true
      }
    },
    "openai/gpt-4o": {
      "provider_name": "openai",
      "model_name": "gpt-4o",
      "model_endpoint_type": "openai",
      "model_endpoint": "https://api.openai.com/v1",
      "provider_category": "base",
      "context_window": 128000,
      "handle": "openai/gpt-4o",
      "temperature": 0.7,
      "max_tokens": 4096,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": true,
        "Token Streaming": true,
        "Multimodal": true
      }
    },
    "openai/gpt-4.1-nano-2025-04-14": {
      "provider_name": "openai",
      "model_name": "gpt-4.1-nano-2025-04-14",
      "model_endpoint_type": "openai",
      "model_endpoint": "https://api.openai.com/v1",
      "provider_category": "base",
      "context_window": 1047576,
      "handle": "openai/gpt-4.1-nano-2025-04-14",
      "temperature": 0.7,
      "max_tokens": 4096,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": true,
        "Token Streaming": true,
        "Multimodal": true
      }
    },
    "openai/gpt-4.1-nano": {
      "provider_name": "openai",
      "model_name": "gpt-4.1-nano",
      "model_endpoint_type": "openai",
      "model_endpoint": "https://api.openai.com/v1",
      "provider_category": "base",
      "context_window": 1047576,
      "handle": "openai/gpt-4.1-nano",
      "temperature": 0.7,
      "max_tokens": 4096,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": true,
        "Token Streaming": true,
        "Multimodal": true
      }
    },
    "openai/gpt-4.1-mini-2025-04-14": {
      "provider_name": "openai",
      "model_name": "gpt-4.1-mini-2025-04-14",
      "model_endpoint_type": "openai",
      "model_endpoint": "https://api.openai.com/v1",
      "provider_category": "base",
      "context_window": 1047576,
      "handle": "openai/gpt-4.1-mini-2025-04-14",
      "temperature": 0.7,
      "max_tokens": 4096,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": true,
        "Token Streaming": true,
        "Multimodal": true
      }
    },
    "openai/gpt-4.1-mini": {
      "provider_name": "openai",
      "model_name": "gpt-4.1-mini",
      "model_endpoint_type": "openai",
      "model_endpoint": "https://api.openai.com/v1",
      "provider_category": "base",
      "context_window": 1047576,
      "handle": "openai/gpt-4.1-mini",
      "temperature": 0.7,
      "max_tokens": 4096,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": true,
        "Token Streaming": true,
        "Multimodal": true
      }
    },
    "openai/gpt-4.1-2025-04-14": {
      "provider_name": "openai",
      "model_name": "gpt-4.1-2025-04-14",
      "model_endpoint_type": "openai",
      "model_endpoint": "https://api.openai.com/v1",
      "provider_category": "base",
      "context_window": 1047576,
      "handle": "openai/gpt-4.1-2025-04-14",
      "temperature": 0.7,
      "max_tokens": 4096,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": true,
        "Token Streaming": true,
        "Multimodal": true
      }
    },
    "openai/gpt-4.1": {
      "provider_name": "openai",
      "model_name": "gpt-4.1",
      "model_endpoint_type": "openai",
      "model_endpoint": "https://api.openai.com/v1",
      "provider_category": "base",
      "context_window": 1047576,
      "handle": "openai/gpt-4.1",
      "temperature": 0.7,
      "max_tokens": 4096,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": true,
        "Token Streaming": true,
        "Multimodal": true
      }
    },
    "openai/gpt-4-turbo-preview": {
      "provider_name": "openai",
      "model_name": "gpt-4-turbo-preview",
      "model_endpoint_type": "openai",
      "model_endpoint": "https://api.openai.com/v1",
      "provider_category": "base",
      "context_window": 128000,
      "handle": "openai/gpt-4-turbo-preview",
      "temperature": 0.7,
      "max_tokens": 4096,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": true,
        "Token Streaming": true,
        "Multimodal": false
      }
    },
    "openai/gpt-4-turbo-apr": {
      "provider_name": "openai",
      "model_name": "gpt-4-turbo-2024-04-09",
      "model_endpoint_type": "openai",
      "model_endpoint": "https://api.openai.com/v1",
      "provider_category": "base",
      "context_window": 128000,
      "handle": "openai/gpt-4-turbo-apr",
      "temperature": 0.7,
      "max_tokens": 4096,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": true,
        "Token Streaming": true,
        "Multimodal": true
      }
    },
    "openai/gpt-4-turbo": {
      "provider_name": "openai",
      "model_name": "gpt-4-turbo",
      "model_endpoint_type": "openai",
      "model_endpoint": "https://api.openai.com/v1",
      "provider_category": "base",
      "context_window": 128000,
      "handle": "openai/gpt-4-turbo",
      "temperature": 0.7,
      "max_tokens": 4096,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": true,
        "Token Streaming": true,
        "Multimodal": true
      }
    },
    "openai/gpt-4-preview-nov": {
      "provider_name": "openai",
      "model_name": "gpt-4-1106-preview",
      "model_endpoint_type": "openai",
      "model_endpoint": "https://api.openai.com/v1",
      "provider_category": "base",
      "context_window": 128000,
      "handle": "openai/gpt-4-preview-nov",
      "temperature": 0.7,
      "max_tokens": 4096,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": true,
        "Token Streaming": true,
        "Multimodal": false
      }
    },
    "openai/gpt-4-june": {
      "provider_name": "openai",
      "model_name": "gpt-4-0613",
      "model_endpoint_type": "openai",
      "model_endpoint": "https://api.openai.com/v1",
      "provider_category": "base",
      "context_window": 8192,
      "handle": "openai/gpt-4-june",
      "temperature": 0.7,
      "max_tokens": 4096,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": true,
        "Token Streaming": true,
        "Multimodal": false
      }
    },
    "openai/gpt-4-preview-jan": {
      "provider_name": "openai",
      "model_name": "gpt-4-0125-preview",
      "model_endpoint_type": "openai",
      "model_endpoint": "https://api.openai.com/v1",
      "provider_category": "base",
      "context_window": 128000,
      "handle": "openai/gpt-4-preview-jan",
      "temperature": 0.7,
      "max_tokens": 4096,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": true,
        "Multimodal": false
      }
    },
    "openai/gpt-4": {
      "provider_name": "openai",
      "model_name": "gpt-4",
      "model_endpoint_type": "openai",
      "model_endpoint": "https://api.openai.com/v1",
      "provider_category": "base",
      "context_window": 8192,
      "handle": "openai/gpt-4",
      "temperature": 0.7,
      "max_tokens": 4096,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": false,
        "Multimodal": false
      }
    },
    "anthropic/claude-opus-4-20250514": {
      "provider_name": "anthropic",
      "model_name": "claude-opus-4-20250514",
      "model_endpoint_type": "anthropic",
      "model_endpoint": "https://api.anthropic.com/v1",
      "provider_category": "base",
      "context_window": 200000,
      "handle": "anthropic/claude-opus-4-20250514",
      "temperature": 0.7,
      "max_tokens": 8192,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": true,
        "Token Streaming": true,
        "Multimodal": true
      }
    },
    "anthropic/claude-sonnet-4-20250514": {
      "provider_name": "anthropic",
      "model_name": "claude-sonnet-4-20250514",
      "model_endpoint_type": "anthropic",
      "model_endpoint": "https://api.anthropic.com/v1",
      "provider_category": "base",
      "context_window": 200000,
      "handle": "anthropic/claude-sonnet-4-20250514",
      "temperature": 0.7,
      "max_tokens": 8192,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": true,
        "Token Streaming": true,
        "Multimodal": true
      }
    },
    "anthropic/claude-3-7-sonnet-20250219": {
      "provider_name": "anthropic",
      "model_name": "claude-3-7-sonnet-20250219",
      "model_endpoint_type": "anthropic",
      "model_endpoint": "https://api.anthropic.com/v1",
      "provider_category": "base",
      "context_window": 200000,
      "handle": "anthropic/claude-3-7-sonnet-20250219",
      "temperature": 0.7,
      "max_tokens": 8192,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": true,
        "Token Streaming": true,
        "Multimodal": true
      }
    },
    "anthropic/claude-3-5-sonnet": {
      "provider_name": "anthropic",
      "model_name": "claude-3-5-sonnet-20241022",
      "model_endpoint_type": "anthropic",
      "model_endpoint": "https://api.anthropic.com/v1",
      "provider_category": "base",
      "context_window": 200000,
      "handle": "anthropic/claude-3-5-sonnet",
      "temperature": 0.7,
      "max_tokens": 8192,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": true,
        "Token Streaming": true,
        "Multimodal": true
      }
    },
    "anthropic/claude-3-5-haiku": {
      "provider_name": "anthropic",
      "model_name": "claude-3-5-haiku-20241022",
      "model_endpoint_type": "anthropic",
      "model_endpoint": "https://api.anthropic.com/v1",
      "provider_category": "base",
      "context_window": 200000,
      "handle": "anthropic/claude-3-5-haiku",
      "temperature": 0.7,
      "max_tokens": 8192,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": true,
        "Token Streaming": true,
        "Multimodal": true
      }
    },
    "anthropic/claude-3-5-sonnet-20240620": {
      "provider_name": "anthropic",
      "model_name": "claude-3-5-sonnet-20240620",
      "model_endpoint_type": "anthropic",
      "model_endpoint": "https://api.anthropic.com/v1",
      "provider_category": "base",
      "context_window": 200000,
      "handle": "anthropic/claude-3-5-sonnet-20240620",
      "temperature": 0.7,
      "max_tokens": 8192,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": true,
        "Token Streaming": true,
        "Multimodal": true
      }
    },
    "anthropic/claude-3-haiku-20240307": {
      "provider_name": "anthropic",
      "model_name": "claude-3-haiku-20240307",
      "model_endpoint_type": "anthropic",
      "model_endpoint": "https://api.anthropic.com/v1",
      "provider_category": "base",
      "context_window": 200000,
      "handle": "anthropic/claude-3-haiku-20240307",
      "temperature": 0.7,
      "max_tokens": 4096,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": false,
        "Multimodal": true
      }
    },
    "anthropic/claude-3-opus": {
      "provider_name": "anthropic",
      "model_name": "claude-3-opus-20240229",
      "model_endpoint_type": "anthropic",
      "model_endpoint": "https://api.anthropic.com/v1",
      "provider_category": "base",
      "context_window": 200000,
      "handle": "anthropic/claude-3-opus",
      "temperature": 0.7,
      "max_tokens": 4096,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": true,
        "Multimodal": true
      }
    },
    "anthropic/claude-3-sonnet-20240229": {
      "provider_name": "anthropic",
      "model_name": "claude-3-sonnet-20240229",
      "model_endpoint_type": "anthropic",
      "model_endpoint": "https://api.anthropic.com/v1",
      "provider_category": "base",
      "context_window": 200000,
      "handle": "anthropic/claude-3-sonnet-20240229",
      "temperature": 0.7,
      "max_tokens": 8192,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": false,
        "Multimodal": false
      }
    },
    "google_ai/gemini-1.0-pro-vision-latest": {
      "provider_name": "google_ai",
      "model_name": "gemini-1.0-pro-vision-latest",
      "model_endpoint_type": "google_ai",
      "model_endpoint": "https://generativelanguage.googleapis.com",
      "provider_category": "base",
      "context_window": 12288,
      "handle": "google_ai/gemini-1.0-pro-vision-latest",
      "temperature": 0.7,
      "max_tokens": 8192,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": false,
        "Multimodal": false
      }
    },
    "google_ai/gemini-pro-vision": {
      "provider_name": "google_ai",
      "model_name": "gemini-pro-vision",
      "model_endpoint_type": "google_ai",
      "model_endpoint": "https://generativelanguage.googleapis.com",
      "provider_category": "base",
      "context_window": 12288,
      "handle": "google_ai/gemini-pro-vision",
      "temperature": 0.7,
      "max_tokens": 8192,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": false,
        "Multimodal": false
      }
    },
    "google_ai/gemini-1.5-pro-latest": {
      "provider_name": "google_ai",
      "model_name": "gemini-1.5-pro-latest",
      "model_endpoint_type": "google_ai",
      "model_endpoint": "https://generativelanguage.googleapis.com",
      "provider_category": "base",
      "context_window": 2000000,
      "handle": "google_ai/gemini-1.5-pro-latest",
      "temperature": 0.7,
      "max_tokens": 8192,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": true,
        "Token Streaming": true,
        "Multimodal": true
      }
    },
    "google_ai/gemini-1.5-pro-002": {
      "provider_name": "google_ai",
      "model_name": "gemini-1.5-pro-002",
      "model_endpoint_type": "google_ai",
      "model_endpoint": "https://generativelanguage.googleapis.com",
      "provider_category": "base",
      "context_window": 2000000,
      "handle": "google_ai/gemini-1.5-pro-002",
      "temperature": 0.7,
      "max_tokens": 8192,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": true,
        "Token Streaming": true,
        "Multimodal": true
      }
    },
    "google_ai/gemini-1.5-pro": {
      "provider_name": "google_ai",
      "model_name": "gemini-1.5-pro",
      "model_endpoint_type": "google_ai",
      "model_endpoint": "https://generativelanguage.googleapis.com",
      "provider_category": "base",
      "context_window": 2000000,
      "handle": "google_ai/gemini-1.5-pro",
      "temperature": 0.7,
      "max_tokens": 8192,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": true,
        "Token Streaming": true,
        "Multimodal": true
      }
    },
    "google_ai/gemini-1.5-flash-latest": {
      "provider_name": "google_ai",
      "model_name": "gemini-1.5-flash-latest",
      "model_endpoint_type": "google_ai",
      "model_endpoint": "https://generativelanguage.googleapis.com",
      "provider_category": "base",
      "context_window": 1000000,
      "handle": "google_ai/gemini-1.5-flash-latest",
      "temperature": 0.7,
      "max_tokens": 8192,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": false,
        "Multimodal": false
      }
    },
    "google_ai/gemini-1.5-flash": {
      "provider_name": "google_ai",
      "model_name": "gemini-1.5-flash",
      "model_endpoint_type": "google_ai",
      "model_endpoint": "https://generativelanguage.googleapis.com",
      "provider_category": "base",
      "context_window": 1000000,
      "handle": "google_ai/gemini-1.5-flash",
      "temperature": 0.7,
      "max_tokens": 8192,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": false,
        "Multimodal": false
      }
    },
    "google_ai/gemini-1.5-flash-002": {
      "provider_name": "google_ai",
      "model_name": "gemini-1.5-flash-002",
      "model_endpoint_type": "google_ai",
      "model_endpoint": "https://generativelanguage.googleapis.com",
      "provider_category": "base",
      "context_window": 1000000,
      "handle": "google_ai/gemini-1.5-flash-002",
      "temperature": 0.7,
      "max_tokens": 8192,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": false,
        "Multimodal": false
      }
    },
    "google_ai/gemini-1.5-flash-8b": {
      "provider_name": "google_ai",
      "model_name": "gemini-1.5-flash-8b",
      "model_endpoint_type": "google_ai",
      "model_endpoint": "https://generativelanguage.googleapis.com",
      "provider_category": "base",
      "context_window": 1000000,
      "handle": "google_ai/gemini-1.5-flash-8b",
      "temperature": 0.7,
      "max_tokens": 8192,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": false,
        "Multimodal": false
      }
    },
    "google_ai/gemini-1.5-flash-8b-001": {
      "provider_name": "google_ai",
      "model_name": "gemini-1.5-flash-8b-001",
      "model_endpoint_type": "google_ai",
      "model_endpoint": "https://generativelanguage.googleapis.com",
      "provider_category": "base",
      "context_window": 1000000,
      "handle": "google_ai/gemini-1.5-flash-8b-001",
      "temperature": 0.7,
      "max_tokens": 8192,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": false,
        "Multimodal": false
      }
    },
    "google_ai/gemini-1.5-flash-8b-latest": {
      "provider_name": "google_ai",
      "model_name": "gemini-1.5-flash-8b-latest",
      "model_endpoint_type": "google_ai",
      "model_endpoint": "https://generativelanguage.googleapis.com",
      "provider_category": "base",
      "context_window": 1000000,
      "handle": "google_ai/gemini-1.5-flash-8b-latest",
      "temperature": 0.7,
      "max_tokens": 8192,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": false,
        "Multimodal": false
      }
    },
    "google_ai/gemini-2.5-pro-preview-03-25": {
      "provider_name": "google_ai",
      "model_name": "gemini-2.5-pro-preview-03-25",
      "model_endpoint_type": "google_ai",
      "model_endpoint": "https://generativelanguage.googleapis.com",
      "provider_category": "base",
      "context_window": 1048576,
      "handle": "google_ai/gemini-2.5-pro-preview-03-25",
      "temperature": 0.7,
      "max_tokens": 8192,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": true,
        "Token Streaming": true,
        "Multimodal": true
      }
    },
    "google_ai/gemini-2.5-flash-preview-04-17": {
      "provider_name": "google_ai",
      "model_name": "gemini-2.5-flash-preview-04-17",
      "model_endpoint_type": "google_ai",
      "model_endpoint": "https://generativelanguage.googleapis.com",
      "provider_category": "base",
      "context_window": 1048576,
      "handle": "google_ai/gemini-2.5-flash-preview-04-17",
      "temperature": 0.7,
      "max_tokens": 8192,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": true,
        "Token Streaming": true,
        "Multimodal": true
      }
    },
    "google_ai/gemini-2.5-flash-preview-05-20": {
      "provider_name": "google_ai",
      "model_name": "gemini-2.5-flash-preview-05-20",
      "model_endpoint_type": "google_ai",
      "model_endpoint": "https://generativelanguage.googleapis.com",
      "provider_category": "base",
      "context_window": 1048576,
      "handle": "google_ai/gemini-2.5-flash-preview-05-20",
      "temperature": 0.7,
      "max_tokens": 8192,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": true,
        "Multimodal": true
      }
    },
    "google_ai/gemini-2.5-flash": {
      "provider_name": "google_ai",
      "model_name": "gemini-2.5-flash",
      "model_endpoint_type": "google_ai",
      "model_endpoint": "https://generativelanguage.googleapis.com",
      "provider_category": "base",
      "context_window": 1048576,
      "handle": "google_ai/gemini-2.5-flash",
      "temperature": 0.7,
      "max_tokens": 8192,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": true,
        "Token Streaming": false,
        "Multimodal": true
      }
    },
    "google_ai/gemini-2.5-flash-preview-04-17-thinking": {
      "provider_name": "google_ai",
      "model_name": "gemini-2.5-flash-preview-04-17-thinking",
      "model_endpoint_type": "google_ai",
      "model_endpoint": "https://generativelanguage.googleapis.com",
      "provider_category": "base",
      "context_window": 1048576,
      "handle": "google_ai/gemini-2.5-flash-preview-04-17-thinking",
      "temperature": 0.7,
      "max_tokens": 8192,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": true,
        "Multimodal": true
      }
    },
    "google_ai/gemini-2.5-flash-lite-preview-06-17": {
      "provider_name": "google_ai",
      "model_name": "gemini-2.5-flash-lite-preview-06-17",
      "model_endpoint_type": "google_ai",
      "model_endpoint": "https://generativelanguage.googleapis.com",
      "provider_category": "base",
      "context_window": 1048576,
      "handle": "google_ai/gemini-2.5-flash-lite-preview-06-17",
      "temperature": 0.7,
      "max_tokens": 8192,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": false,
        "Multimodal": true
      }
    },
    "google_ai/gemini-2.5-pro-preview-05-06": {
      "provider_name": "google_ai",
      "model_name": "gemini-2.5-pro-preview-05-06",
      "model_endpoint_type": "google_ai",
      "model_endpoint": "https://generativelanguage.googleapis.com",
      "provider_category": "base",
      "context_window": 1048576,
      "handle": "google_ai/gemini-2.5-pro-preview-05-06",
      "temperature": 0.7,
      "max_tokens": 8192,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": true,
        "Token Streaming": true,
        "Multimodal": true
      }
    },
    "google_ai/gemini-2.5-pro-preview-06-05": {
      "provider_name": "google_ai",
      "model_name": "gemini-2.5-pro-preview-06-05",
      "model_endpoint_type": "google_ai",
      "model_endpoint": "https://generativelanguage.googleapis.com",
      "provider_category": "base",
      "context_window": 1048576,
      "handle": "google_ai/gemini-2.5-pro-preview-06-05",
      "temperature": 0.7,
      "max_tokens": 8192,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": true,
        "Multimodal": true
      }
    },
    "google_ai/gemini-2.5-pro": {
      "provider_name": "google_ai",
      "model_name": "gemini-2.5-pro",
      "model_endpoint_type": "google_ai",
      "model_endpoint": "https://generativelanguage.googleapis.com",
      "provider_category": "base",
      "context_window": 1048576,
      "handle": "google_ai/gemini-2.5-pro",
      "temperature": 0.7,
      "max_tokens": 8192,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": true,
        "Token Streaming": true,
        "Multimodal": true
      }
    },
    "google_ai/gemini-2.0-flash-exp": {
      "provider_name": "google_ai",
      "model_name": "gemini-2.0-flash-exp",
      "model_endpoint_type": "google_ai",
      "model_endpoint": "https://generativelanguage.googleapis.com",
      "provider_category": "base",
      "context_window": 1048576,
      "handle": "google_ai/gemini-2.0-flash-exp",
      "temperature": 0.7,
      "max_tokens": 8192,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": false,
        "Multimodal": false
      }
    },
    "google_ai/gemini-2.0-flash": {
      "provider_name": "google_ai",
      "model_name": "gemini-2.0-flash",
      "model_endpoint_type": "google_ai",
      "model_endpoint": "https://generativelanguage.googleapis.com",
      "provider_category": "base",
      "context_window": 1048576,
      "handle": "google_ai/gemini-2.0-flash",
      "temperature": 0.7,
      "max_tokens": 8192,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": false,
        "Multimodal": false
      }
    },
    "google_ai/gemini-2.0-flash-001": {
      "provider_name": "google_ai",
      "model_name": "gemini-2.0-flash-001",
      "model_endpoint_type": "google_ai",
      "model_endpoint": "https://generativelanguage.googleapis.com",
      "provider_category": "base",
      "context_window": 1048576,
      "handle": "google_ai/gemini-2.0-flash-001",
      "temperature": 0.7,
      "max_tokens": 8192,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": false,
        "Multimodal": false
      }
    },
    "google_ai/gemini-2.0-flash-exp-image-generation": {
      "provider_name": "google_ai",
      "model_name": "gemini-2.0-flash-exp-image-generation",
      "model_endpoint_type": "google_ai",
      "model_endpoint": "https://generativelanguage.googleapis.com",
      "provider_category": "base",
      "context_window": 1048576,
      "handle": "google_ai/gemini-2.0-flash-exp-image-generation",
      "temperature": 0.7,
      "max_tokens": 8192,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": false,
        "Multimodal": false
      }
    },
    "google_ai/gemini-2.0-flash-lite-001": {
      "provider_name": "google_ai",
      "model_name": "gemini-2.0-flash-lite-001",
      "model_endpoint_type": "google_ai",
      "model_endpoint": "https://generativelanguage.googleapis.com",
      "provider_category": "base",
      "context_window": 1048576,
      "handle": "google_ai/gemini-2.0-flash-lite-001",
      "temperature": 0.7,
      "max_tokens": 8192,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": false,
        "Multimodal": false
      }
    },
    "google_ai/gemini-2.0-flash-lite": {
      "provider_name": "google_ai",
      "model_name": "gemini-2.0-flash-lite",
      "model_endpoint_type": "google_ai",
      "model_endpoint": "https://generativelanguage.googleapis.com",
      "provider_category": "base",
      "context_window": 1048576,
      "handle": "google_ai/gemini-2.0-flash-lite",
      "temperature": 0.7,
      "max_tokens": 8192,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": false,
        "Multimodal": false
      }
    },
    "google_ai/gemini-2.0-flash-preview-image-generation": {
      "provider_name": "google_ai",
      "model_name": "gemini-2.0-flash-preview-image-generation",
      "model_endpoint_type": "google_ai",
      "model_endpoint": "https://generativelanguage.googleapis.com",
      "provider_category": "base",
      "context_window": 32768,
      "handle": "google_ai/gemini-2.0-flash-preview-image-generation",
      "temperature": 0.7,
      "max_tokens": 8192,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": false,
        "Multimodal": false
      }
    },
    "google_ai/gemini-2.0-flash-lite-preview-02-05": {
      "provider_name": "google_ai",
      "model_name": "gemini-2.0-flash-lite-preview-02-05",
      "model_endpoint_type": "google_ai",
      "model_endpoint": "https://generativelanguage.googleapis.com",
      "provider_category": "base",
      "context_window": 1048576,
      "handle": "google_ai/gemini-2.0-flash-lite-preview-02-05",
      "temperature": 0.7,
      "max_tokens": 8192,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": false,
        "Multimodal": false
      }
    },
    "google_ai/gemini-2.0-flash-lite-preview": {
      "provider_name": "google_ai",
      "model_name": "gemini-2.0-flash-lite-preview",
      "model_endpoint_type": "google_ai",
      "model_endpoint": "https://generativelanguage.googleapis.com",
      "provider_category": "base",
      "context_window": 1048576,
      "handle": "google_ai/gemini-2.0-flash-lite-preview",
      "temperature": 0.7,
      "max_tokens": 8192,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": false,
        "Multimodal": false
      }
    },
    "google_ai/gemini-2.0-pro-exp": {
      "provider_name": "google_ai",
      "model_name": "gemini-2.0-pro-exp",
      "model_endpoint_type": "google_ai",
      "model_endpoint": "https://generativelanguage.googleapis.com",
      "provider_category": "base",
      "context_window": 1048576,
      "handle": "google_ai/gemini-2.0-pro-exp",
      "temperature": 0.7,
      "max_tokens": 8192,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": false,
        "Multimodal": false
      }
    },
    "google_ai/gemini-2.0-pro-exp-02-05": {
      "provider_name": "google_ai",
      "model_name": "gemini-2.0-pro-exp-02-05",
      "model_endpoint_type": "google_ai",
      "model_endpoint": "https://generativelanguage.googleapis.com",
      "provider_category": "base",
      "context_window": 1048576,
      "handle": "google_ai/gemini-2.0-pro-exp-02-05",
      "temperature": 0.7,
      "max_tokens": 8192,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": false,
        "Multimodal": false
      }
    },
    "google_ai/gemini-exp-1206": {
      "provider_name": "google_ai",
      "model_name": "gemini-exp-1206",
      "model_endpoint_type": "google_ai",
      "model_endpoint": "https://generativelanguage.googleapis.com",
      "provider_category": "base",
      "context_window": 1048576,
      "handle": "google_ai/gemini-exp-1206",
      "temperature": 0.7,
      "max_tokens": 8192,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": false,
        "Multimodal": false
      }
    },
    "google_ai/gemini-2.0-flash-thinking-exp-01-21": {
      "provider_name": "google_ai",
      "model_name": "gemini-2.0-flash-thinking-exp-01-21",
      "model_endpoint_type": "google_ai",
      "model_endpoint": "https://generativelanguage.googleapis.com",
      "provider_category": "base",
      "context_window": 1048576,
      "handle": "google_ai/gemini-2.0-flash-thinking-exp-01-21",
      "temperature": 0.7,
      "max_tokens": 8192,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": false,
        "Multimodal": true
      }
    },
    "google_ai/gemini-2.0-flash-thinking-exp": {
      "provider_name": "google_ai",
      "model_name": "gemini-2.0-flash-thinking-exp",
      "model_endpoint_type": "google_ai",
      "model_endpoint": "https://generativelanguage.googleapis.com",
      "provider_category": "base",
      "context_window": 1048576,
      "handle": "google_ai/gemini-2.0-flash-thinking-exp",
      "temperature": 0.7,
      "max_tokens": 8192,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": true,
        "Token Streaming": true,
        "Multimodal": true
      }
    },
    "google_ai/gemini-2.0-flash-thinking-exp-1219": {
      "provider_name": "google_ai",
      "model_name": "gemini-2.0-flash-thinking-exp-1219",
      "model_endpoint_type": "google_ai",
      "model_endpoint": "https://generativelanguage.googleapis.com",
      "provider_category": "base",
      "context_window": 1048576,
      "handle": "google_ai/gemini-2.0-flash-thinking-exp-1219",
      "temperature": 0.7,
      "max_tokens": 8192,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": true,
        "Multimodal": true
      }
    },
    "google_ai/gemini-2.5-flash-preview-tts": {
      "provider_name": "google_ai",
      "model_name": "gemini-2.5-flash-preview-tts",
      "model_endpoint_type": "google_ai",
      "model_endpoint": "https://generativelanguage.googleapis.com",
      "provider_category": "base",
      "context_window": 32768,
      "handle": "google_ai/gemini-2.5-flash-preview-tts",
      "temperature": 0.7,
      "max_tokens": 8192,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": false,
        "Multimodal": false
      }
    },
    "google_ai/gemini-2.5-pro-preview-tts": {
      "provider_name": "google_ai",
      "model_name": "gemini-2.5-pro-preview-tts",
      "model_endpoint_type": "google_ai",
      "model_endpoint": "https://generativelanguage.googleapis.com",
      "provider_category": "base",
      "context_window": 65536,
      "handle": "google_ai/gemini-2.5-pro-preview-tts",
      "temperature": 0.7,
      "max_tokens": 8192,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": false,
        "Multimodal": false
      }
    },
    "openai-proxy/meta-llama/llama-guard-4-12b": {
      "provider_name": "groq",
      "model_name": "meta-llama/llama-guard-4-12b",
      "model_endpoint_type": "openai",
      "model_endpoint": "https://api.groq.com/openai/v1",
      "provider_category": "base",
      "context_window": 30000,
      "handle": "openai-proxy/meta-llama/llama-guard-4-12b",
      "temperature": 0.7,
      "max_tokens": 4096,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": false,
        "Multimodal": false
      }
    },
    "openai-proxy/llama-3.1-8b-instant": {
      "provider_name": "groq",
      "model_name": "llama-3.1-8b-instant",
      "model_endpoint_type": "openai",
      "model_endpoint": "https://api.groq.com/openai/v1",
      "provider_category": "base",
      "context_window": 30000,
      "handle": "openai-proxy/llama-3.1-8b-instant",
      "temperature": 0.7,
      "max_tokens": 4096,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": false,
        "Multimodal": false
      }
    },
    "openai-proxy/playai-tts": {
      "provider_name": "groq",
      "model_name": "playai-tts",
      "model_endpoint_type": "openai",
      "model_endpoint": "https://api.groq.com/openai/v1",
      "provider_category": "base",
      "context_window": 30000,
      "handle": "openai-proxy/playai-tts",
      "temperature": 0.7,
      "max_tokens": 4096,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": false,
        "Multimodal": false
      }
    },
    "openai-proxy/meta-llama/llama-4-maverick-17b-128e-instruct": {
      "provider_name": "groq",
      "model_name": "meta-llama/llama-4-maverick-17b-128e-instruct",
      "model_endpoint_type": "openai",
      "model_endpoint": "https://api.groq.com/openai/v1",
      "provider_category": "base",
      "context_window": 30000,
      "handle": "openai-proxy/meta-llama/llama-4-maverick-17b-128e-instruct",
      "temperature": 0.7,
      "max_tokens": 4096,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": false,
        "Multimodal": false
      }
    },
    "openai-proxy/playai-tts-arabic": {
      "provider_name": "groq",
      "model_name": "playai-tts-arabic",
      "model_endpoint_type": "openai",
      "model_endpoint": "https://api.groq.com/openai/v1",
      "provider_category": "base",
      "context_window": 30000,
      "handle": "openai-proxy/playai-tts-arabic",
      "temperature": 0.7,
      "max_tokens": 4096,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": false,
        "Multimodal": false
      }
    },
    "openai-proxy/deepseek-r1-distill-llama-70b": {
      "provider_name": "groq",
      "model_name": "deepseek-r1-distill-llama-70b",
      "model_endpoint_type": "openai",
      "model_endpoint": "https://api.groq.com/openai/v1",
      "provider_category": "base",
      "context_window": 30000,
      "handle": "openai-proxy/deepseek-r1-distill-llama-70b",
      "temperature": 0.7,
      "max_tokens": 4096,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": false,
        "Multimodal": false
      }
    },
    "openai-proxy/compound-beta": {
      "provider_name": "groq",
      "model_name": "compound-beta",
      "model_endpoint_type": "openai",
      "model_endpoint": "https://api.groq.com/openai/v1",
      "provider_category": "base",
      "context_window": 30000,
      "handle": "openai-proxy/compound-beta",
      "temperature": 0.7,
      "max_tokens": 4096,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": false,
        "Multimodal": false
      }
    },
    "openai-proxy/llama-3.3-70b-versatile": {
      "provider_name": "groq",
      "model_name": "llama-3.3-70b-versatile",
      "model_endpoint_type": "openai",
      "model_endpoint": "https://api.groq.com/openai/v1",
      "provider_category": "base",
      "context_window": 30000,
      "handle": "openai-proxy/llama-3.3-70b-versatile",
      "temperature": 0.7,
      "max_tokens": 4096,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": false,
        "Multimodal": false
      }
    },
    "openai-proxy/whisper-large-v3": {
      "provider_name": "groq",
      "model_name": "whisper-large-v3",
      "model_endpoint_type": "openai",
      "model_endpoint": "https://api.groq.com/openai/v1",
      "provider_category": "base",
      "context_window": 30000,
      "handle": "openai-proxy/whisper-large-v3",
      "temperature": 0.7,
      "max_tokens": 4096,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": false,
        "Multimodal": false
      }
    },
    "openai-proxy/compound-beta-mini": {
      "provider_name": "groq",
      "model_name": "compound-beta-mini",
      "model_endpoint_type": "openai",
      "model_endpoint": "https://api.groq.com/openai/v1",
      "provider_category": "base",
      "context_window": 30000,
      "handle": "openai-proxy/compound-beta-mini",
      "temperature": 0.7,
      "max_tokens": 4096,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": false,
        "Multimodal": false
      }
    },
    "openai-proxy/gemma2-9b-it": {
      "provider_name": "groq",
      "model_name": "gemma2-9b-it",
      "model_endpoint_type": "openai",
      "model_endpoint": "https://api.groq.com/openai/v1",
      "provider_category": "base",
      "context_window": 30000,
      "handle": "openai-proxy/gemma2-9b-it",
      "temperature": 0.7,
      "max_tokens": 4096,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": false,
        "Multimodal": false
      }
    },
    "openai-proxy/llama3-70b-8192": {
      "provider_name": "groq",
      "model_name": "llama3-70b-8192",
      "model_endpoint_type": "openai",
      "model_endpoint": "https://api.groq.com/openai/v1",
      "provider_category": "base",
      "context_window": 30000,
      "handle": "openai-proxy/llama3-70b-8192",
      "temperature": 0.7,
      "max_tokens": 4096,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": false,
        "Multimodal": false
      }
    },
    "openai-proxy/qwen/qwen3-32b": {
      "provider_name": "groq",
      "model_name": "qwen/qwen3-32b",
      "model_endpoint_type": "openai",
      "model_endpoint": "https://api.groq.com/openai/v1",
      "provider_category": "base",
      "context_window": 30000,
      "handle": "openai-proxy/qwen/qwen3-32b",
      "temperature": 0.7,
      "max_tokens": 4096,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": false,
        "Multimodal": false
      }
    },
    "openai-proxy/whisper-large-v3-turbo": {
      "provider_name": "groq",
      "model_name": "whisper-large-v3-turbo",
      "model_endpoint_type": "openai",
      "model_endpoint": "https://api.groq.com/openai/v1",
      "provider_category": "base",
      "context_window": 30000,
      "handle": "openai-proxy/whisper-large-v3-turbo",
      "temperature": 0.7,
      "max_tokens": 4096,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": false,
        "Multimodal": false
      }
    },
    "openai-proxy/meta-llama/llama-prompt-guard-2-86m": {
      "provider_name": "groq",
      "model_name": "meta-llama/llama-prompt-guard-2-86m",
      "model_endpoint_type": "openai",
      "model_endpoint": "https://api.groq.com/openai/v1",
      "provider_category": "base",
      "context_window": 30000,
      "handle": "openai-proxy/meta-llama/llama-prompt-guard-2-86m",
      "temperature": 0.7,
      "max_tokens": 4096,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": false,
        "Multimodal": false
      }
    },
    "openai-proxy/meta-llama/llama-prompt-guard-2-22m": {
      "provider_name": "groq",
      "model_name": "meta-llama/llama-prompt-guard-2-22m",
      "model_endpoint_type": "openai",
      "model_endpoint": "https://api.groq.com/openai/v1",
      "provider_category": "base",
      "context_window": 30000,
      "handle": "openai-proxy/meta-llama/llama-prompt-guard-2-22m",
      "temperature": 0.7,
      "max_tokens": 4096,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": false,
        "Multimodal": false
      }
    },
    "openai-proxy/distil-whisper-large-v3-en": {
      "provider_name": "groq",
      "model_name": "distil-whisper-large-v3-en",
      "model_endpoint_type": "openai",
      "model_endpoint": "https://api.groq.com/openai/v1",
      "provider_category": "base",
      "context_window": 30000,
      "handle": "openai-proxy/distil-whisper-large-v3-en",
      "temperature": 0.7,
      "max_tokens": 4096,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": false,
        "Multimodal": false
      }
    },
    "openai-proxy/allam-2-7b": {
      "provider_name": "groq",
      "model_name": "allam-2-7b",
      "model_endpoint_type": "openai",
      "model_endpoint": "https://api.groq.com/openai/v1",
      "provider_category": "base",
      "context_window": 30000,
      "handle": "openai-proxy/allam-2-7b",
      "temperature": 0.7,
      "max_tokens": 4096,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": false,
        "Multimodal": false
      }
    },
    "openai-proxy/mistral-saba-24b": {
      "provider_name": "groq",
      "model_name": "mistral-saba-24b",
      "model_endpoint_type": "openai",
      "model_endpoint": "https://api.groq.com/openai/v1",
      "provider_category": "base",
      "context_window": 30000,
      "handle": "openai-proxy/mistral-saba-24b",
      "temperature": 0.7,
      "max_tokens": 4096,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": false,
        "Multimodal": false
      }
    },
    "openai-proxy/meta-llama/llama-4-scout-17b-16e-instruct": {
      "provider_name": "groq",
      "model_name": "meta-llama/llama-4-scout-17b-16e-instruct",
      "model_endpoint_type": "openai",
      "model_endpoint": "https://api.groq.com/openai/v1",
      "provider_category": "base",
      "context_window": 30000,
      "handle": "openai-proxy/meta-llama/llama-4-scout-17b-16e-instruct",
      "temperature": 0.7,
      "max_tokens": 4096,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": false,
        "Multimodal": false
      }
    },
    "openai-proxy/llama3-8b-8192": {
      "provider_name": "groq",
      "model_name": "llama3-8b-8192",
      "model_endpoint_type": "openai",
      "model_endpoint": "https://api.groq.com/openai/v1",
      "provider_category": "base",
      "context_window": 30000,
      "handle": "openai-proxy/llama3-8b-8192",
      "temperature": 0.7,
      "max_tokens": 4096,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": false,
        "Multimodal": false
      }
    },
    "openai-proxy/qwen-qwq-32b": {
      "provider_name": "groq",
      "model_name": "qwen-qwq-32b",
      "model_endpoint_type": "openai",
      "model_endpoint": "https://api.groq.com/openai/v1",
      "provider_category": "base",
      "context_window": 30000,
      "handle": "openai-proxy/qwen-qwq-32b",
      "temperature": 0.7,
      "max_tokens": 4096,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": false,
        "Multimodal": false
      }
    },
    "together/llama-3.3-70b-instruct": {
      "provider_name": "together",
      "model_name": "meta-llama/Llama-3.3-70B-Instruct-Turbo",
      "model_endpoint_type": "together",
      "model_endpoint": "https://api.together.ai/v1",
      "provider_category": "base",
      "context_window": 131072,
      "handle": "together/llama-3.3-70b-instruct",
      "temperature": 0.7,
      "max_tokens": 4096,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": true,
        "Token Streaming": true,
        "Multimodal": false
      }
    },
    "together/Qwen/Qwen3-235B-A22B-fp8-tput": {
      "provider_name": "together",
      "model_name": "Qwen/Qwen3-235B-A22B-fp8-tput",
      "model_endpoint_type": "together",
      "model_endpoint": "https://api.together.ai/v1",
      "provider_category": "base",
      "context_window": 40960,
      "handle": "together/Qwen/Qwen3-235B-A22B-fp8-tput",
      "temperature": 0.7,
      "max_tokens": 4096,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": true,
        "Multimodal": false
      }
    },
    "together/Qwen/Qwen2.5-Coder-32B-Instruct": {
      "provider_name": "together",
      "model_name": "Qwen/Qwen2.5-Coder-32B-Instruct",
      "model_endpoint_type": "together",
      "model_endpoint": "https://api.together.ai/v1",
      "provider_category": "base",
      "context_window": 32768,
      "handle": "together/Qwen/Qwen2.5-Coder-32B-Instruct",
      "temperature": 0.7,
      "max_tokens": 4096,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": true,
        "Token Streaming": true,
        "Multimodal": false
      }
    },
    "together/togethercomputer/MoA-1": {
      "provider_name": "together",
      "model_name": "togethercomputer/MoA-1",
      "model_endpoint_type": "together",
      "model_endpoint": "https://api.together.ai/v1",
      "provider_category": "base",
      "context_window": 32768,
      "handle": "together/togethercomputer/MoA-1",
      "temperature": 0.7,
      "max_tokens": 4096,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": false,
        "Multimodal": false
      }
    },
    "together/llama-3-70b-instruct": {
      "provider_name": "together",
      "model_name": "meta-llama/Meta-Llama-3-70B-Instruct-Turbo",
      "model_endpoint_type": "together",
      "model_endpoint": "https://api.together.ai/v1",
      "provider_category": "base",
      "context_window": 8192,
      "handle": "together/llama-3-70b-instruct",
      "temperature": 0.7,
      "max_tokens": 4096,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": false,
        "Multimodal": false
      }
    },
    "together/arcee-ai/AFM-4.5B-Preview": {
      "provider_name": "together",
      "model_name": "arcee-ai/AFM-4.5B-Preview",
      "model_endpoint_type": "together",
      "model_endpoint": "https://api.together.ai/v1",
      "provider_category": "base",
      "context_window": 65536,
      "handle": "together/arcee-ai/AFM-4.5B-Preview",
      "temperature": 0.7,
      "max_tokens": 4096,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": false,
        "Multimodal": false
      }
    },
    "together/deepseek-ai/DeepSeek-V3": {
      "provider_name": "together",
      "model_name": "deepseek-ai/DeepSeek-V3",
      "model_endpoint_type": "together",
      "model_endpoint": "https://api.together.ai/v1",
      "provider_category": "base",
      "context_window": 131072,
      "handle": "together/deepseek-ai/DeepSeek-V3",
      "temperature": 0.7,
      "max_tokens": 4096,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": true,
        "Token Streaming": false,
        "Multimodal": false
      }
    },
    "together/lgai/exaone-3-5-32b-instruct": {
      "provider_name": "together",
      "model_name": "lgai/exaone-3-5-32b-instruct",
      "model_endpoint_type": "together",
      "model_endpoint": "https://api.together.ai/v1",
      "provider_category": "base",
      "context_window": 32768,
      "handle": "together/lgai/exaone-3-5-32b-instruct",
      "temperature": 0.7,
      "max_tokens": 4096,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": false,
        "Multimodal": false
      }
    },
    "together/deepseek-ai/DeepSeek-R1-0528-tput": {
      "provider_name": "together",
      "model_name": "deepseek-ai/DeepSeek-R1-0528-tput",
      "model_endpoint_type": "together",
      "model_endpoint": "https://api.together.ai/v1",
      "provider_category": "base",
      "context_window": 163840,
      "handle": "together/deepseek-ai/DeepSeek-R1-0528-tput",
      "temperature": 0.7,
      "max_tokens": 4096,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": false,
        "Multimodal": false
      }
    },
    "together/mixtral-8x7b-instruct": {
      "provider_name": "together",
      "model_name": "mistralai/Mixtral-8x7B-Instruct-v0.1",
      "model_endpoint_type": "together",
      "model_endpoint": "https://api.together.ai/v1",
      "provider_category": "base",
      "context_window": 32768,
      "handle": "together/mixtral-8x7b-instruct",
      "temperature": 0.7,
      "max_tokens": 4096,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": false,
        "Multimodal": false
      }
    },
    "together/meta-llama/Llama-4-Scout-17B-16E-Instruct": {
      "provider_name": "together",
      "model_name": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
      "model_endpoint_type": "together",
      "model_endpoint": "https://api.together.ai/v1",
      "provider_category": "base",
      "context_window": 1048576,
      "handle": "together/meta-llama/Llama-4-Scout-17B-16E-Instruct",
      "temperature": 0.7,
      "max_tokens": 4096,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": true,
        "Multimodal": true
      }
    },
    "together/meta-llama/Llama-Vision-Free": {
      "provider_name": "together",
      "model_name": "meta-llama/Llama-Vision-Free",
      "model_endpoint_type": "together",
      "model_endpoint": "https://api.together.ai/v1",
      "provider_category": "base",
      "context_window": 131072,
      "handle": "together/meta-llama/Llama-Vision-Free",
      "temperature": 0.7,
      "max_tokens": 4096,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": false,
        "Multimodal": false
      }
    },
    "together/meta-llama/Llama-3-8b-chat-hf": {
      "provider_name": "together",
      "model_name": "meta-llama/Llama-3-8b-chat-hf",
      "model_endpoint_type": "together",
      "model_endpoint": "https://api.together.ai/v1",
      "provider_category": "base",
      "context_window": 8192,
      "handle": "together/meta-llama/Llama-3-8b-chat-hf",
      "temperature": 0.7,
      "max_tokens": 4096,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": false,
        "Multimodal": false
      }
    },
    "together/mistralai/Mistral-7B-Instruct-v0.1": {
      "provider_name": "together",
      "model_name": "mistralai/Mistral-7B-Instruct-v0.1",
      "model_endpoint_type": "together",
      "model_endpoint": "https://api.together.ai/v1",
      "provider_category": "base",
      "context_window": 32768,
      "handle": "together/mistralai/Mistral-7B-Instruct-v0.1",
      "temperature": 0.7,
      "max_tokens": 4096,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": false,
        "Multimodal": false
      }
    },
    "together/Qwen/Qwen2.5-VL-72B-Instruct": {
      "provider_name": "together",
      "model_name": "Qwen/Qwen2.5-VL-72B-Instruct",
      "model_endpoint_type": "together",
      "model_endpoint": "https://api.together.ai/v1",
      "provider_category": "base",
      "context_window": 32768,
      "handle": "together/Qwen/Qwen2.5-VL-72B-Instruct",
      "temperature": 0.7,
      "max_tokens": 4096,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": false,
        "Multimodal": false
      }
    },
    "together/deepseek-ai/DeepSeek-R1": {
      "provider_name": "together",
      "model_name": "deepseek-ai/DeepSeek-R1",
      "model_endpoint_type": "together",
      "model_endpoint": "https://api.together.ai/v1",
      "provider_category": "base",
      "context_window": 163840,
      "handle": "together/deepseek-ai/DeepSeek-R1",
      "temperature": 0.7,
      "max_tokens": 4096,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": false,
        "Multimodal": false
      }
    },
    "together/togethercomputer/MoA-1-Turbo": {
      "provider_name": "together",
      "model_name": "togethercomputer/MoA-1-Turbo",
      "model_endpoint_type": "together",
      "model_endpoint": "https://api.together.ai/v1",
      "provider_category": "base",
      "context_window": 32768,
      "handle": "together/togethercomputer/MoA-1-Turbo",
      "temperature": 0.7,
      "max_tokens": 4096,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": false,
        "Multimodal": false
      }
    },
    "together/meta-llama/Meta-Llama-3-8B-Instruct-Lite": {
      "provider_name": "together",
      "model_name": "meta-llama/Meta-Llama-3-8B-Instruct-Lite",
      "model_endpoint_type": "together",
      "model_endpoint": "https://api.together.ai/v1",
      "provider_category": "base",
      "context_window": 8192,
      "handle": "together/meta-llama/Meta-Llama-3-8B-Instruct-Lite",
      "temperature": 0.7,
      "max_tokens": 4096,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": false,
        "Multimodal": false
      }
    },
    "together/perplexity-ai/r1-1776": {
      "provider_name": "together",
      "model_name": "perplexity-ai/r1-1776",
      "model_endpoint_type": "together",
      "model_endpoint": "https://api.together.ai/v1",
      "provider_category": "base",
      "context_window": 163840,
      "handle": "together/perplexity-ai/r1-1776",
      "temperature": 0.7,
      "max_tokens": 4096,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": false,
        "Multimodal": true
      }
    },
    "together/mistral-7b-instruct-v2": {
      "provider_name": "together",
      "model_name": "mistralai/Mistral-7B-Instruct-v0.2",
      "model_endpoint_type": "together",
      "model_endpoint": "https://api.together.ai/v1",
      "provider_category": "base",
      "context_window": 32768,
      "handle": "together/mistral-7b-instruct-v2",
      "temperature": 0.7,
      "max_tokens": 4096,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": false,
        "Multimodal": true
      }
    },
    "together/deepseek-ai/DeepSeek-V3-p-dp": {
      "provider_name": "together",
      "model_name": "deepseek-ai/DeepSeek-V3-p-dp",
      "model_endpoint_type": "together",
      "model_endpoint": "https://api.together.ai/v1",
      "provider_category": "base",
      "context_window": 131072,
      "handle": "together/deepseek-ai/DeepSeek-V3-p-dp",
      "temperature": 0.7,
      "max_tokens": 4096,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": false,
        "Multimodal": false
      }
    },
    "together/arcee_ai/arcee-spotlight": {
      "provider_name": "together",
      "model_name": "arcee_ai/arcee-spotlight",
      "model_endpoint_type": "together",
      "model_endpoint": "https://api.together.ai/v1",
      "provider_category": "base",
      "context_window": 131072,
      "handle": "together/arcee_ai/arcee-spotlight",
      "temperature": 0.7,
      "max_tokens": 4096,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": false,
        "Multimodal": false
      }
    },
    "together/Qwen/Qwen2-72B-Instruct": {
      "provider_name": "together",
      "model_name": "Qwen/Qwen2-72B-Instruct",
      "model_endpoint_type": "together",
      "model_endpoint": "https://api.together.ai/v1",
      "provider_category": "base",
      "context_window": 32768,
      "handle": "together/Qwen/Qwen2-72B-Instruct",
      "temperature": 0.7,
      "max_tokens": 4096,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": false,
        "Multimodal": false
      }
    },
    "together/mistral-7b-instruct-v3": {
      "provider_name": "together",
      "model_name": "mistralai/Mistral-7B-Instruct-v0.3",
      "model_endpoint_type": "together",
      "model_endpoint": "https://api.together.ai/v1",
      "provider_category": "base",
      "context_window": 32768,
      "handle": "together/mistral-7b-instruct-v3",
      "temperature": 0.7,
      "max_tokens": 4096,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": false,
        "Multimodal": false
      }
    },
    "together/hermes-2-mixtral": {
      "provider_name": "together",
      "model_name": "NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO",
      "model_endpoint_type": "together",
      "model_endpoint": "https://api.together.ai/v1",
      "provider_category": "base",
      "context_window": 32768,
      "handle": "together/hermes-2-mixtral",
      "temperature": 0.7,
      "max_tokens": 4096,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": false,
        "Multimodal": true
      }
    },
    "together/meta-llama/Llama-3.2-11B-Vision-Instruct-Turbo": {
      "provider_name": "together",
      "model_name": "meta-llama/Llama-3.2-11B-Vision-Instruct-Turbo",
      "model_endpoint_type": "together",
      "model_endpoint": "https://api.together.ai/v1",
      "provider_category": "base",
      "context_window": 131072,
      "handle": "together/meta-llama/Llama-3.2-11B-Vision-Instruct-Turbo",
      "temperature": 0.7,
      "max_tokens": 4096,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": false,
        "Multimodal": false
      }
    },
    "together/google/gemma-2-27b-it": {
      "provider_name": "together",
      "model_name": "google/gemma-2-27b-it",
      "model_endpoint_type": "together",
      "model_endpoint": "https://api.together.ai/v1",
      "provider_category": "base",
      "context_window": 8192,
      "handle": "together/google/gemma-2-27b-it",
      "temperature": 0.7,
      "max_tokens": 4096,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": false,
        "Multimodal": false
      }
    },
    "together/togethercomputer/Refuel-Llm-V2-Small": {
      "provider_name": "together",
      "model_name": "togethercomputer/Refuel-Llm-V2-Small",
      "model_endpoint_type": "together",
      "model_endpoint": "https://api.together.ai/v1",
      "provider_category": "base",
      "context_window": 8192,
      "handle": "together/togethercomputer/Refuel-Llm-V2-Small",
      "temperature": 0.7,
      "max_tokens": 4096,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": false,
        "Multimodal": false
      }
    },
    "together/Qwen/Qwen2-VL-72B-Instruct": {
      "provider_name": "together",
      "model_name": "Qwen/Qwen2-VL-72B-Instruct",
      "model_endpoint_type": "together",
      "model_endpoint": "https://api.together.ai/v1",
      "provider_category": "base",
      "context_window": 32768,
      "handle": "together/Qwen/Qwen2-VL-72B-Instruct",
      "temperature": 0.7,
      "max_tokens": 4096,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": false,
        "Multimodal": false
      }
    },
    "together/meta-llama/Llama-3.2-90B-Vision-Instruct-Turbo": {
      "provider_name": "together",
      "model_name": "meta-llama/Llama-3.2-90B-Vision-Instruct-Turbo",
      "model_endpoint_type": "together",
      "model_endpoint": "https://api.together.ai/v1",
      "provider_category": "base",
      "context_window": 131072,
      "handle": "together/meta-llama/Llama-3.2-90B-Vision-Instruct-Turbo",
      "temperature": 0.7,
      "max_tokens": 4096,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": false,
        "Multimodal": false
      }
    },
    "together/scb10x/scb10x-llama3-1-typhoon2-70b-instruct": {
      "provider_name": "together",
      "model_name": "scb10x/scb10x-llama3-1-typhoon2-70b-instruct",
      "model_endpoint_type": "together",
      "model_endpoint": "https://api.together.ai/v1",
      "provider_category": "base",
      "context_window": 8192,
      "handle": "together/scb10x/scb10x-llama3-1-typhoon2-70b-instruct",
      "temperature": 0.7,
      "max_tokens": 4096,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": true,
        "Multimodal": false
      }
    },
    "together/arcee-ai/maestro-reasoning": {
      "provider_name": "together",
      "model_name": "arcee-ai/maestro-reasoning",
      "model_endpoint_type": "together",
      "model_endpoint": "https://api.together.ai/v1",
      "provider_category": "base",
      "context_window": 131072,
      "handle": "together/arcee-ai/maestro-reasoning",
      "temperature": 0.7,
      "max_tokens": 4096,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": false,
        "Multimodal": false
      }
    },
    "together/togethercomputer/Refuel-Llm-V2": {
      "provider_name": "together",
      "model_name": "togethercomputer/Refuel-Llm-V2",
      "model_endpoint_type": "together",
      "model_endpoint": "https://api.together.ai/v1",
      "provider_category": "base",
      "context_window": 16384,
      "handle": "together/togethercomputer/Refuel-Llm-V2",
      "temperature": 0.7,
      "max_tokens": 4096,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": false,
        "Multimodal": false
      }
    },
    "together/meta-llama/Llama-3.2-3B-Instruct-Turbo": {
      "provider_name": "together",
      "model_name": "meta-llama/Llama-3.2-3B-Instruct-Turbo",
      "model_endpoint_type": "together",
      "model_endpoint": "https://api.together.ai/v1",
      "provider_category": "base",
      "context_window": 131072,
      "handle": "together/meta-llama/Llama-3.2-3B-Instruct-Turbo",
      "temperature": 0.7,
      "max_tokens": 4096,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": false,
        "Multimodal": false
      }
    },
    "together/arcee-ai/virtuoso-medium-v2": {
      "provider_name": "together",
      "model_name": "arcee-ai/virtuoso-medium-v2",
      "model_endpoint_type": "together",
      "model_endpoint": "https://api.together.ai/v1",
      "provider_category": "base",
      "context_window": 131072,
      "handle": "together/arcee-ai/virtuoso-medium-v2",
      "temperature": 0.7,
      "max_tokens": 4096,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": true,
        "Multimodal": true
      }
    },
    "together/arcee-ai/coder-large": {
      "provider_name": "together",
      "model_name": "arcee-ai/coder-large",
      "model_endpoint_type": "together",
      "model_endpoint": "https://api.together.ai/v1",
      "provider_category": "base",
      "context_window": 32768,
      "handle": "together/arcee-ai/coder-large",
      "temperature": 0.7,
      "max_tokens": 4096,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": true,
        "Token Streaming": true,
        "Multimodal": true
      }
    },
    "together/deepseek-ai/DeepSeek-R1-Distill-Qwen-14B": {
      "provider_name": "together",
      "model_name": "deepseek-ai/DeepSeek-R1-Distill-Qwen-14B",
      "model_endpoint_type": "together",
      "model_endpoint": "https://api.together.ai/v1",
      "provider_category": "base",
      "context_window": 131072,
      "handle": "together/deepseek-ai/DeepSeek-R1-Distill-Qwen-14B",
      "temperature": 0.7,
      "max_tokens": 4096,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": false,
        "Multimodal": false
      }
    },
    "together/arcee-ai/virtuoso-large": {
      "provider_name": "together",
      "model_name": "arcee-ai/virtuoso-large",
      "model_endpoint_type": "together",
      "model_endpoint": "https://api.together.ai/v1",
      "provider_category": "base",
      "context_window": 131072,
      "handle": "together/arcee-ai/virtuoso-large",
      "temperature": 0.7,
      "max_tokens": 4096,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": true,
        "Multimodal": true
      }
    },
    "together/qwen-2.5-72b-instruct": {
      "provider_name": "together",
      "model_name": "Qwen/Qwen2.5-72B-Instruct-Turbo",
      "model_endpoint_type": "together",
      "model_endpoint": "https://api.together.ai/v1",
      "provider_category": "base",
      "context_window": 131072,
      "handle": "together/qwen-2.5-72b-instruct",
      "temperature": 0.7,
      "max_tokens": 4096,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": true,
        "Multimodal": true
      }
    },
    "together/llama-3-70b": {
      "provider_name": "together",
      "model_name": "meta-llama/Llama-3-70b-chat-hf",
      "model_endpoint_type": "together",
      "model_endpoint": "https://api.together.ai/v1",
      "provider_category": "base",
      "context_window": 8192,
      "handle": "together/llama-3-70b",
      "temperature": 0.7,
      "max_tokens": 4096,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": false,
        "Multimodal": false
      }
    },
    "together/deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B": {
      "provider_name": "together",
      "model_name": "deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B",
      "model_endpoint_type": "together",
      "model_endpoint": "https://api.together.ai/v1",
      "provider_category": "base",
      "context_window": 131072,
      "handle": "together/deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B",
      "temperature": 0.7,
      "max_tokens": 4096,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": false,
        "Multimodal": false
      }
    },
    "together/deepseek-ai/DeepSeek-R1-Distill-Llama-70B": {
      "provider_name": "together",
      "model_name": "deepseek-ai/DeepSeek-R1-Distill-Llama-70B",
      "model_endpoint_type": "together",
      "model_endpoint": "https://api.together.ai/v1",
      "provider_category": "base",
      "context_window": 131072,
      "handle": "together/deepseek-ai/DeepSeek-R1-Distill-Llama-70B",
      "temperature": 0.7,
      "max_tokens": 4096,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": false,
        "Multimodal": false
      }
    },
    "together/nvidia/Llama-3.1-Nemotron-70B-Instruct-HF": {
      "provider_name": "together",
      "model_name": "nvidia/Llama-3.1-Nemotron-70B-Instruct-HF",
      "model_endpoint_type": "together",
      "model_endpoint": "https://api.together.ai/v1",
      "provider_category": "base",
      "context_window": 32768,
      "handle": "together/nvidia/Llama-3.1-Nemotron-70B-Instruct-HF",
      "temperature": 0.7,
      "max_tokens": 4096,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": true,
        "Multimodal": false
      }
    },
    "together/Qwen/QwQ-32B": {
      "provider_name": "together",
      "model_name": "Qwen/QwQ-32B",
      "model_endpoint_type": "together",
      "model_endpoint": "https://api.together.ai/v1",
      "provider_category": "base",
      "context_window": 131072,
      "handle": "together/Qwen/QwQ-32B",
      "temperature": 0.7,
      "max_tokens": 4096,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": false,
        "Multimodal": true
      }
    },
    "together/deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free": {
      "provider_name": "together",
      "model_name": "deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free",
      "model_endpoint_type": "together",
      "model_endpoint": "https://api.together.ai/v1",
      "provider_category": "base",
      "context_window": 8192,
      "handle": "together/deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free",
      "temperature": 0.7,
      "max_tokens": 4096,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": false,
        "Multimodal": false
      }
    },
    "together/mistralai/Mistral-Small-24B-Instruct-2501": {
      "provider_name": "together",
      "model_name": "mistralai/Mistral-Small-24B-Instruct-2501",
      "model_endpoint_type": "together",
      "model_endpoint": "https://api.together.ai/v1",
      "provider_category": "base",
      "context_window": 32768,
      "handle": "together/mistralai/Mistral-Small-24B-Instruct-2501",
      "temperature": 0.7,
      "max_tokens": 4096,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": false,
        "Multimodal": false
      }
    },
    "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8": {
      "provider_name": "together",
      "model_name": "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8",
      "model_endpoint_type": "together",
      "model_endpoint": "https://api.together.ai/v1",
      "provider_category": "base",
      "context_window": 1048576,
      "handle": "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8",
      "temperature": 0.7,
      "max_tokens": 4096,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": true,
        "Token Streaming": true,
        "Multimodal": true
      }
    },
    "together/Qwen/Qwen2.5-7B-Instruct-Turbo": {
      "provider_name": "together",
      "model_name": "Qwen/Qwen2.5-7B-Instruct-Turbo",
      "model_endpoint_type": "together",
      "model_endpoint": "https://api.together.ai/v1",
      "provider_category": "base",
      "context_window": 32768,
      "handle": "together/Qwen/Qwen2.5-7B-Instruct-Turbo",
      "temperature": 0.7,
      "max_tokens": 4096,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": false,
        "Multimodal": false
      }
    },
    "together/llama-3.1-70b-instruct": {
      "provider_name": "together",
      "model_name": "meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo",
      "model_endpoint_type": "together",
      "model_endpoint": "https://api.together.ai/v1",
      "provider_category": "base",
      "context_window": 131072,
      "handle": "together/llama-3.1-70b-instruct",
      "temperature": 0.7,
      "max_tokens": 4096,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": true,
        "Token Streaming": false,
        "Multimodal": false
      }
    },
    "together/llama-3.1-405b-instruct": {
      "provider_name": "together",
      "model_name": "meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo",
      "model_endpoint_type": "together",
      "model_endpoint": "https://api.together.ai/v1",
      "provider_category": "base",
      "context_window": 130815,
      "handle": "together/llama-3.1-405b-instruct",
      "temperature": 0.7,
      "max_tokens": 4096,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": true,
        "Token Streaming": true,
        "Multimodal": false
      }
    },
    "together/scb10x/scb10x-typhoon-2-1-gemma3-12b": {
      "provider_name": "together",
      "model_name": "scb10x/scb10x-typhoon-2-1-gemma3-12b",
      "model_endpoint_type": "together",
      "model_endpoint": "https://api.together.ai/v1",
      "provider_category": "base",
      "context_window": 131072,
      "handle": "together/scb10x/scb10x-typhoon-2-1-gemma3-12b",
      "temperature": 0.7,
      "max_tokens": 4096,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": false,
        "Multimodal": false
      }
    },
    "together/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo": {
      "provider_name": "together",
      "model_name": "meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo",
      "model_endpoint_type": "together",
      "model_endpoint": "https://api.together.ai/v1",
      "provider_category": "base",
      "context_window": 131072,
      "handle": "together/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo",
      "temperature": 0.7,
      "max_tokens": 4096,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": true,
        "Token Streaming": true,
        "Multimodal": false
      }
    },
    "together/arcee-ai/caller": {
      "provider_name": "together",
      "model_name": "arcee-ai/caller",
      "model_endpoint_type": "together",
      "model_endpoint": "https://api.together.ai/v1",
      "provider_category": "base",
      "context_window": 32768,
      "handle": "together/arcee-ai/caller",
      "temperature": 0.7,
      "max_tokens": 4096,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": false,
        "Multimodal": false
      }
    },
    "together/lgai/exaone-deep-32b": {
      "provider_name": "together",
      "model_name": "lgai/exaone-deep-32b",
      "model_endpoint_type": "together",
      "model_endpoint": "https://api.together.ai/v1",
      "provider_category": "base",
      "context_window": 32768,
      "handle": "together/lgai/exaone-deep-32b",
      "temperature": 0.7,
      "max_tokens": 4096,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": false,
        "Multimodal": false
      }
    },
    "together/google/gemma-3n-E4B-it": {
      "provider_name": "together",
      "model_name": "google/gemma-3n-E4B-it",
      "model_endpoint_type": "together",
      "model_endpoint": "https://api.together.ai/v1",
      "provider_category": "base",
      "context_window": 32768,
      "handle": "together/google/gemma-3n-E4B-it",
      "temperature": 0.7,
      "max_tokens": 4096,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": false,
        "Multimodal": true
      }
    },
    "together/arcee-ai/arcee-blitz": {
      "provider_name": "together",
      "model_name": "arcee-ai/arcee-blitz",
      "model_endpoint_type": "together",
      "model_endpoint": "https://api.together.ai/v1",
      "provider_category": "base",
      "context_window": 32768,
      "handle": "together/arcee-ai/arcee-blitz",
      "temperature": 0.7,
      "max_tokens": 4096,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": false,
        "Multimodal": false
      }
    },
    "together/meta-llama/Llama-3.3-70B-Instruct-Turbo-Free": {
      "provider_name": "together",
      "model_name": "meta-llama/Llama-3.3-70B-Instruct-Turbo-Free",
      "model_endpoint_type": "together",
      "model_endpoint": "https://api.together.ai/v1",
      "provider_category": "base",
      "context_window": 131072,
      "handle": "together/meta-llama/Llama-3.3-70B-Instruct-Turbo-Free",
      "temperature": 0.7,
      "max_tokens": 4096,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": true,
        "Token Streaming": true,
        "Multimodal": false
      }
    },
    "openai-proxy/deepseek-chat": {
      "provider_name": "deepseek",
      "model_name": "deepseek-chat",
      "model_endpoint_type": "openai",
      "model_endpoint": "https://api.deepseek.com/v1",
      "provider_category": "base",
      "context_window": 64000,
      "handle": "openai-proxy/deepseek-chat",
      "temperature": 0.7,
      "max_tokens": 4096,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": false,
        "Multimodal": false
      }
    },
    "openai-proxy/deepseek-reasoner": {
      "provider_name": "deepseek",
      "model_name": "deepseek-reasoner",
      "model_endpoint_type": "openai",
      "model_endpoint": "https://api.deepseek.com/v1",
      "provider_category": "base",
      "context_window": 64000,
      "handle": "openai-proxy/deepseek-reasoner",
      "temperature": 0.7,
      "max_tokens": 4096,
      "last_scanned": "2025-06-27",
      "capabilities": {
        "Basic": false,
        "Token Streaming": false,
        "Multimodal": false
      }
    }
  }
}
