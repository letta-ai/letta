name: Reusable Test Workflow

on:
  workflow_call:
    inputs:
      test-type:
        description: 'Type of tests to run (unit, integration, docker, send-message)'
        required: true
        type: string
      poetry-core-directory:
        description: 'Working directory for commands. Defaults to apps/core and expects poetry functionality.'
        required: false
        type: string
        default: 'apps/core'
      install-args:
        description: 'Poetry install arguments'
        required: true
        type: string
      test-command:
        description: 'Command to run tests'
        required: false
        type: string
        default: 'poetry run pytest -svv'
      test-path-prefix:
        description: 'Prefix for test path (e.g., tests/)'
        required: false
        type: string
        default: 'tests/'
      timeout-minutes:
        description: 'Timeout in minutes'
        required: false
        type: number
        default: 15
      runner:
        description: 'Runner to use'
        required: false
        type: string
        default: '["self-hosted", "medium"]'
      matrix-strategy:
        description: 'JSON string for matrix strategy'
        required: false
        type: string
        default: '{}'
      changed-files-pattern:
        description: 'Pattern for changed files detection'
        required: false
        type: string
        default: |
          apps/core/**
          .github/workflows/*.yml
      skip-fern-generation:
        description: 'Skip Fern SDK generation'
        required: false
        type: boolean
        default: false
      use-docker:
        description: 'Use Docker for tests'
        required: false
        type: boolean
        default: false
      ref:
        description: 'Git ref to wait for checks on'
        required: false
        type: string
        default: ${{ github.sha }}

jobs:
  changed-files:
    runs-on: ${{ fromJSON(inputs.runner) }}
    name: changed-files
    outputs:
      all_changed_files: ${{ steps.changed-files.outputs.all_changed_files }}
      any_changed: ${{ steps.changed-files.outputs.any_changed }}
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0
      - name: Get changed files
        id: changed-files
        uses: tj-actions/changed-files@v46.0.4
        with:
          files: ${{ inputs.changed-files-pattern }}

  test-run:
    needs: [changed-files]
    if: |
      needs.changed-files.outputs.any_changed == 'true'
    runs-on: ${{ fromJSON(inputs.runner) }}
    timeout-minutes: ${{ inputs.timeout-minutes }}
    strategy: ${{ fromJSON(inputs.matrix-strategy) }}

    services:
      postgres:
        image: pgvector/pgvector:pg17
        ports:
          # avoids conflict with docker postgres
          - ${{ inputs.use-docker && '9999:5432' || '5432:5432' }}
        env:
          POSTGRES_HOST_AUTH_METHOD: trust
          POSTGRES_DB: postgres
          POSTGRES_USER: postgres
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Debug ref information
        run: |
          echo "Input ref: ${{ inputs.ref }}"
          echo "GitHub SHA: ${{ github.sha }}"
          echo "GitHub ref: ${{ github.ref }}"
          echo "PR head SHA: ${{ github.event.pull_request.head.sha }}"
          echo "Event name: ${{ github.event_name }}"

      - name: Wait for Preview SDK workflow
        if: inputs.skip-fern-generation != true || (!contains(needs.changed-files.outputs.all_changed_files, 'apps/fern/openapi.json') && !contains(needs.changed-files.outputs.all_changed_files, 'apps/fern/openapi-overrides.yml'))
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          echo "Waiting for 'preview-python-sdk' check to complete on ref: ${{ inputs.ref }}"

          # Wait for the check to complete with timeout
          timeout_seconds=1800
          interval_seconds=10
          elapsed=0

          while [ $elapsed -lt $timeout_seconds ]; do
            echo "Checking status... (elapsed: ${elapsed}s)"

            # Get check runs using pr checks syntax with branch name or PR number
            if [ "${{ github.event_name }}" = "pull_request" ]; then
              pr_identifier="${{ github.event.pull_request.number }}"
            else
              pr_identifier="${{ github.ref_name }}"
            fi

            check_info=$(gh pr checks "$pr_identifier" -R ${{ github.repository }} --json name,state,startedAt \
              | jq -r '.[] | select(.name == "preview-python-sdk") | [.startedAt, .state] | @tsv' | sort -r | head -1 | cut -f2)

            if [ -n "$check_info" ]; then
              echo "Check state: $check_info"

              if [ "$check_info" = "SUCCESS" ] || [ "$check_info" = "FAILURE" ] || [ "$check_info" = "SKIPPED" ] || [ "$check_info" = "CANCELLED" ]; then
                echo "Check completed with state: $check_info"
                exit 0
              fi
            else
              echo "Check 'preview-python-sdk' not found yet"
            fi

            sleep $interval_seconds
            elapsed=$((elapsed + interval_seconds))
          done

          echo "Timeout waiting for check to complete"
          exit 1

      - name: Generate cache key
        if: inputs.skip-fern-generation != true || (!contains(needs.changed-files.outputs.all_changed_files, 'apps/fern/openapi.json') && !contains(needs.changed-files.outputs.all_changed_files, 'apps/fern/openapi-overrides.yml'))
        id: cache-key
        run: |
          echo "key=sdk-${{ github.ref_name }}-${{ hashFiles('apps/fern/*', 'apps/core/pyproject.toml') }}" >> $GITHUB_OUTPUT

      - name: Restore SDK cache
        # skip if "skip-fern-generation" is true or if the upstream workflow would've generated an sdk preview (changes to openapi files)
        if: inputs.skip-fern-generation != true || (!contains(needs.changed-files.outputs.all_changed_files, 'apps/fern/openapi.json') && !contains(needs.changed-files.outputs.all_changed_files, 'apps/fern/openapi-overrides.yml'))
        uses: actions/cache/restore@v4
        with:
          path: |
            apps/fern/.preview/fern-python-sdk/
          key: ${{ steps.cache-key.outputs.key }}
          fail-on-cache-miss: true

      - name: Install dependencies
        shell: bash
        working-directory: ${{ inputs.poetry-core-directory }}
        run: |
          poetry install --no-interaction --no-root ${{ inputs.install-args }}

      - name: Install custom SDK
        if: inputs.skip-fern-generation != true
        working-directory: ${{ inputs.poetry-core-directory }}
        run: |
          poetry run pip install -e ../fern/.preview/fern-python-sdk/.

      - name: Migrate database
        if: inputs.use-docker != true
        working-directory: ${{ inputs.poetry-core-directory }}
        env:
          LETTA_PG_PORT: 5432
          LETTA_PG_USER: postgres
          LETTA_PG_PASSWORD: postgres
          LETTA_PG_DB: postgres
          LETTA_PG_HOST: localhost
        run: |
          psql -h localhost -U postgres -d postgres -c 'CREATE EXTENSION vector'
          poetry run alembic upgrade head
      - name: Inject env vars into environment
        working-directory: ${{ inputs.poetry-core-directory }}
        run: |
          # Get secrets and mask them before adding to environment
          while IFS= read -r line || [[ -n "$line" ]]; do
            if [[ -n "$line" ]]; then
              value=$(echo "$line" | cut -d= -f2-)
              echo "::add-mask::$value"
              echo "$line" >> $GITHUB_ENV
            fi
          done < <(letta_secrets_helper --env dev --service ci)

      - name: Docker setup for Docker tests
        if: inputs.use-docker
        run: |
          mkdir -p /home/ci-runner/.letta/logs
          sudo chown -R $USER:$USER /home/ci-runner/.letta/logs
          chmod -R 755 /home/ci-runner/.letta/logs

      - name: Build and run docker dev server
        if: inputs.use-docker
        env:
          LETTA_PG_DB: letta
          LETTA_PG_USER: letta
          LETTA_PG_PASSWORD: letta
          LETTA_PG_PORT: 5432
          OPENAI_API_KEY: ${{ env.OPENAI_API_KEY }}
        run: |
          cd libs/config-core-deploy
          docker compose -f compose.yaml up --build -d

      - name: Wait for Docker service
        if: inputs.use-docker
        working-directory: ${{ inputs.poetry-core-directory }}
        run: |
          bash scripts/wait_for_service.sh localhost:8083 -- echo "Service is ready"

      - name: Run tests
        working-directory: ${{ inputs.poetry-core-directory }}
        env:
          # Database configuration (shared, but values depend on Docker usage)
          LETTA_PG_PORT: 5432
          LETTA_PG_USER: ${{ inputs.use-docker && 'letta' || 'postgres' }}
          LETTA_PG_PASSWORD: ${{ inputs.use-docker && 'letta' || 'postgres' }}
          LETTA_PG_DB: ${{ inputs.use-docker && 'letta' || 'postgres' }}
          LETTA_PG_HOST: localhost

          # Server configuration (conditional)
          LETTA_SERVER_PASS: test_server_token

          # LLM Provider API Keys (shared across all test types)
          OPENAI_API_KEY: ${{ env.OPENAI_API_KEY }}
          ANTHROPIC_API_KEY: ${{ env.ANTHROPIC_API_KEY }}
          GEMINI_API_KEY: ${{ env.GEMINI_API_KEY }}
          GROQ_API_KEY: ${{ env.GROQ_API_KEY }}
          AZURE_API_KEY: ${{ env.AZURE_API_KEY }}
          AZURE_BASE_URL: ${{ secrets.AZURE_BASE_URL }}
          DEEPSEEK_API_KEY: ${{ env.DEEPSEEK_API_KEY }}
          LETTA_MISTRAL_API_KEY: ${{ secrets.LETTA_MISTRAL_API_KEY }}

          # External service API Keys (shared across all test types)
          COMPOSIO_API_KEY: ${{ env.COMPOSIO_API_KEY }}
          E2B_API_KEY: ${{ env.E2B_API_KEY }}
          E2B_SANDBOX_TEMPLATE_ID: ${{ env.E2B_SANDBOX_TEMPLATE_ID }}
          TAVILY_API_KEY: ${{ secrets.TAVILY_API_KEY }}
          PINECONE_API_KEY: ${{ secrets.PINECONE_API_KEY }}
          PINECONE_INDEX_HOST: ${{ secrets.PINECONE_INDEX_HOST }}
          PINECONE_NAMESPACE: ${{ secrets.PINECONE_NAMESPACE }}

          # Google Cloud (shared across all test types)
          GOOGLE_CLOUD_PROJECT: ${{ secrets.GOOGLE_CLOUD_PROJECT }}
          GOOGLE_CLOUD_LOCATION: ${{ secrets.GOOGLE_CLOUD_LOCATION }}

          # Feature flags (shared across all test types)
          LETTA_ENABLE_BATCH_JOB_POLLING: true
          LETTA_USE_EXPERIMENTAL: ${{ secrets.LETTA_USE_EXPERIMENTAL }}

          # Docker-specific environment variables
          PYTHONPATH: ${{ inputs.use-docker && format('{0}:{1}', github.workspace, env.PYTHONPATH) || '' }}
        run: |
          set -o xtrace

          # Set LETTA_SERVER_URL only for Docker tests
          if [[ "${{ inputs.use-docker }}" == "true" ]]; then
            export LETTA_SERVER_URL="http://localhost:8083"
          fi

          # Set LLM_CONFIG_FILE only for send-message tests
          if [[ "${{ inputs.test-type }}" == "send-message" ]]; then
            export LLM_CONFIG_FILE="${{ matrix.config_file }}"
          fi

          # Handle different matrix variable names and test commands based on test type
          if [[ "${{ inputs.test-type }}" == "integration" ]]; then
            poetry run pip install letta
            poetry run pip show letta
            poetry run pip show letta-client
            poetry run pytest -svv ${{ inputs.test-path-prefix }}${{ matrix.test_suite }}
          elif [[ "${{ inputs.test-type }}" == "unit" ]]; then
            poetry run pip show letta-client
            poetry run pytest -svv ${{ inputs.test-path-prefix }}${{ matrix.test_suite }}
          elif [[ "${{ inputs.test-type }}" == "send-message" ]]; then
            poetry run pytest -s -vv tests/integration_test_send_message.py --maxfail=1 --durations=10
          elif [[ "${{ inputs.test-type }}" == "docker" ]]; then
            poetry run pytest -s tests/test_client.py
          else
            ${{ inputs.test-command }}
          fi

      - name: Print docker logs if tests fail
        if: ${{ (failure() || cancelled()) && inputs.use-docker }}
        working-directory: libs/config-core-deploy
        run: |
          echo "Printing Docker Logs..."
          docker compose -f compose.yaml logs

      - name: Stop docker
        if: ${{ always() && inputs.use-docker }}
        working-directory: libs/config-core-deploy
        run: |
          docker compose -f compose.yaml down --volumes
          sudo rm -rf .persist
