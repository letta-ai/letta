---
title: Archival Memory
subtitle: Long-term semantic storage for agent knowledge
slug: guides/agents/archival-memory
---

## What is archival memory?

Archival memory is a semantically searchable database where agents store facts, knowledge, and information for long-term retrieval. Unlike memory blocks that are always visible, archival memory is queried on-demand when relevant.

**Key characteristics:**
- **Agent-immutable** - Agents cannot easily modify or delete archival memories (though developers can via SDK)
- **Unlimited storage** - No practical size limits
- **Semantic search** - Find information by meaning, not exact keywords
- **Tagged organization** - Agents can categorize memories with tags

**Best for:** Event descriptions, reports, articles, historical records, and reference material that doesn't change frequently.

## When to use archival memory

**Use archival memory for:**
- Document repositories (API docs, technical guides, research papers)
- Conversation logs beyond the context window
- Customer interaction history and support tickets
- Reports, articles, and written content
- Code examples and technical references
- Training materials and educational content
- User research data and feedback
- Historical records and event logs

**Don't use archival memory for:**
- Information that should always be visible → Use memory blocks
- Frequently changing state → Use memory blocks
- Current working memory → Use scratchpad blocks
- Information that needs frequent modification → Use memory blocks

## How agents interact with archival memory

Agents have two primary tools for archival memory: `archival_memory_insert` and `archival_memory_search`.

### Inserting information

Agents can insert memories during conversations:

```python
# Agent inserts after learning something
archival_memory_insert(
    content="Deckard retired six replicants in the off-world colonies before returning to Los Angeles",
    tags=["replicant", "history", "retirement"]
)
```

Developers can also insert programmatically:

<CodeGroup>
```python Python
client.agents.passages.insert(
    agent_id=agent.id,
    content="The Tyrell Corporation's motto: 'More human than human'",
    tags=["company", "motto", "tyrell"]
)
```
```typescript TypeScript
await client.agents.passages.insert(agent.id, {
    content: "The Tyrell Corporation's motto: 'More human than human'",
    tags: ["company", "motto", "tyrell"]
});
```
</CodeGroup>

### Searching for information

```python
# Agent searches semantically
results = archival_memory_search(
    query="replicant lifespan",
    tags=["technical"],  # Optional: filter by tags
    page=0
)
```

Results return semantically relevant information - the agent doesn't need exact keywords.

<Info>
**Search results format:**
Each result contains:
- `content` - The stored text
- `tags` - Associated tags
- `timestamp` - When the memory was created
- `relevance` - Scoring with `rrf_score`, `vector_rank`, `fts_rank`

Letta uses **hybrid search** combining semantic (vector) and keyword (full-text) search, ranked using Reciprocal Rank Fusion (RRF). Higher `rrf_score` means more relevant.
</Info>

## Writing effective queries

Letta uses OpenAI's `text-embedding-3-small` model, which handles natural language questions well. Agents can use various query styles:

**Natural language questions work best:**
```python
archival_memory_search(query="How does the test work?")
# Returns: "The Voight-Kampff test measures involuntary emotional responses..."
```

**Keywords also work:**
```python
archival_memory_search(query="replicant lifespan")
# Returns memories containing both keywords and semantically related concepts
```

**Concept-based queries leverage semantic understanding:**
```python
archival_memory_search(query="artificial memories")
# Returns: "...experimental replicant with implanted memories..."
# (semantic match despite different terminology)
```

<Tip>
**Pagination:** Agents receive multiple results per search. If an agent doesn't paginate correctly, you can instruct it to adjust the `page` parameter or remind it to iterate through results.
</Tip>

### Filtering by time

Agents can search by date ranges:

```python
# Recent memories
archival_memory_search(
    query="test results",
    start_datetime="2025-09-29T00:00:00"
)

# Specific time window
archival_memory_search(
    query="replicant cases",
    start_datetime="2025-09-29T00:00:00",
    end_datetime="2025-09-30T23:59:59"
)
```

<Info>
**Agent datetime awareness:**
- Agents know the current day but not the current time
- Agents can see timestamps of messages they've received
- Agents cannot control insertion timestamps (automatic)
- Developers can backdate memories via SDK with `created_at`
- Time filtering enables queries like "what did we discuss last week?"
</Info>

## Tags and organization

Tags help agents organize and filter archival memories. **Agents always know what tags exist in their archive** since tag lists are compiled into the context window.

**Common tag patterns:**
- `user_info`, `professional`, `personal_history`
- `documentation`, `technical`, `reference`
- `conversation`, `milestone`, `event`
- `company_policy`, `procedure`, `guideline`

**Tag search modes:**
- Match any tag
- Match all tags
- Filter by date ranges

Example of organized tagging:

```python
# Atomic memory with precise tags
archival_memory_insert(
    content="Nexus-6 replicants have a four-year lifespan",
    tags=["technical", "replicant", "nexus-6"]
)

# Later, easy retrieval
archival_memory_search(
    query="how long do replicants live",
    tags=["technical"]
)
```

## Atomic vs comprehensive memories

There are two approaches to storing information in archival memory:

### Atomic approach
Store single, discrete facts:
- "Roy Batty led the replicant group"
- "Rachael is a Nexus-7 prototype with implanted memories"
- "The Voight-Kampff test measures empathic responses"

**Pros:** Precise retrieval, granular tagging
**Cons:** Loses narrative context and relationships

### Comprehensive approach
Store complete narratives:
- "Roy Batty's final monologue: After leading a group of escaped Nexus-6 replicants back to Earth, Roy confronted his creator Eldon Tyrell seeking more life. When Tyrell couldn't extend his lifespan, Roy killed him. In his final moments, Roy saved Deckard's life and delivered the 'Tears in Rain' speech before his four-year lifespan expired."

**Pros:** Maintains context and causal relationships
**Cons:** Harder to retrieve specific facts

### Recommended: Hybrid approach
Store both atomic facts AND comprehensive narratives:
- Atomic memories for precise retrieval ("Roy Batty's lifespan: 4 years")
- Comprehensive memories for context (full narrative of his final scenes)
- Tag both appropriately

This gives you precision when needed and context when relevant.

## Backfilling archives

You can pre-load archival memory with existing knowledge:

<CodeGroup>
```python Python
# Load company policies
policies = [
    "All replicants must undergo Voight-Kampff testing upon arrival",
    "Blade Runner units are authorized to retire rogue replicants",
    "Tyrell Corporation employees must report suspected replicants immediately"
]

for policy in policies:
    client.agents.passages.insert(
        agent_id=agent.id,
        content=policy,
        tags=["policy", "company", "protocol"]
    )

# Load technical documentation
docs = [
    {
        "content": "Nexus-6 replicants: Superior strength, agility, and intelligence. Four-year lifespan prevents emotional development.",
        "tags": ["technical", "nexus-6", "specifications"]
    },
    {
        "content": "Voight-Kampff test: Measures capillary dilation, blush response, and pupil dilation to detect replicants.",
        "tags": ["technical", "testing", "voight-kampff"]
    }
]

for doc in docs:
    client.agents.passages.insert(
        agent_id=agent.id,
        content=doc["content"],
        tags=doc["tags"]
    )
```
```typescript TypeScript
// Load company policies
const policies = [
    "All replicants must undergo Voight-Kampff testing upon arrival",
    "Blade Runner units are authorized to retire rogue replicants",
    "Tyrell Corporation employees must report suspected replicants immediately"
];

for (const policy of policies) {
    await client.agents.passages.insert(agent.id, {
        content: policy,
        tags: ["policy", "company", "protocol"]
    });
}

// Load technical documentation
const docs = [
    {
        content: "Nexus-6 replicants: Superior strength, agility, and intelligence. Four-year lifespan prevents emotional development.",
        tags: ["technical", "nexus-6", "specifications"]
    },
    {
        content: "Voight-Kampff test: Measures capillary dilation, blush response, and pupil dilation to detect replicants.",
        tags: ["technical", "testing", "voight-kampff"]
    }
];

for (const doc of docs) {
    await client.agents.passages.insert(agent.id, {
        content: doc.content,
        tags: doc.tags
    });
}
```
</CodeGroup>

**Use cases for backfilling:**
- Migrating knowledge bases to Letta
- Seeding specialized agents with domain knowledge
- Loading historical conversation logs
- Importing research libraries

## Enforcing archival usage with tool rules

If your agent forgets to use archival memory, you can enforce it with tool rules:

**Force archival search at turn start:**
```
Tool Rule: Start Constraint
Tool: archival_memory_search
```

**Require at least one insertion per turn:**
```
Tool Rule: Required Before Exit
Tool: archival_memory_insert
```

<Warning>
**Note:** Anthropic models don't support strict structured output, so tool rules may not be enforced. Use OpenAI or Gemini models for guaranteed tool rule compliance.
</Warning>

**When to use tool rules:**
- Knowledge management agents that should always search context
- Agents that need to learn from every interaction
- Librarian/archivist agents focused on information storage

**Latency considerations:** Forcing archival search adds a tool call at the start of every turn. For latency-sensitive applications (like customer support), consider making archival search optional.

## Real-world examples

### Example 1: Personal knowledge manager
An agent with 30k+ archival memories tracking:
- Personal preferences and history
- Technical learnings and insights
- Article summaries and research notes
- Conversation highlights

### Example 2: Social media agent
An agent with 32k+ memories tracking interactions:
- User preferences and conversation history
- Common topics and interests
- Interaction patterns and communication styles
- Tags by user, topic, and interaction type

### Example 3: Customer support agent
- Stores ticket resolutions and common issues
- Tags by product, issue type, priority
- Searches archival for similar past issues
- Learns from successful resolutions over time

### Example 4: Research assistant
- Stores paper summaries with key findings
- Tags by topic, methodology, author
- Cross-references related research
- Builds a semantic knowledge graph

## Performance and scale

<Info>
Archival memory has no practical size limits and remains fast at scale:

**Letta Cloud:** Uses [TurboPuffer](https://turbopuffer.com/) for extremely fast semantic search, even with hundreds of thousands of memories.

**Self-hosted:** Uses pgvector (PostgreSQL) for vector search. Performance scales well with proper indexing.

**Letta Desktop:** Uses SQLite with vector search extensions. Suitable for personal use cases.

No matter the backend, archival memory scales to large archives without performance degradation.
</Info>

## Archival memory vs other memory types

| Feature | Memory Blocks | Archival Memory | Conversation Search |
|---------|--------------|-----------------|-------------------|
| **Always visible** | ✅ Yes | ❌ No (searched) | ❌ No (searched) |
| **Search type** | N/A | Semantic | Full-text + semantic |
| **Storage limit** | Character limit | Unlimited | Unlimited |
| **Agent modifiable** | ✅ Full edit control | ❌ Insert + search only | ❌ Search only |
| **SDK modifiable** | ✅ Yes | ✅ Yes | ❌ No |
| **Use case** | Current state | Long-term facts | Past messages |
| **Best for** | Active context | Historical records | Conversation history |

### When to use archival vs conversation search

<Tip>
**Archival memory** is for **intentional** storage:
- Agents decide what's worth remembering long-term
- Used for facts, knowledge, and reference material
- Curated by the agent through active insertion

**Conversation search** is for **historical** retrieval:
- Searches through actual past messages
- Used to recall what was said in previous conversations
- Automatic - no agent curation needed

**Example:**
- User says: "I prefer Python for data science projects"
- **Archival:** Agent inserts "User prefers Python for data science" as a fact
- **Conversation search:** Agent can search for the original message later

Use archival for structured knowledge, conversation search for historical context.
</Tip>

## Embedding models and search quality

Archival search quality depends on the agent's embedding model:

**Letta Cloud:** All agents use `text-embedding-3-small`, which is optimized for most use cases. This model cannot be changed.

**Self-hosted:** Embedding model is pinned to the agent at creation. The default `text-embedding-3-small` is sufficient for nearly all use cases.

### Changing embedding models (self-hosted only)

To change an agent's embedding model, you must:
1. List and export all archival memories
2. Delete all archival memories
3. Update the agent's embedding model
4. Re-insert all memories (they'll be re-embedded)

<Warning>
Changing embedding models is a destructive operation. Export your archival memories first.
</Warning>

## Best practices

<Warning>
**1. Avoid over-insertion**
The most common pitfall is inserting too many memories, creating clutter. Trust the agent to decide what's worth storing long-term.
</Warning>

**2. Track query effectiveness**
If archival search quality matters, have the agent track its performance in a memory block:
```python
# Agent creates a memory block
memory_insert(
    block_label="archival_tracking",
    content="""
    Query patterns: Natural language questions work best
    Recent searches: "test procedures" (3 results), "replicant specs" (5 results)
    Success rate: ~85% of searches return relevant results
    """
)
```

**3. Let agents experiment**
Agents can test different query styles to understand what works:
```python
# Agent tries variations
archival_memory_search(query="How does the Voight-Kampff test work?")
archival_memory_search(query="Voight-Kampff procedure")
archival_memory_search(query="replicant detection method")
```

**Important:** Have the agent persist learnings from experimentation in a memory block, not in archival (avoid meta-clutter).

**4. Use tags consistently**
Establish a tag taxonomy and stick to it. Good language models typically handle tagging well.

**5. Use the hybrid approach**
Store both atomic facts and comprehensive narratives when dealing with complex information.

**6. Add context to insertions**
❌ Don't: "Likes replicants"
✅ Do: "Deckard shows unusual empathy toward replicants, particularly Rachael, suggesting possible replicant identity"

**7. Pre-load domain knowledge**
For specialized agents, seed archival with relevant information upfront via backfilling.

**8. Consider latency**
Forced archival search adds overhead. For real-time applications, make it optional or use it selectively.

## Advanced: Archival performance tracking

Build self-improving agents by having them track archival effectiveness:

<CodeGroup>
```python Python
# Create a memory block
client.blocks.create(
    label="archival_performance",
    value="""
    Frequently searched topics: [replicant specifications, test protocols, case histories]
    Success rate: ~85% (queries return relevant results)
    Common patterns: Queries about technical specs, protocol requirements, historical cases
    Improvements needed: Better atomic granularity for technical specifications
    Tag usage: technical (450), case_history (120), protocol (89)
    """
)
```
```typescript TypeScript
// Create a memory block
await client.blocks.create({
    label: "archival_performance",
    value: `
    Frequently searched topics: [replicant specifications, test protocols, case histories]
    Success rate: ~85% (queries return relevant results)
    Common patterns: Queries about technical specs, protocol requirements, historical cases
    Improvements needed: Better atomic granularity for technical specifications
    Tag usage: technical (450), case_history (120), protocol (89)
    `
});
```
</CodeGroup>

The agent can update this block based on search results and refine its archival strategy over time.

## Modifying archival memories (SDK only)

While agents cannot modify archival memories, developers can update or delete them via the SDK:

<CodeGroup>
```python Python
# Update a memory
client.agents.passages.update(
    agent_id=agent.id,
    passage_id=passage.id,
    content="Updated content",
    tags=["new", "tags"]
)

# Delete a memory
client.agents.passages.delete(
    agent_id=agent.id,
    passage_id=passage.id
)
```
```typescript TypeScript
// Update a memory
await client.agents.passages.update(agent.id, passage.id, {
    content: "Updated content",
    tags: ["new", "tags"]
});

// Delete a memory
await client.agents.passages.delete(agent.id, passage.id);
```
</CodeGroup>

This allows you to:
- Fix incorrect information
- Update outdated facts
- Remove sensitive or irrelevant data
- Reorganize tag structures

## Programmatic access

You can manage archival memory via the SDK:

<CodeGroup>
```python Python
# Insert a memory
client.agents.passages.insert(
    agent_id=agent.id,
    content="The Voight-Kampff test requires a minimum of 20 cross-referenced questions",
    tags=["technical", "testing", "protocol"]
)

# Search memories
results = client.agents.passages.search(
    agent_id=agent.id,
    query="testing procedures",
    tags=["protocol"],
    page=0
)

# List all memories
passages = client.agents.passages.list(
    agent_id=agent.id,
    limit=100
)

# Get a specific memory
passage = client.agents.passages.get(
    agent_id=agent.id,
    passage_id=passage_id
)
```
```typescript TypeScript
// Insert a memory
await client.agents.passages.insert(agent.id, {
    content: "The Voight-Kampff test requires a minimum of 20 cross-referenced questions",
    tags: ["technical", "testing", "protocol"]
});

// Search memories
const results = await client.agents.passages.search(agent.id, {
    query: "testing procedures",
    tags: ["protocol"],
    page: 0
});

// List all memories
const passages = await client.agents.passages.list(agent.id, {
    limit: 100
});

// Get a specific memory
const passage = await client.agents.passages.get(agent.id, passageId);
```
</CodeGroup>

## Next steps

<CardGroup cols={2}>
  <Card
    title="Memory Blocks"
    href="/guides/agents/memory-blocks"
  >
    Learn about always-visible memory
  </Card>
  <Card
    title="Agent Memory Overview"
    href="/guides/agents/memory"
  >
    Understand Letta's memory system
  </Card>
  <Card
    title="Letta Filesystem"
    href="/guides/agents/filesystem"
  >
    Work with documents and files
  </Card>
  <Card
    title="Custom Tools"
    href="/guides/agents/custom-tools"
  >
    Create tools for external data sources
  </Card>
</CardGroup>
