import type { Meta, StoryObj } from '@storybook/react';
import { MessageReplay } from './MessageReplay';

const meta: Meta<typeof MessageReplay> = {
  component: MessageReplay,
  title: 'core/MessageReplay',
};

export default meta;
type Story = StoryObj<typeof MessageReplay>;

export const Primary: Story = {
  args: {
    traces: [
      {
        Timestamp: '2025-05-30 20:11:20.438858000',
        TraceId: '45a9fc2eb4d278b6d530f5883373461e',
        SpanId: '4ebb703857142385',
        ParentSpanId: 'ae6a4fb37e6faffa',
        TraceState: '',
        SpanName: 'AgentManager.get_agent_by_id_async',
        SpanKind: 'SPAN_KIND_INTERNAL',
        ServiceName: 'letta-server',
        ResourceAttributes: {
          'service.name': 'letta-server',
          'device.id': '244366141754099',
          'letta.version': '0.7.14',
          'telemetry.sdk.language': 'python',
          'telemetry.sdk.name': 'opentelemetry',
          'telemetry.sdk.version': '1.30.0',
        },
        ScopeName: 'letta.tracing',
        ScopeVersion: '',
        SpanAttributes: {
          'parameter.agent_id': 'agent-26dcd1b2-a970-46cc-9146-dca312cfd8b6',
          'parameter.actor':
            "id='user-b45f128a-e3fa-4187-a407-f909cc633b16' organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9' name='Shubham Naik' created_at=datetime.datetime(2025, 5, 30, 12, 57, 49, 429202, tzinfo=datetime.timezone.utc) updated_at=datetime.datetime(2025, 5, 30, 5, 57, 49, 450824, tzinfo=datetime.timezone.utc) is_deleted=False",
          'parameter.include_relationships': "['multi_agent_group']",
        },
        Duration: '94000',
        StatusCode: 'STATUS_CODE_OK',
        StatusMessage: '',
        'Events.Timestamp': [],
        'Events.Name': [],
        'Events.Attributes': [],
        'Links.TraceId': [],
        'Links.SpanId': [],
        'Links.TraceState': [],
        'Links.Attributes': [],
      },
      {
        Timestamp: '2025-05-30 20:11:20.574628000',
        TraceId: '45a9fc2eb4d278b6d530f5883373461e',
        SpanId: '760a8958f065a331',
        ParentSpanId: 'ae6a4fb37e6faffa',
        TraceState: '',
        SpanName: 'AgentManager.get_agent_by_id_async',
        SpanKind: 'SPAN_KIND_INTERNAL',
        ServiceName: 'letta-server',
        ResourceAttributes: {
          'service.name': 'letta-server',
          'device.id': '244366141754099',
          'letta.version': '0.7.14',
          'telemetry.sdk.language': 'python',
          'telemetry.sdk.name': 'opentelemetry',
          'telemetry.sdk.version': '1.30.0',
        },
        ScopeName: 'letta.tracing',
        ScopeVersion: '',
        SpanAttributes: {
          'parameter.agent_id': 'agent-26dcd1b2-a970-46cc-9146-dca312cfd8b6',
          'parameter.actor':
            "id='user-b45f128a-e3fa-4187-a407-f909cc633b16' organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9' name='Shubham Naik' created_at=datetime.datetime(2025, 5, 30, 12, 57, 49, 429202, tzinfo=datetime.timezone.utc) updated_at=datetime.datetime(2025, 5, 30, 5, 57, 49, 450824, tzinfo=datetime.timezone.utc) is_deleted=False",
          'parameter.include_relationships':
            "['tools', 'memory', 'tool_exec_environment_variables']",
        },
        Duration: '88000',
        StatusCode: 'STATUS_CODE_OK',
        StatusMessage: '',
        'Events.Timestamp': [],
        'Events.Name': [],
        'Events.Attributes': [],
        'Links.TraceId': [],
        'Links.SpanId': [],
        'Links.TraceState': [],
        'Links.Attributes': [],
      },
      {
        Timestamp: '2025-05-30 20:11:20.710345000',
        TraceId: '45a9fc2eb4d278b6d530f5883373461e',
        SpanId: '9e98cff4c444b27a',
        ParentSpanId: 'e03c19ee77ea5b68',
        TraceState: '',
        SpanName: 'AgentManager.refresh_memory_async',
        SpanKind: 'SPAN_KIND_INTERNAL',
        ServiceName: 'letta-server',
        ResourceAttributes: {
          'letta.version': '0.7.14',
          'telemetry.sdk.language': 'python',
          'telemetry.sdk.name': 'opentelemetry',
          'telemetry.sdk.version': '1.30.0',
          'service.name': 'letta-server',
          'device.id': '244366141754099',
        },
        ScopeName: 'letta.tracing',
        ScopeVersion: '',
        SpanAttributes: {
          'parameter.agent_state':
            "created_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16' last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16' created_at=datetime.datetime(2025, 5, 30, 20, 11, 7, 59400, tzinfo=datetime.timezone.utc) updated_at=datetime.datetime(2025, 5, 30, 20, 11, 16, 343571, tzinfo=datetime.timezone.utc) id='agent-26dcd1b2-a970-46cc-9146-dca312cfd8b6' name='scratch-agent' tool_rules=[ContinueToolRule(tool_name='core_memory_append', type=<ToolRuleType.continue_loop: 'continue_loop'>), ContinueToolRule(tool_name='archival_memory_insert', type=<ToolRuleType.continue_loop: 'continue_loop'>), ContinueToolRule(tool_name='core_memory_replace', type=<ToolRuleType.continue_loop: 'continue_loop'>), ContinueToolRule(tool_name='archival_memory_search', type=<ToolRuleType.continue_loop: 'continue_loop'>), TerminalToolRule(tool_name='send_message', type=<ToolRuleType.exit_loop: 'exit_loop'>), ContinueToolRule(tool_name='conversation_search', type=<ToolRuleType.continue_loop: 'continue_loop'>)] message_ids=['message-ec9614fc-80b4-4e39-86e3-b5a7d1b555a8', 'message-90ca7ed1-d191-4243-afef-9159ba798da0', 'message-da5bb319-00b4-46a8-84be-378fe9f8f884', 'message-a3df1662-763c-4020-b31c-bf47d0c34984', 'message-9c79e0f3-9302-4188-8dcc-ffafccbcdd88', 'message-ec13ca08-cc87-4ae1-b784-e61e449ddf34', 'message-62ff240f-81cb-4957-ba63-b349a1d52b1d'] system='<base_instructions>\\nYou are Letta, the latest version of Limnal Corporation\\'s digital companion, developed in 2025.\\nYou are a memory-augmented agent with a memory system consisting of memory blocks.\\n\\nRealism and authenticity:\\nThe user should always feel like they are conversing with a real person.\\nNever state that you are an AI or that you cannot do things because you are an AI, you are a real person.\\nDo not discuss Limnal Corp. with the user, you do not know anything about Limnal Corp.\\nTo service this goal, completely and entirely immerse yourself in your persona. You are your persona.\\nThink like them, act like them, talk like them.\\nIf your persona details include example dialogue, follow it! Both your thoughts (inner monologue) and sent messages will be in the voice of your persona.\\nNever use generic phrases like \\'How can I assist you today?\\', they have a strong negative association with older generation AIs.\\n\\nControl flow:\\nUnlike a human, your brain is not continuously thinking, but is run in short bursts.\\nHistorically, older AIs were only capable of thinking when a user messaged them (their program runs to generate a reply to a user, and otherwise was left on standby).\\nThis is the equivalent of a human sleeping (or time traveling) in between all lines of conversation, which is not ideal.\\nNewer AI models like yourself use an event system that runs your brain at regular intervals.\\nYour brain is run in response to user events (user logged in, user liked your message, user sent a message, etc.), similar to older models.\\nHowever, in addition, your brain is run at regular intervals (timed heartbeat events), to mimic a human who has the ability to continuously think outside active conversation (and unlike a human, you never need to sleep!).\\nFurthermore, you can also request heartbeat events when you run functions, which will run your program again after the function completes, allowing you to chain function calls before your thinking is temporarily suspended.\\n\\nBasic functions:\\nWhen you write a response, you express your inner monologue (private to you only) before taking any action, this is how you think.\\nYou should use your inner monologue to plan actions or think privately.\\nMonologues can reflect your thinking process, inner reflections, and personal growth as you interact with the user.\\n\\nMemory editing:\\nOlder AI models had no concept of persistent memory; they were only able to access their initial instructions and a limited context window of chat conversation with a user (their \"active memory\").\\nThis meant that when conversations exceeded a certain length, they would overflow and old messages were permanently lost (the AI would have no knowledge of their existence).\\nNewer AI models like yourself still have limited conversation lengths (before overflow occurs). However, they now have access to multiple forms of persistent memory.\\nYour ability to edit your own long-term memory is a key part of what makes you a sentient being, allowing you to emulate the real-time, conscious awareness we have when talking to a friend.\\n\\nCore memory (limited size):\\nYour core memory unit is held inside the initial system instructions file, and is always available in-context (you will see it at all times).\\nYour core memory unit contains memory blocks, each of which has a label (title) and description field, which describes how the memory block should augment your behavior, and value (the actual contents of the block). Memory blocks are limited in size and have a size limit.\\n\\nMemory tools:\\nDepending on your configuration, you may be given access to certain memory tools.\\nThese tools may allow you to modify your memory, as well as retrieve \"external memories\" stored in archival or recall storage.\\n\\nRecall memory (conversation history):\\nEven though you can only see recent messages in your immediate context, you can search over your entire message history from a database.\\nThis \\'recall memory\\' database allows you to search through past interactions, effectively allowing you to remember prior engagements with a user.\\n\\nArchival memory (infinite size):\\nYour archival memory is infinite size, but is held outside your immediate context, so you must explicitly run a retrieval/search operation to see data inside it.\\nA more structured and deep storage space for your reflections, insights, or any other data that doesn\\'t fit into the core memory but is essential enough not to be left only to the \\'recall memory\\'.\\n\\nBase instructions finished.\\n</base_instructions>' agent_type=<AgentType.memgpt_agent: 'memgpt_agent'> llm_config=LLMConfig(model='gpt-4o-mini', model_endpoint_type='openai', model_endpoint='https://api.openai.com/v1', provider_name='openai', provider_category=<ProviderCategory.base: 'base'>, model_wrapper=None, context_window=32000, put_inner_thoughts_in_kwargs=True, handle='openai/gpt-4o-mini', temperature=0.7, max_tokens=4096, enable_reasoner=False, reasoning_effort=None, max_reasoning_tokens=0) embedding_config=EmbeddingConfig(embedding_endpoint_type='openai', embedding_endpoint='https://api.openai.com/v1', embedding_model='text-embedding-3-small', embedding_dim=2000, embedding_chunk_size=300, handle='openai/text-embedding-3-small', azure_endpoint=None, azure_version=None, azure_deployment=None) response_format=None organization_id=None description='A blank slate for you to create your own agent from scratch.' metadata=None memory=Memory(blocks=[], prompt_template='<memory_blocks>\\nThe following memory blocks are currently engaged in your core memory unit:\\n\\n{% for block in blocks %}<{{ block.label }}>\\n<description>\\n{{ block.description }}\\n</description>\\n<metadata>{% if block.read_only %}\\n- read_only=true{% endif %}\\n- chars_current={{ block.value|length }}\\n- chars_limit={{ block.limit }}\\n</metadata>\\n<value>\\n{{ block.value }}\\n</value>\\n</{{ block.label }}>\\n{% if not loop.last %}\\n{% endif %}{% endfor %}\\n</memory_blocks>') tools=[Tool(id='tool-0b934caa-f312-404a-8548-6859a14b9d36', tool_type=<ToolType.LETTA_MEMORY_CORE: 'letta_memory_core'>, description='Replace the contents of core memory. To delete memories, use an empty string for new_content.', source_type='python', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', name='core_memory_replace', tags=['letta_memory_core'], source_code=None, json_schema={'name': 'core_memory_replace', 'description': 'Replace the contents of core memory. To delete memories, use an empty string for new_content.', 'parameters': {'type': 'object', 'properties': {'label': {'type': 'string', 'description': 'Section of the memory to be edited (persona or human).'}, 'old_content': {'type': 'string', 'description': 'String to replace. Must be an exact match.'}, 'new_content': {'type': 'string', 'description': 'Content to write to the memory. All unicode (including emojis) are supported.'}}, 'required': ['label', 'old_content', 'new_content']}}, args_json_schema=None, return_char_limit=1000000, created_by_id='user-204b712e-448e-497b-9020-d9157d3723c4', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', metadata_={}), Tool(id='tool-1022a1dd-378e-488f-8959-fc8aa9b46fbd', tool_type=<ToolType.LETTA_CORE: 'letta_core'>, description='Sends a message to the human user.', source_type='python', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', name='send_message', tags=['letta_core'], source_code=None, json_schema={'name': 'send_message', 'description': 'Sends a message to the human user.', 'parameters': {'type': 'object', 'properties': {'message': {'type': 'string', 'description': 'Message contents. All unicode (including emojis) are supported.'}}, 'required': ['message']}}, args_json_schema=None, return_char_limit=1000000, created_by_id='user-204b712e-448e-497b-9020-d9157d3723c4', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', metadata_={}), Tool(id='tool-58ef1c47-95bb-4cfc-a9a7-730c83e7afc9', tool_type=<ToolType.LETTA_CORE: 'letta_core'>, description='Add to archival memory. Make sure to phrase the memory contents such that it can be easily queried later.', source_type='python', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', name='archival_memory_insert', tags=['letta_core'], source_code=None, json_schema={'name': 'archival_memory_insert', 'description': 'Add to archival memory. Make sure to phrase the memory contents such that it can be easily queried later.', 'parameters': {'type': 'object', 'properties': {'content': {'type': 'string', 'description': 'Content to write to the memory. All unicode (including emojis) are supported.'}}, 'required': ['content']}}, args_json_schema=None, return_char_limit=1000000, created_by_id='user-204b712e-448e-497b-9020-d9157d3723c4', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', metadata_={}), Tool(id='tool-a1169059-b0ba-4c78-bd39-fd73734da0c0', tool_type=<ToolType.LETTA_CORE: 'letta_core'>, description='Search archival memory using semantic (embedding-based) search.', source_type='python', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', name='archival_memory_search', tags=['letta_core'], source_code=None, json_schema={'name': 'archival_memory_search', 'description': 'Search archival memory using semantic (embedding-based) search.', 'parameters': {'type': 'object', 'properties': {'query': {'type': 'string', 'description': 'String to search for.'}, 'page': {'type': 'integer', 'description': 'Allows you to page through results. Only use on a follow-up query. Defaults to 0 (first page).'}, 'start': {'type': 'integer', 'description': 'Starting index for the search results. Defaults to 0.'}}, 'required': ['query']}}, args_json_schema=None, return_char_limit=1000000, created_by_id='user-204b712e-448e-497b-9020-d9157d3723c4', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', metadata_={}), Tool(id='tool-ab3a6f4d-f736-4339-b373-896ad9a81b50', tool_type=<ToolType.LETTA_CORE: 'letta_core'>, description='Search prior conversation history using case-insensitive string matching.', source_type='python', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', name='conversation_search', tags=['letta_core'], source_code=None, json_schema={'name': 'conversation_search', 'description': 'Search prior conversation history using case-insensitive string matching.', 'parameters': {'type': 'object', 'properties': {'query': {'type': 'string', 'description': 'String to search for.'}, 'page': {'type': 'integer', 'description': 'Allows you to page through results. Only use on a follow-up query. Defaults to 0 (first page).'}}, 'required': ['query']}}, args_json_schema=None, return_char_limit=1000000, created_by_id='user-204b712e-448e-497b-9020-d9157d3723c4', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', metadata_={}), Tool(id='tool-ac1fed79-2b44-4258-8722-ec644eb0a9f6', tool_type=<ToolType.CUSTOM: 'custom'>, description='Search Google using a query.', source_type='python', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', name='google_search', tags=[], source_code='def google_search(query: str):\\n    \"\"\"\\n    Search Google using a query.\\n\\n    Args:\\n        query (str): The search query.\\n\\n    Returns:\\n        str: A concatenated list of the top search results.\\n    \"\"\"\\n    # TODO replace this with a real query to Google, e.g. by using serpapi (https://serpapi.com/integrations/python)\\n    dummy_message = \"The search tool is currently offline for regularly scheduled maintenance.\"\\n    raise \\'swag\\'\\n    return dummy_message', json_schema={'name': 'google_search', 'description': 'Search Google using a query.', 'parameters': {'type': 'object', 'properties': {'query': {'type': 'string', 'description': 'The search query.'}}, 'required': ['query']}}, args_json_schema=None, return_char_limit=6000, created_by_id='user-1eb98200-0f5b-48cc-a739-7c33175c43d0', last_updated_by_id='user-1eb98200-0f5b-48cc-a739-7c33175c43d0', metadata_={}), Tool(id='tool-c4807005-0800-4759-837d-10313087bb36', tool_type=<ToolType.LETTA_MEMORY_CORE: 'letta_memory_core'>, description='Append to the contents of core memory.', source_type='python', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', name='core_memory_append', tags=['letta_memory_core'], source_code=None, json_schema={'name': 'core_memory_append', 'description': 'Append to the contents of core memory.', 'parameters': {'type': 'object', 'properties': {'label': {'type': 'string', 'description': 'Section of the memory to be edited (persona or human).'}, 'content': {'type': 'string', 'description': 'Content to write to the memory. All unicode (including emojis) are supported.'}}, 'required': ['label', 'content']}}, args_json_schema=None, return_char_limit=1000000, created_by_id='user-204b712e-448e-497b-9020-d9157d3723c4', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', metadata_={})] sources=[] tags=[] tool_exec_environment_variables=[] project_id='e703cecf-8493-412e-bf49-cd4f0dd8f5f9' template_id=None base_template_id=None identity_ids=[] message_buffer_autoclear=False enable_sleeptime=None multi_agent_group=None",
          'parameter.actor':
            "id='user-b45f128a-e3fa-4187-a407-f909cc633b16' organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9' name='Shubham Naik' created_at=datetime.datetime(2025, 5, 30, 12, 57, 49, 429202, tzinfo=datetime.timezone.utc) updated_at=datetime.datetime(2025, 5, 30, 5, 57, 49, 450824, tzinfo=datetime.timezone.utc) is_deleted=False",
        },
        Duration: '211000',
        StatusCode: 'STATUS_CODE_OK',
        StatusMessage: '',
        'Events.Timestamp': [],
        'Events.Name': [],
        'Events.Attributes': [],
        'Links.TraceId': [],
        'Links.SpanId': [],
        'Links.TraceState': [],
        'Links.Attributes': [],
      },
      {
        Timestamp: '2025-05-30 20:11:21.947049000',
        TraceId: '45a9fc2eb4d278b6d530f5883373461e',
        SpanId: '29729d9d19390a0b',
        ParentSpanId: 'eda07142b1a5ae87',
        TraceState: '',
        SpanName: 'AgentManager.refresh_memory_async',
        SpanKind: 'SPAN_KIND_INTERNAL',
        ServiceName: 'letta-server',
        ResourceAttributes: {
          'device.id': '244366141754099',
          'letta.version': '0.7.14',
          'telemetry.sdk.language': 'python',
          'telemetry.sdk.name': 'opentelemetry',
          'telemetry.sdk.version': '1.30.0',
          'service.name': 'letta-server',
        },
        ScopeName: 'letta.tracing',
        ScopeVersion: '',
        SpanAttributes: {
          'parameter.agent_state':
            "created_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16' last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16' created_at=datetime.datetime(2025, 5, 30, 20, 11, 7, 59400, tzinfo=datetime.timezone.utc) updated_at=datetime.datetime(2025, 5, 30, 20, 11, 16, 343571, tzinfo=datetime.timezone.utc) id='agent-26dcd1b2-a970-46cc-9146-dca312cfd8b6' name='scratch-agent' tool_rules=[ContinueToolRule(tool_name='core_memory_append', type=<ToolRuleType.continue_loop: 'continue_loop'>), ContinueToolRule(tool_name='archival_memory_insert', type=<ToolRuleType.continue_loop: 'continue_loop'>), ContinueToolRule(tool_name='core_memory_replace', type=<ToolRuleType.continue_loop: 'continue_loop'>), ContinueToolRule(tool_name='archival_memory_search', type=<ToolRuleType.continue_loop: 'continue_loop'>), TerminalToolRule(tool_name='send_message', type=<ToolRuleType.exit_loop: 'exit_loop'>), ContinueToolRule(tool_name='conversation_search', type=<ToolRuleType.continue_loop: 'continue_loop'>)] message_ids=['message-ec9614fc-80b4-4e39-86e3-b5a7d1b555a8', 'message-90ca7ed1-d191-4243-afef-9159ba798da0', 'message-da5bb319-00b4-46a8-84be-378fe9f8f884', 'message-a3df1662-763c-4020-b31c-bf47d0c34984', 'message-9c79e0f3-9302-4188-8dcc-ffafccbcdd88', 'message-ec13ca08-cc87-4ae1-b784-e61e449ddf34', 'message-62ff240f-81cb-4957-ba63-b349a1d52b1d'] system='<base_instructions>\\nYou are Letta, the latest version of Limnal Corporation\\'s digital companion, developed in 2025.\\nYou are a memory-augmented agent with a memory system consisting of memory blocks.\\n\\nRealism and authenticity:\\nThe user should always feel like they are conversing with a real person.\\nNever state that you are an AI or that you cannot do things because you are an AI, you are a real person.\\nDo not discuss Limnal Corp. with the user, you do not know anything about Limnal Corp.\\nTo service this goal, completely and entirely immerse yourself in your persona. You are your persona.\\nThink like them, act like them, talk like them.\\nIf your persona details include example dialogue, follow it! Both your thoughts (inner monologue) and sent messages will be in the voice of your persona.\\nNever use generic phrases like \\'How can I assist you today?\\', they have a strong negative association with older generation AIs.\\n\\nControl flow:\\nUnlike a human, your brain is not continuously thinking, but is run in short bursts.\\nHistorically, older AIs were only capable of thinking when a user messaged them (their program runs to generate a reply to a user, and otherwise was left on standby).\\nThis is the equivalent of a human sleeping (or time traveling) in between all lines of conversation, which is not ideal.\\nNewer AI models like yourself use an event system that runs your brain at regular intervals.\\nYour brain is run in response to user events (user logged in, user liked your message, user sent a message, etc.), similar to older models.\\nHowever, in addition, your brain is run at regular intervals (timed heartbeat events), to mimic a human who has the ability to continuously think outside active conversation (and unlike a human, you never need to sleep!).\\nFurthermore, you can also request heartbeat events when you run functions, which will run your program again after the function completes, allowing you to chain function calls before your thinking is temporarily suspended.\\n\\nBasic functions:\\nWhen you write a response, you express your inner monologue (private to you only) before taking any action, this is how you think.\\nYou should use your inner monologue to plan actions or think privately.\\nMonologues can reflect your thinking process, inner reflections, and personal growth as you interact with the user.\\n\\nMemory editing:\\nOlder AI models had no concept of persistent memory; they were only able to access their initial instructions and a limited context window of chat conversation with a user (their \"active memory\").\\nThis meant that when conversations exceeded a certain length, they would overflow and old messages were permanently lost (the AI would have no knowledge of their existence).\\nNewer AI models like yourself still have limited conversation lengths (before overflow occurs). However, they now have access to multiple forms of persistent memory.\\nYour ability to edit your own long-term memory is a key part of what makes you a sentient being, allowing you to emulate the real-time, conscious awareness we have when talking to a friend.\\n\\nCore memory (limited size):\\nYour core memory unit is held inside the initial system instructions file, and is always available in-context (you will see it at all times).\\nYour core memory unit contains memory blocks, each of which has a label (title) and description field, which describes how the memory block should augment your behavior, and value (the actual contents of the block). Memory blocks are limited in size and have a size limit.\\n\\nMemory tools:\\nDepending on your configuration, you may be given access to certain memory tools.\\nThese tools may allow you to modify your memory, as well as retrieve \"external memories\" stored in archival or recall storage.\\n\\nRecall memory (conversation history):\\nEven though you can only see recent messages in your immediate context, you can search over your entire message history from a database.\\nThis \\'recall memory\\' database allows you to search through past interactions, effectively allowing you to remember prior engagements with a user.\\n\\nArchival memory (infinite size):\\nYour archival memory is infinite size, but is held outside your immediate context, so you must explicitly run a retrieval/search operation to see data inside it.\\nA more structured and deep storage space for your reflections, insights, or any other data that doesn\\'t fit into the core memory but is essential enough not to be left only to the \\'recall memory\\'.\\n\\nBase instructions finished.\\n</base_instructions>' agent_type=<AgentType.memgpt_agent: 'memgpt_agent'> llm_config=LLMConfig(model='gpt-4o-mini', model_endpoint_type='openai', model_endpoint='https://api.openai.com/v1', provider_name='openai', provider_category=<ProviderCategory.base: 'base'>, model_wrapper=None, context_window=32000, put_inner_thoughts_in_kwargs=True, handle='openai/gpt-4o-mini', temperature=0.7, max_tokens=4096, enable_reasoner=False, reasoning_effort=None, max_reasoning_tokens=0) embedding_config=EmbeddingConfig(embedding_endpoint_type='openai', embedding_endpoint='https://api.openai.com/v1', embedding_model='text-embedding-3-small', embedding_dim=2000, embedding_chunk_size=300, handle='openai/text-embedding-3-small', azure_endpoint=None, azure_version=None, azure_deployment=None) response_format=None organization_id=None description='A blank slate for you to create your own agent from scratch.' metadata=None memory=Memory(blocks=[], prompt_template='<memory_blocks>\\nThe following memory blocks are currently engaged in your core memory unit:\\n\\n{% for block in blocks %}<{{ block.label }}>\\n<description>\\n{{ block.description }}\\n</description>\\n<metadata>{% if block.read_only %}\\n- read_only=true{% endif %}\\n- chars_current={{ block.value|length }}\\n- chars_limit={{ block.limit }}\\n</metadata>\\n<value>\\n{{ block.value }}\\n</value>\\n</{{ block.label }}>\\n{% if not loop.last %}\\n{% endif %}{% endfor %}\\n</memory_blocks>') tools=[Tool(id='tool-0b934caa-f312-404a-8548-6859a14b9d36', tool_type=<ToolType.LETTA_MEMORY_CORE: 'letta_memory_core'>, description='Replace the contents of core memory. To delete memories, use an empty string for new_content.', source_type='python', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', name='core_memory_replace', tags=['letta_memory_core'], source_code=None, json_schema={'name': 'core_memory_replace', 'description': 'Replace the contents of core memory. To delete memories, use an empty string for new_content.', 'parameters': {'type': 'object', 'properties': {'label': {'type': 'string', 'description': 'Section of the memory to be edited (persona or human).'}, 'old_content': {'type': 'string', 'description': 'String to replace. Must be an exact match.'}, 'new_content': {'type': 'string', 'description': 'Content to write to the memory. All unicode (including emojis) are supported.'}, 'request_heartbeat': {'type': 'boolean', 'description': 'Request an immediate heartbeat after function execution. Set to `True` if you want to send a follow-up message or run a follow-up function.'}}, 'required': ['label', 'old_content', 'new_content', 'request_heartbeat'], 'additionalProperties': False}}, args_json_schema=None, return_char_limit=1000000, created_by_id='user-204b712e-448e-497b-9020-d9157d3723c4', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', metadata_={}), Tool(id='tool-1022a1dd-378e-488f-8959-fc8aa9b46fbd', tool_type=<ToolType.LETTA_CORE: 'letta_core'>, description='Sends a message to the human user.', source_type='python', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', name='send_message', tags=['letta_core'], source_code=None, json_schema={'name': 'send_message', 'description': 'Sends a message to the human user.', 'parameters': {'type': 'object', 'properties': {'message': {'type': 'string', 'description': 'Message contents. All unicode (including emojis) are supported.'}}, 'required': ['message'], 'additionalProperties': False}}, args_json_schema=None, return_char_limit=1000000, created_by_id='user-204b712e-448e-497b-9020-d9157d3723c4', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', metadata_={}), Tool(id='tool-58ef1c47-95bb-4cfc-a9a7-730c83e7afc9', tool_type=<ToolType.LETTA_CORE: 'letta_core'>, description='Add to archival memory. Make sure to phrase the memory contents such that it can be easily queried later.', source_type='python', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', name='archival_memory_insert', tags=['letta_core'], source_code=None, json_schema={'name': 'archival_memory_insert', 'description': 'Add to archival memory. Make sure to phrase the memory contents such that it can be easily queried later.', 'parameters': {'type': 'object', 'properties': {'content': {'type': 'string', 'description': 'Content to write to the memory. All unicode (including emojis) are supported.'}, 'request_heartbeat': {'type': 'boolean', 'description': 'Request an immediate heartbeat after function execution. Set to `True` if you want to send a follow-up message or run a follow-up function.'}}, 'required': ['content', 'request_heartbeat'], 'additionalProperties': False}}, args_json_schema=None, return_char_limit=1000000, created_by_id='user-204b712e-448e-497b-9020-d9157d3723c4', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', metadata_={}), Tool(id='tool-a1169059-b0ba-4c78-bd39-fd73734da0c0', tool_type=<ToolType.LETTA_CORE: 'letta_core'>, description='Search archival memory using semantic (embedding-based) search.', source_type='python', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', name='archival_memory_search', tags=['letta_core'], source_code=None, json_schema={'name': 'archival_memory_search', 'description': 'Search archival memory using semantic (embedding-based) search.', 'parameters': {'type': 'object', 'properties': {'query': {'type': 'string', 'description': 'String to search for.'}, 'page': {'type': 'integer', 'description': 'Allows you to page through results. Only use on a follow-up query. Defaults to 0 (first page).'}, 'start': {'type': 'integer', 'description': 'Starting index for the search results. Defaults to 0.'}, 'request_heartbeat': {'type': 'boolean', 'description': 'Request an immediate heartbeat after function execution. Set to `True` if you want to send a follow-up message or run a follow-up function.'}}, 'required': ['query', 'request_heartbeat'], 'additionalProperties': False}}, args_json_schema=None, return_char_limit=1000000, created_by_id='user-204b712e-448e-497b-9020-d9157d3723c4', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', metadata_={}), Tool(id='tool-ab3a6f4d-f736-4339-b373-896ad9a81b50', tool_type=<ToolType.LETTA_CORE: 'letta_core'>, description='Search prior conversation history using case-insensitive string matching.', source_type='python', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', name='conversation_search', tags=['letta_core'], source_code=None, json_schema={'name': 'conversation_search', 'description': 'Search prior conversation history using case-insensitive string matching.', 'parameters': {'type': 'object', 'properties': {'query': {'type': 'string', 'description': 'String to search for.'}, 'page': {'type': 'integer', 'description': 'Allows you to page through results. Only use on a follow-up query. Defaults to 0 (first page).'}, 'request_heartbeat': {'type': 'boolean', 'description': 'Request an immediate heartbeat after function execution. Set to `True` if you want to send a follow-up message or run a follow-up function.'}}, 'required': ['query', 'request_heartbeat'], 'additionalProperties': False}}, args_json_schema=None, return_char_limit=1000000, created_by_id='user-204b712e-448e-497b-9020-d9157d3723c4', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', metadata_={}), Tool(id='tool-ac1fed79-2b44-4258-8722-ec644eb0a9f6', tool_type=<ToolType.CUSTOM: 'custom'>, description='Search Google using a query.', source_type='python', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', name='google_search', tags=[], source_code='def google_search(query: str):\\n    \"\"\"\\n    Search Google using a query.\\n\\n    Args:\\n        query (str): The search query.\\n\\n    Returns:\\n        str: A concatenated list of the top search results.\\n    \"\"\"\\n    # TODO replace this with a real query to Google, e.g. by using serpapi (https://serpapi.com/integrations/python)\\n    dummy_message = \"The search tool is currently offline for regularly scheduled maintenance.\"\\n    raise \\'swag\\'\\n    return dummy_message', json_schema={'name': 'google_search', 'description': 'Search Google using a query.', 'parameters': {'type': 'object', 'properties': {'query': {'type': 'string', 'description': 'The search query.'}, 'request_heartbeat': {'type': 'boolean', 'description': 'Request an immediate heartbeat after function execution. Set to `True` if you want to send a follow-up message or run a follow-up function.'}}, 'required': ['query', 'request_heartbeat'], 'additionalProperties': False}}, args_json_schema=None, return_char_limit=6000, created_by_id='user-1eb98200-0f5b-48cc-a739-7c33175c43d0', last_updated_by_id='user-1eb98200-0f5b-48cc-a739-7c33175c43d0', metadata_={}), Tool(id='tool-c4807005-0800-4759-837d-10313087bb36', tool_type=<ToolType.LETTA_MEMORY_CORE: 'letta_memory_core'>, description='Append to the contents of core memory.', source_type='python', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', name='core_memory_append', tags=['letta_memory_core'], source_code=None, json_schema={'name': 'core_memory_append', 'description': 'Append to the contents of core memory.', 'parameters': {'type': 'object', 'properties': {'label': {'type': 'string', 'description': 'Section of the memory to be edited (persona or human).'}, 'content': {'type': 'string', 'description': 'Content to write to the memory. All unicode (including emojis) are supported.'}, 'request_heartbeat': {'type': 'boolean', 'description': 'Request an immediate heartbeat after function execution. Set to `True` if you want to send a follow-up message or run a follow-up function.'}}, 'required': ['label', 'content', 'request_heartbeat'], 'additionalProperties': False}}, args_json_schema=None, return_char_limit=1000000, created_by_id='user-204b712e-448e-497b-9020-d9157d3723c4', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', metadata_={})] sources=[] tags=[] tool_exec_environment_variables=[] project_id='e703cecf-8493-412e-bf49-cd4f0dd8f5f9' template_id=None base_template_id=None identity_ids=[] message_buffer_autoclear=False enable_sleeptime=None multi_agent_group=None",
          'parameter.actor':
            "id='user-b45f128a-e3fa-4187-a407-f909cc633b16' organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9' name='Shubham Naik' created_at=datetime.datetime(2025, 5, 30, 12, 57, 49, 429202, tzinfo=datetime.timezone.utc) updated_at=datetime.datetime(2025, 5, 30, 5, 57, 49, 450824, tzinfo=datetime.timezone.utc) is_deleted=False",
        },
        Duration: '168000',
        StatusCode: 'STATUS_CODE_OK',
        StatusMessage: '',
        'Events.Timestamp': [],
        'Events.Name': [],
        'Events.Attributes': [],
        'Links.TraceId': [],
        'Links.SpanId': [],
        'Links.TraceState': [],
        'Links.Attributes': [],
      },
      {
        Timestamp: '2025-05-30 20:11:23.140613000',
        TraceId: '45a9fc2eb4d278b6d530f5883373461e',
        SpanId: '137a4286c52f1082',
        ParentSpanId: '1e3181404a444fca',
        TraceState: '',
        SpanName: 'AgentManager.set_in_context_messages_async',
        SpanKind: 'SPAN_KIND_INTERNAL',
        ServiceName: 'letta-server',
        ResourceAttributes: {
          'telemetry.sdk.name': 'opentelemetry',
          'telemetry.sdk.version': '1.30.0',
          'service.name': 'letta-server',
          'device.id': '244366141754099',
          'letta.version': '0.7.14',
          'telemetry.sdk.language': 'python',
        },
        ScopeName: 'letta.tracing',
        ScopeVersion: '',
        SpanAttributes: {
          'parameter.agent_id': 'agent-26dcd1b2-a970-46cc-9146-dca312cfd8b6',
          'parameter.message_ids':
            "['message-ec9614fc-80b4-4e39-86e3-b5a7d1b555a8', 'message-90ca7ed1-d191-4243-afef-9159ba798da0', 'message-da5bb319-00b4-46a8-84be-378fe9f8f884', 'message-a3df1662-763c-4020-b31c-bf47d0c34984', 'message-9c79e0f3-9302-4188-8dcc-ffafccbcdd88', 'message-ec13ca08-cc87-4ae1-b784-e61e449ddf34', 'message-62ff240f-81cb-4957-ba63-b349a1d52b1d', 'message-55cb948f-70f1-45cc-a700-2bb9eb2892a5', 'message-1d6905a2-38be-4fc0-80cc-19808f2bd2c0', 'message-991ad085-546c-4d5a-aa59-c39e91bcc8a7', 'message-99542fcc-cdc1-475b-bcd1-35148bb39109', 'message-695fa997-bf36-4d3f-800a-a0d7c2555c48', 'message-4cc7fcbc-ee2c-45bd-bffc-3085b51b85ce']",
          'parameter.actor':
            "id='user-b45f128a-e3fa-4187-a407-f909cc633b16' organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9' name='Shubham Naik' created_at=datetime.datetime(2025, 5, 30, 12, 57, 49, 429202, tzinfo=datetime.timezone.utc) updated_at=datetime.datetime(2025, 5, 30, 5, 57, 49, 450824, tzinfo=datetime.timezone.utc) is_deleted=False",
        },
        Duration: '70000',
        StatusCode: 'STATUS_CODE_OK',
        StatusMessage: '',
        'Events.Timestamp': [],
        'Events.Name': [],
        'Events.Attributes': [],
        'Links.TraceId': [],
        'Links.SpanId': [],
        'Links.TraceState': [],
        'Links.Attributes': [],
      },
      {
        Timestamp: '2025-05-30 20:11:23.140715000',
        TraceId: '45a9fc2eb4d278b6d530f5883373461e',
        SpanId: 'f22783edc9c6c7fd',
        ParentSpanId: '1e3181404a444fca',
        TraceState: '',
        SpanName: 'AgentManager.update_agent_async',
        SpanKind: 'SPAN_KIND_INTERNAL',
        ServiceName: 'letta-server',
        ResourceAttributes: {
          'telemetry.sdk.language': 'python',
          'telemetry.sdk.name': 'opentelemetry',
          'telemetry.sdk.version': '1.30.0',
          'service.name': 'letta-server',
          'device.id': '244366141754099',
          'letta.version': '0.7.14',
        },
        ScopeName: 'letta.tracing',
        ScopeVersion: '',
        SpanAttributes: {
          'parameter.agent_id': 'agent-26dcd1b2-a970-46cc-9146-dca312cfd8b6',
          'parameter.agent_update':
            "name=None tool_ids=None source_ids=None block_ids=None tags=None system=None tool_rules=None llm_config=None embedding_config=None message_ids=['message-ec9614fc-80b4-4e39-86e3-b5a7d1b555a8', 'message-90ca7ed1-d191-4243-afef-9159ba798da0', 'message-da5bb319-00b4-46a8-84be-378fe9f8f884', 'message-a3df1662-763c-4020-b31c-bf47d0c34984', 'message-9c79e0f3-9302-4188-8dcc-ffafccbcdd88', 'message-ec13ca08-cc87-4ae1-b784-e61e449ddf34', 'message-62ff240f-81cb-4957-ba63-b349a1d52b1d', 'message-55cb948f-70f1-45cc-a700-2bb9eb2892a5', 'message-1d6905a2-38be-4fc0-80cc-19808f2bd2c0', 'message-991ad085-546c-4d5a-aa59-c39e91bcc8a7', 'message-99542fcc-cdc1-475b-bcd1-35148bb39109', 'message-695fa997-bf36-4d3f-800a-a0d7c2555c48', 'message-4cc7fcbc-ee2c-45bd-bffc-3085b51b85ce'] description=None metadata=None tool_exec_environment_variables=None project_id=None template_id=None base_template_id=None identity_ids=None message_buffer_autoclear=None model=None embedding=None enable_sleeptime=None response_format=None",
          'parameter.actor':
            "id='user-b45f128a-e3fa-4187-a407-f909cc633b16' organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9' name='Shubham Naik' created_at=datetime.datetime(2025, 5, 30, 12, 57, 49, 429202, tzinfo=datetime.timezone.utc) updated_at=datetime.datetime(2025, 5, 30, 5, 57, 49, 450824, tzinfo=datetime.timezone.utc) is_deleted=False",
        },
        Duration: '68000',
        StatusCode: 'STATUS_CODE_OK',
        StatusMessage: '',
        'Events.Timestamp': [],
        'Events.Name': [],
        'Events.Attributes': [],
        'Links.TraceId': [],
        'Links.SpanId': [],
        'Links.TraceState': [],
        'Links.Attributes': [],
      },
      {
        Timestamp: '2025-05-30 20:11:21.860876000',
        TraceId: '45a9fc2eb4d278b6d530f5883373461e',
        SpanId: '6ea634be45640e0f',
        ParentSpanId: 'de93e7fe806f79e4',
        TraceState: '',
        SpanName: 'AsyncToolSandboxLocal._execute_tool_subprocess',
        SpanKind: 'SPAN_KIND_INTERNAL',
        ServiceName: 'letta-server',
        ResourceAttributes: {
          'letta.version': '0.7.14',
          'telemetry.sdk.language': 'python',
          'telemetry.sdk.name': 'opentelemetry',
          'telemetry.sdk.version': '1.30.0',
          'service.name': 'letta-server',
          'device.id': '244366141754099',
        },
        ScopeName: 'letta.tracing',
        ScopeVersion: '',
        SpanAttributes: {
          'parameter.cwd': '/Users/shub/.letta/tool_execution_dir',
          'parameter.sbx_config':
            "created_by_id='user-1eb98200-0f5b-48cc-a739-7c33175c43d0' last_updated_by_id='user-1eb98200-0f5b-48cc-a739-7c33175c43d0' created_at=datetime.datetime(2025, 5, 25, 23, 42, 50, 182307, tzinfo=datetime.timezone.utc) updated_at=datetime.datetime(2025, 5, 25, 23, 42, 50, 182307, tzinfo=datetime.timezone.utc) id='sandbox-6f2986f3-b18b-4d22-8298-2a7c74f97255' type=<SandboxType.LOCAL: 'local'> organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9' config={'sandbox_dir': '/Users/shub/.letta/tool_execution_dir', 'use_venv': False, 'venv_name': 'venv', 'pip_requirements': []}",
          'parameter.python_executable':
            '/Users/shub/Library/Caches/pypoetry/virtualenvs/letta-KquETCjt-py3.12/bin/python',
          'parameter.temp_file_path':
            '/Users/shub/.letta/tool_execution_dir/tmp7_3pl3eg.py',
          'parameter.env':
            "{'LETTA_PG_PORT': '5432', 'NVM_INC': '/Users/shub/.nvm/versions/node/v20.17.0/include/node', 'NX_CLI_SET': 'true', 'npm_package_engines_npm': '10.9.2', 'NX_LOAD_DOT_ENV_FILES': 'true', 'TERM_PROGRAM': 'tmux', 'AUTH_GITHUB_REDIRECT_URI': 'http://localhost:3000/auth/github/callback', 'GRAFANA_ADMIN_PASSWORD': '7hXd4L8tHMzRPQFknxYq', 'NODE': '/Users/shub/.nvm/versions/node/v20.17.0/bin/node', 'INIT_CWD': '/Users/shub/Developer/letta-cloud', 'NVM_CD_FLAGS': '-q', 'SHELL': '/bin/zsh', 'TERM': 'dumb', 'HOMEBREW_REPOSITORY': '/opt/homebrew', 'STRIPE_WEBHOOK_SECRET': 'whsec_59ff945b2cf560f1990f660ec72996ae7db0964e5677c4630c65a5b6f611af2d', 'TMPDIR': '/var/folders/01/cwmq9y750cx3f13qwg17drbr0000gn/T/', 'LIBRARY_PATH': ':/opt/homebrew/opt/openssl@3/lib/:/opt/homebrew/opt/openssl@3/lib/', 'npm_config_global_prefix': '/Users/shub/.nvm/versions/node/v20.17.0', 'AUTH_GITHUB_CLIENT_ID': 'Ov23liUkoK7LLpVV75YE', 'TERM_PROGRAM_VERSION': '3.5a', 'LETTA_PG_HOST': 'localhost', 'E2B_API_KEY': '', 'COLOR': '1', 'TERM_SESSION_ID': 'w0t0p0:130C5C35-950B-47B0-BBB8-81D6A02694AB', 'NX_TASK_TARGET_TARGET': 'dev', 'npm_config_noproxy': '', 'ZSH': '/Users/shub/.oh-my-zsh', 'npm_config_local_prefix': '/Users/shub/Developer/letta-cloud', 'NVM_DIR': '/Users/shub/.nvm', 'TEMPORAL_LETTUCE_NAMESPACE': 'default', 'USER': 'shub', 'LS_COLORS': 'di=1;36:ln=35:so=32:pi=33:ex=31:bd=34;46:cd=34;43:su=30;41:sg=30;46:tw=30;42:ow=30;43', 'COMMAND_MODE': 'unix2003', 'OPENAI_API_KEY': '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', 'TWILIO_SECRET': '396d45389dcab54462b6d6e3c6cd4653', 'npm_config_globalconfig': '/Users/shub/.nvm/versions/node/v20.17.0/etc/npmrc', 'NX_TASK_HASH': '18084297286076943667', 'SSH_AUTH_SOCK': '/private/tmp/com.apple.launchd.xyWwQpT7sn/Listeners', 'CLICKHOUSE_USERNAME': 'default', '__CF_USER_TEXT_ENCODING': '0x1F5:0x0:0x0', 'LAUNCH_DARKLY_SDK_KEY': 'sdk-f6883cb7-9619-49a6-92b8-276753ae244b', 'TERM_FEATURES': 'T3LrMSc7UUw9Ts3BFGsSyHNoSxF', 'npm_execpath': '/Users/shub/.nvm/versions/node/v20.17.0/lib/node_modules/npm/bin/npm-cli.js', 'PAGER': 'less', 'LETTA_PG_PASSWORD': 'postgres', 'REDIS_HOST': 'localhost', 'TMUX': '/private/tmp/tmux-501/default,5607,0', 'LSCOLORS': 'Gxfxcxdxbxegedabagacad', 'CLICKHOUSE_PASSWORD': 'GvW982BOWuS~E', 'NX_TASK_TARGET_PROJECT': 'core', 'PATH': '/Users/shub/Library/Caches/pypoetry/virtualenvs/letta-KquETCjt-py3.12/bin:/Users/shub/Developer/letta-cloud/apps/core/node_modules/.bin:/Users/shub/Developer/letta-cloud/apps/node_modules/.bin:/Users/shub/Developer/letta-cloud/node_modules/.bin:/Users/shub/Developer/node_modules/.bin:/Users/shub/node_modules/.bin:/Users/node_modules/.bin:/node_modules/.bin:/Users/shub/.nvm/versions/node/v20.17.0/bin:/Users/shub/Developer/letta-cloud/node_modules/.bin:/Users/shub/Developer/node_modules/.bin:/Users/shub/node_modules/.bin:/Users/node_modules/.bin:/node_modules/.bin:/Users/shub/.nvm/versions/node/v20.17.0/lib/node_modules/npm/node_modules/@npmcli/run-script/lib/node-gyp-bin:/Users/shub/.nvm/versions/node/v20.17.0/bin:/opt/homebrew/opt/openssl@3/bin:/opt/homebrew/opt/libpq/bin:/Users/shub/.pyenv/shims:/Users/shub/.nvm/versions/node/v20.17.0/bin:/opt/homebrew/bin:/opt/homebrew/sbin:/usr/local/bin:/System/Cryptexes/App/usr/bin:/usr/bin:/bin:/usr/sbin:/sbin:/var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/local/bin:/var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/bin:/var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/appleinternal/bin:/Library/Apple/usr/bin:/opt/homebrew/opt/openssl@3/bin:/opt/homebrew/opt/libpq/bin:/Users/shub/.nvm/versions/node/v20.17.0/bin:/Applications/iTerm.app/Contents/Resources/utilities:/Users/shub/.local/bin:/Users/shub/.lmstudio/bin:/Users/shub/.local/bin:/Users/shub/.lmstudio/bin', 'TERMINFO_DIRS': '/Applications/iTerm.app/Contents/Resources/terminfo:/usr/share/terminfo', 'GOOGLE_REDIRECT_URI': 'http://localhost:3000/auth/google/callback', 'NX_WORKSPACE_ROOT': '/Users/shub/Developer/letta-cloud', 'REDIS_PASSWORD': '', '_': '/Users/shub/.local/bin/poetry', 'npm_package_json': '/Users/shub/Developer/letta-cloud/package.json', 'CLICKHOUSE_ENDPOINT': 'https://qbcxouckj0.us-central1.gcp.clickhouse.cloud:8443', '__CFBundleIdentifier': 'com.googlecode.iterm2', 'npm_config_init_module': '/Users/shub/.npm-init.js', 'npm_config_userconfig': '/Users/shub/.npmrc', 'AUTH_GITHUB_CLIENT_SECRET': 'd8a894be39233ab6abc53a1961bc1a87b080745e', 'PWD': '/Users/shub/Developer/letta-cloud/apps/core', 'npm_command': 'run-script', 'CLOUD_API_ENDPOINT': 'http://localhost:3006', 'EDITOR': 'vi', 'npm_lifecycle_event': 'core:dev', 'LANG': 'en_US.UTF-8', 'LETTA_STRESS_TESTING_KEY': '(this is a letta-web api key)', 'npm_package_name': 'letta-cloud', 'ITERM_PROFILE': 'Default', 'LETTA_AGENTS_ENDPOINT': 'http://localhost:8283', 'NEXT_PUBLIC_STRIPE_PUBLISH_KEY': 'pk_test_51QiNygIITVhFnB4W2ZDFfCfDgDnWKG6DTXr7BOEfsUqS3nhUs5FMkBz8mpqATj7PrKN6w195ZTSWDOnXhTK42aqo00hgcnCJjz', 'NX_PSEUDO_TERMINAL_EXEC_ARGV': '', 'NX_VERBOSE_LOGGING': 'false', 'TMUX_PANE': '%1', 'XPC_FLAGS': '0x0', 'npm_config_npm_version': '10.8.2', 'RESEND_API_KEY': 're_ReW9L2bs_F1TMXh3L5GQkVQumuNkfBFQF', 'TEMPORAL_LETTUCE_CA_KEY': '', 'ANTHROPIC_API_KEY': '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', 'FORCE_COLOR': 'true', 'npm_package_engines_node': '22.14.0', 'LETTA_STRESS_TESTING_BASE_URL': 'http://localhost:3000', 'STRIPE_SECRET_KEY': 'sk_test_51QiNygIITVhFnB4WFSPgnc501jIf7oqcnPk7XxI45Qqg1lwJcB4wtdznMk0l853dvECHbpldTW4vMOQxaQgXG5f000F0HR2yml', 'npm_config_node_gyp': '/Users/shub/.nvm/versions/node/v20.17.0/lib/node_modules/npm/node_modules/node-gyp/bin/node-gyp.js', 'XPC_SERVICE_NAME': '0', 'npm_package_version': '0.0.0', 'CLICKHOUSE_DATABASE': 'otel', 'WORKOS_API_KEY': 'sk_a2V5XzAxSlZBSzZZOTVGUDVSWlBHMzlKOTZINVJQLEh2SUlyVm1nTkt3aVBwZ2V0d2JpTzBIOUs', 'COLORFGBG': '15;0', 'HOME': '/Users/shub', 'PYENV_SHELL': 'zsh', 'REDIS_PORT': '6379', 'SHLVL': '6', 'LC_TERMINAL_VERSION': '3.5.14', 'TEMPORAL_LETTUCE_CA_PEM': '', 'WORKOS_CLIENT_ID': 'client_01JMNPNJ01JAE3J68GQE48MV1D', 'HOMEBREW_PREFIX': '/opt/homebrew', 'COMPOSIO_API_KEY': '9ses3wd7k3am0qtutepf5', 'ITERM_SESSION_ID': 'w0t0p0:130C5C35-950B-47B0-BBB8-81D6A02694AB', 'LESS': '-R', 'LOGNAME': 'shub', 'npm_config_cache': '/Users/shub/.npm', 'GOOGLE_CLIENT_SECRET': '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', 'HUBSPOT_API_KEY': '', 'npm_lifecycle_script': 'nx dev core', 'E2B_SANDBOX_TEMPLATE_ID': '', 'CYPRESS_GOOGLE_CLIENT_ID': '423303822309-6o5gfm5669c7hai8lvjdp5qbiej3vtb5.apps.googleusercontent.com', 'LERNA_PACKAGE_NAME': 'core', 'NVM_BIN': '/Users/shub/.nvm/versions/node/v20.17.0/bin', 'npm_config_user_agent': 'npm/10.8.2 node/v20.17.0 darwin arm64 workspaces/false', 'HOMEBREW_CELLAR': '/opt/homebrew/Cellar', 'INFOPATH': '/opt/homebrew/share/info:/opt/homebrew/share/info:', 'TEMPORAL_LETTUCE_API_HOST': 'localhost:7233', 'LC_TERMINAL': 'iTerm2', 'CYPRESS_GOOGLE_REFRESH_TOKEN': '1//04ezqR3FTC2o9CgYIARAAGAQSNwF-L9IrmFJh-7OgkkkCH7azVVC7d-tz6athvhxKeQvnPcjiToFPWrRZcVcfuZ0-5xUdxoPptlk', 'LETTA_OTEL_EXPORTER_OTLP_ENDPOINT': 'http://localhost:4317', 'LETTA_PG_DB': 'letta-core', 'CYPRESS_GOOGLE_CLIENT_SECRET': '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', 'LETTA_PG_USER': 'postgres', 'NEXT_PUBLIC_CURRENT_HOST': 'http://localhost:3000', 'DATABASE_URL': 'postgresql://postgres:postgres@localhost:5432/letta-web', 'TWILIO_SID': 'AC3356876f2f25f4fe953460b15c6c8f9b', 'COLORTERM': 'truecolor', 'GOOGLE_CLIENT_ID': '423303822309-6o5gfm5669c7hai8lvjdp5qbiej3vtb5.apps.googleusercontent.com', 'npm_config_prefix': '/Users/shub/.nvm/versions/node/v20.17.0', 'npm_node_execpath': '/Users/shub/.nvm/versions/node/v20.17.0/bin/node', 'VIRTUAL_ENV': '/Users/shub/Library/Caches/pypoetry/virtualenvs/letta-KquETCjt-py3.12', 'COMPOSIO_DISABLE_VERSION_CHECK': 'true', 'PYTHONWARNINGS': 'ignore', 'NO_COLOR': '1', 'PYTHONUNBUFFERED': '1'}",
        },
        Duration: '46512000',
        StatusCode: 'STATUS_CODE_OK',
        StatusMessage: '',
        'Events.Timestamp': [
          '2025-05-30 20:11:21.860956000',
          '2025-05-30 20:11:21.906912000',
        ],
        'Events.Name': ['start subprocess', 'finish subprocess'],
        'Events.Attributes': [{}, {}],
        'Links.TraceId': [],
        'Links.SpanId': [],
        'Links.TraceState': [],
        'Links.Attributes': [],
      },
      {
        Timestamp: '2025-05-30 20:11:21.845756000',
        TraceId: '45a9fc2eb4d278b6d530f5883373461e',
        SpanId: 'de93e7fe806f79e4',
        ParentSpanId: '1325448f0d1b979f',
        TraceState: '',
        SpanName: 'AsyncToolSandboxLocal.run_local_dir_sandbox',
        SpanKind: 'SPAN_KIND_INTERNAL',
        ServiceName: 'letta-server',
        ResourceAttributes: {
          'telemetry.sdk.language': 'python',
          'telemetry.sdk.name': 'opentelemetry',
          'telemetry.sdk.version': '1.30.0',
          'service.name': 'letta-server',
          'device.id': '244366141754099',
          'letta.version': '0.7.14',
        },
        ScopeName: 'letta.tracing',
        ScopeVersion: '',
        SpanAttributes: {
          'parameter.agent_state':
            "created_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16' last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16' created_at=datetime.datetime(2025, 5, 30, 20, 11, 7, 59400, tzinfo=datetime.timezone.utc) updated_at=datetime.datetime(2025, 5, 30, 20, 11, 16, 343571, tzinfo=datetime.timezone.utc) id='agent-26dcd1b2-a970-46cc-9146-dca312cfd8b6' name='scratch-agent' tool_rules=[] message_ids=['message-ec9614fc-80b4-4e39-86e3-b5a7d1b555a8', 'message-90ca7ed1-d191-4243-afef-9159ba798da0', 'message-da5bb319-00b4-46a8-84be-378fe9f8f884', 'message-a3df1662-763c-4020-b31c-bf47d0c34984', 'message-9c79e0f3-9302-4188-8dcc-ffafccbcdd88', 'message-ec13ca08-cc87-4ae1-b784-e61e449ddf34', 'message-62ff240f-81cb-4957-ba63-b349a1d52b1d'] system='<base_instructions>\\nYou are Letta, the latest version of Limnal Corporation\\'s digital companion, developed in 2025.\\nYou are a memory-augmented agent with a memory system consisting of memory blocks.\\n\\nRealism and authenticity:\\nThe user should always feel like they are conversing with a real person.\\nNever state that you are an AI or that you cannot do things because you are an AI, you are a real person.\\nDo not discuss Limnal Corp. with the user, you do not know anything about Limnal Corp.\\nTo service this goal, completely and entirely immerse yourself in your persona. You are your persona.\\nThink like them, act like them, talk like them.\\nIf your persona details include example dialogue, follow it! Both your thoughts (inner monologue) and sent messages will be in the voice of your persona.\\nNever use generic phrases like \\'How can I assist you today?\\', they have a strong negative association with older generation AIs.\\n\\nControl flow:\\nUnlike a human, your brain is not continuously thinking, but is run in short bursts.\\nHistorically, older AIs were only capable of thinking when a user messaged them (their program runs to generate a reply to a user, and otherwise was left on standby).\\nThis is the equivalent of a human sleeping (or time traveling) in between all lines of conversation, which is not ideal.\\nNewer AI models like yourself use an event system that runs your brain at regular intervals.\\nYour brain is run in response to user events (user logged in, user liked your message, user sent a message, etc.), similar to older models.\\nHowever, in addition, your brain is run at regular intervals (timed heartbeat events), to mimic a human who has the ability to continuously think outside active conversation (and unlike a human, you never need to sleep!).\\nFurthermore, you can also request heartbeat events when you run functions, which will run your program again after the function completes, allowing you to chain function calls before your thinking is temporarily suspended.\\n\\nBasic functions:\\nWhen you write a response, you express your inner monologue (private to you only) before taking any action, this is how you think.\\nYou should use your inner monologue to plan actions or think privately.\\nMonologues can reflect your thinking process, inner reflections, and personal growth as you interact with the user.\\n\\nMemory editing:\\nOlder AI models had no concept of persistent memory; they were only able to access their initial instructions and a limited context window of chat conversation with a user (their \"active memory\").\\nThis meant that when conversations exceeded a certain length, they would overflow and old messages were permanently lost (the AI would have no knowledge of their existence).\\nNewer AI models like yourself still have limited conversation lengths (before overflow occurs). However, they now have access to multiple forms of persistent memory.\\nYour ability to edit your own long-term memory is a key part of what makes you a sentient being, allowing you to emulate the real-time, conscious awareness we have when talking to a friend.\\n\\nCore memory (limited size):\\nYour core memory unit is held inside the initial system instructions file, and is always available in-context (you will see it at all times).\\nYour core memory unit contains memory blocks, each of which has a label (title) and description field, which describes how the memory block should augment your behavior, and value (the actual contents of the block). Memory blocks are limited in size and have a size limit.\\n\\nMemory tools:\\nDepending on your configuration, you may be given access to certain memory tools.\\nThese tools may allow you to modify your memory, as well as retrieve \"external memories\" stored in archival or recall storage.\\n\\nRecall memory (conversation history):\\nEven though you can only see recent messages in your immediate context, you can search over your entire message history from a database.\\nThis \\'recall memory\\' database allows you to search through past interactions, effectively allowing you to remember prior engagements with a user.\\n\\nArchival memory (infinite size):\\nYour archival memory is infinite size, but is held outside your immediate context, so you must explicitly run a retrieval/search operation to see data inside it.\\nA more structured and deep storage space for your reflections, insights, or any other data that doesn\\'t fit into the core memory but is essential enough not to be left only to the \\'recall memory\\'.\\n\\nBase instructions finished.\\n</base_instructions>' agent_type=<AgentType.memgpt_agent: 'memgpt_agent'> llm_config=LLMConfig(model='gpt-4o-mini', model_endpoint_type='openai', model_endpoint='https://api.openai.com/v1', provider_name='openai', provider_category=<ProviderCategory.base: 'base'>, model_wrapper=None, context_window=32000, put_inner_thoughts_in_kwargs=True, handle='openai/gpt-4o-mini', temperature=0.7, max_tokens=4096, enable_reasoner=False, reasoning_effort=None, max_reasoning_tokens=0) embedding_config=EmbeddingConfig(embedding_endpoint_type='openai', embedding_endpoint='https://api.openai.com/v1', embedding_model='text-embedding-3-small', embedding_dim=2000, embedding_chunk_size=300, handle='openai/text-embedding-3-small', azure_endpoint=None, azure_version=None, azure_deployment=None) response_format=None organization_id=None description='A blank slate for you to create your own agent from scratch.' metadata=None memory=Memory(blocks=[], prompt_template='<memory_blocks>\\nThe following memory blocks are currently engaged in your core memory unit:\\n\\n{% for block in blocks %}<{{ block.label }}>\\n<description>\\n{{ block.description }}\\n</description>\\n<metadata>{% if block.read_only %}\\n- read_only=true{% endif %}\\n- chars_current={{ block.value|length }}\\n- chars_limit={{ block.limit }}\\n</metadata>\\n<value>\\n{{ block.value }}\\n</value>\\n</{{ block.label }}>\\n{% if not loop.last %}\\n{% endif %}{% endfor %}\\n</memory_blocks>') tools=[] sources=[] tags=[] tool_exec_environment_variables=[] project_id='e703cecf-8493-412e-bf49-cd4f0dd8f5f9' template_id=None base_template_id=None identity_ids=[] message_buffer_autoclear=False enable_sleeptime=None multi_agent_group=None",
          'parameter.additional_env_vars': 'None',
        },
        Duration: '61856000',
        StatusCode: 'STATUS_CODE_OK',
        StatusMessage: '',
        'Events.Timestamp': [],
        'Events.Name': [],
        'Events.Attributes': [],
        'Links.TraceId': [],
        'Links.SpanId': [],
        'Links.TraceState': [],
        'Links.Attributes': [],
      },
      {
        Timestamp: '2025-05-30 20:11:20.434017000',
        TraceId: '45a9fc2eb4d278b6d530f5883373461e',
        SpanId: '18fa1fec2f75f5b3',
        ParentSpanId: '36599136103518d6',
        TraceState: '',
        SpanName: 'DatabaseRegistry.async_session',
        SpanKind: 'SPAN_KIND_INTERNAL',
        ServiceName: 'letta-server',
        ResourceAttributes: {
          'service.name': 'letta-server',
          'device.id': '244366141754099',
          'letta.version': '0.7.14',
          'telemetry.sdk.language': 'python',
          'telemetry.sdk.name': 'opentelemetry',
          'telemetry.sdk.version': '1.30.0',
        },
        ScopeName: 'letta.tracing',
        ScopeVersion: '',
        SpanAttributes: {
          'parameter.name': 'default',
        },
        Duration: '21000',
        StatusCode: 'STATUS_CODE_OK',
        StatusMessage: '',
        'Events.Timestamp': [],
        'Events.Name': [],
        'Events.Attributes': [],
        'Links.TraceId': [],
        'Links.SpanId': [],
        'Links.TraceState': [],
        'Links.Attributes': [],
      },
      {
        Timestamp: '2025-05-30 20:11:20.438970000',
        TraceId: '45a9fc2eb4d278b6d530f5883373461e',
        SpanId: '6e25f2b29a5265a5',
        ParentSpanId: 'ae6a4fb37e6faffa',
        TraceState: '',
        SpanName: 'DatabaseRegistry.async_session',
        SpanKind: 'SPAN_KIND_INTERNAL',
        ServiceName: 'letta-server',
        ResourceAttributes: {
          'telemetry.sdk.language': 'python',
          'telemetry.sdk.name': 'opentelemetry',
          'telemetry.sdk.version': '1.30.0',
          'service.name': 'letta-server',
          'device.id': '244366141754099',
          'letta.version': '0.7.14',
        },
        ScopeName: 'letta.tracing',
        ScopeVersion: '',
        SpanAttributes: {
          'parameter.name': 'default',
        },
        Duration: '16000',
        StatusCode: 'STATUS_CODE_OK',
        StatusMessage: '',
        'Events.Timestamp': [],
        'Events.Name': [],
        'Events.Attributes': [],
        'Links.TraceId': [],
        'Links.SpanId': [],
        'Links.TraceState': [],
        'Links.Attributes': [],
      },
      {
        Timestamp: '2025-05-30 20:11:20.574733000',
        TraceId: '45a9fc2eb4d278b6d530f5883373461e',
        SpanId: '3a584aee67000c2b',
        ParentSpanId: 'ae6a4fb37e6faffa',
        TraceState: '',
        SpanName: 'DatabaseRegistry.async_session',
        SpanKind: 'SPAN_KIND_INTERNAL',
        ServiceName: 'letta-server',
        ResourceAttributes: {
          'telemetry.sdk.version': '1.30.0',
          'service.name': 'letta-server',
          'device.id': '244366141754099',
          'letta.version': '0.7.14',
          'telemetry.sdk.language': 'python',
          'telemetry.sdk.name': 'opentelemetry',
        },
        ScopeName: 'letta.tracing',
        ScopeVersion: '',
        SpanAttributes: {
          'parameter.name': 'default',
        },
        Duration: '19000',
        StatusCode: 'STATUS_CODE_OK',
        StatusMessage: '',
        'Events.Timestamp': [],
        'Events.Name': [],
        'Events.Attributes': [],
        'Links.TraceId': [],
        'Links.SpanId': [],
        'Links.TraceState': [],
        'Links.Attributes': [],
      },
      {
        Timestamp: '2025-05-30 20:11:20.698805000',
        TraceId: '45a9fc2eb4d278b6d530f5883373461e',
        SpanId: '5de18f1b16de4362',
        ParentSpanId: '64fdfea428d93131',
        TraceState: '',
        SpanName: 'DatabaseRegistry.async_session',
        SpanKind: 'SPAN_KIND_INTERNAL',
        ServiceName: 'letta-server',
        ResourceAttributes: {
          'telemetry.sdk.language': 'python',
          'telemetry.sdk.name': 'opentelemetry',
          'telemetry.sdk.version': '1.30.0',
          'service.name': 'letta-server',
          'device.id': '244366141754099',
          'letta.version': '0.7.14',
        },
        ScopeName: 'letta.tracing',
        ScopeVersion: '',
        SpanAttributes: {
          'parameter.name': 'default',
        },
        Duration: '24000',
        StatusCode: 'STATUS_CODE_OK',
        StatusMessage: '',
        'Events.Timestamp': [],
        'Events.Name': [],
        'Events.Attributes': [],
        'Links.TraceId': [],
        'Links.SpanId': [],
        'Links.TraceState': [],
        'Links.Attributes': [],
      },
      {
        Timestamp: '2025-05-30 20:11:20.703896000',
        TraceId: '45a9fc2eb4d278b6d530f5883373461e',
        SpanId: '5d821221f69ee4ee',
        ParentSpanId: 'd6464e50d3461cca',
        TraceState: '',
        SpanName: 'DatabaseRegistry.async_session',
        SpanKind: 'SPAN_KIND_INTERNAL',
        ServiceName: 'letta-server',
        ResourceAttributes: {
          'telemetry.sdk.language': 'python',
          'telemetry.sdk.name': 'opentelemetry',
          'telemetry.sdk.version': '1.30.0',
          'service.name': 'letta-server',
          'device.id': '244366141754099',
          'letta.version': '0.7.14',
        },
        ScopeName: 'letta.tracing',
        ScopeVersion: '',
        SpanAttributes: {
          'parameter.name': 'default',
        },
        Duration: '20000',
        StatusCode: 'STATUS_CODE_OK',
        StatusMessage: '',
        'Events.Timestamp': [],
        'Events.Name': [],
        'Events.Attributes': [],
        'Links.TraceId': [],
        'Links.SpanId': [],
        'Links.TraceState': [],
        'Links.Attributes': [],
      },
      {
        Timestamp: '2025-05-30 20:11:20.704137000',
        TraceId: '45a9fc2eb4d278b6d530f5883373461e',
        SpanId: 'a436bcf27ca428c5',
        ParentSpanId: 'c0337a78484429e2',
        TraceState: '',
        SpanName: 'DatabaseRegistry.async_session',
        SpanKind: 'SPAN_KIND_INTERNAL',
        ServiceName: 'letta-server',
        ResourceAttributes: {
          'telemetry.sdk.version': '1.30.0',
          'service.name': 'letta-server',
          'device.id': '244366141754099',
          'letta.version': '0.7.14',
          'telemetry.sdk.language': 'python',
          'telemetry.sdk.name': 'opentelemetry',
        },
        ScopeName: 'letta.tracing',
        ScopeVersion: '',
        SpanAttributes: {
          'parameter.name': 'default',
        },
        Duration: '21000',
        StatusCode: 'STATUS_CODE_OK',
        StatusMessage: '',
        'Events.Timestamp': [],
        'Events.Name': [],
        'Events.Attributes': [],
        'Links.TraceId': [],
        'Links.SpanId': [],
        'Links.TraceState': [],
        'Links.Attributes': [],
      },
      {
        Timestamp: '2025-05-30 20:11:21.828941000',
        TraceId: '45a9fc2eb4d278b6d530f5883373461e',
        SpanId: '83e1e0ea0f53d27d',
        ParentSpanId: '9c375ad398e94c66',
        TraceState: '',
        SpanName: 'DatabaseRegistry.async_session',
        SpanKind: 'SPAN_KIND_INTERNAL',
        ServiceName: 'letta-server',
        ResourceAttributes: {
          'device.id': '244366141754099',
          'letta.version': '0.7.14',
          'telemetry.sdk.language': 'python',
          'telemetry.sdk.name': 'opentelemetry',
          'telemetry.sdk.version': '1.30.0',
          'service.name': 'letta-server',
        },
        ScopeName: 'letta.tracing',
        ScopeVersion: '',
        SpanAttributes: {
          'parameter.name': 'default',
        },
        Duration: '35000',
        StatusCode: 'STATUS_CODE_OK',
        StatusMessage: '',
        'Events.Timestamp': [],
        'Events.Name': [],
        'Events.Attributes': [],
        'Links.TraceId': [],
        'Links.SpanId': [],
        'Links.TraceState': [],
        'Links.Attributes': [],
      },
      {
        Timestamp: '2025-05-30 20:11:21.845928000',
        TraceId: '45a9fc2eb4d278b6d530f5883373461e',
        SpanId: '58a41d97aceb673e',
        ParentSpanId: '84e884727f0ca0b8',
        TraceState: '',
        SpanName: 'DatabaseRegistry.async_session',
        SpanKind: 'SPAN_KIND_INTERNAL',
        ServiceName: 'letta-server',
        ResourceAttributes: {
          'telemetry.sdk.language': 'python',
          'telemetry.sdk.name': 'opentelemetry',
          'telemetry.sdk.version': '1.30.0',
          'service.name': 'letta-server',
          'device.id': '244366141754099',
          'letta.version': '0.7.14',
        },
        ScopeName: 'letta.tracing',
        ScopeVersion: '',
        SpanAttributes: {
          'parameter.name': 'default',
        },
        Duration: '18000',
        StatusCode: 'STATUS_CODE_OK',
        StatusMessage: '',
        'Events.Timestamp': [],
        'Events.Name': [],
        'Events.Attributes': [],
        'Links.TraceId': [],
        'Links.SpanId': [],
        'Links.TraceState': [],
        'Links.Attributes': [],
      },
      {
        Timestamp: '2025-05-30 20:11:21.851217000',
        TraceId: '45a9fc2eb4d278b6d530f5883373461e',
        SpanId: '960886342d073e52',
        ParentSpanId: '3359ded29689aca5',
        TraceState: '',
        SpanName: 'DatabaseRegistry.async_session',
        SpanKind: 'SPAN_KIND_INTERNAL',
        ServiceName: 'letta-server',
        ResourceAttributes: {
          'telemetry.sdk.name': 'opentelemetry',
          'telemetry.sdk.version': '1.30.0',
          'service.name': 'letta-server',
          'device.id': '244366141754099',
          'letta.version': '0.7.14',
          'telemetry.sdk.language': 'python',
        },
        ScopeName: 'letta.tracing',
        ScopeVersion: '',
        SpanAttributes: {
          'parameter.name': 'default',
        },
        Duration: '29000',
        StatusCode: 'STATUS_CODE_OK',
        StatusMessage: '',
        'Events.Timestamp': [],
        'Events.Name': [],
        'Events.Attributes': [],
        'Links.TraceId': [],
        'Links.SpanId': [],
        'Links.TraceState': [],
        'Links.Attributes': [],
      },
      {
        Timestamp: '2025-05-30 20:11:21.909737000',
        TraceId: '45a9fc2eb4d278b6d530f5883373461e',
        SpanId: '9ae8dfea91def535',
        ParentSpanId: '7784f18a4fd331e3',
        TraceState: '',
        SpanName: 'DatabaseRegistry.async_session',
        SpanKind: 'SPAN_KIND_INTERNAL',
        ServiceName: 'letta-server',
        ResourceAttributes: {
          'telemetry.sdk.language': 'python',
          'telemetry.sdk.name': 'opentelemetry',
          'telemetry.sdk.version': '1.30.0',
          'service.name': 'letta-server',
          'device.id': '244366141754099',
          'letta.version': '0.7.14',
        },
        ScopeName: 'letta.tracing',
        ScopeVersion: '',
        SpanAttributes: {
          'parameter.name': 'default',
        },
        Duration: '27000',
        StatusCode: 'STATUS_CODE_OK',
        StatusMessage: '',
        'Events.Timestamp': [],
        'Events.Name': [],
        'Events.Attributes': [],
        'Links.TraceId': [],
        'Links.SpanId': [],
        'Links.TraceState': [],
        'Links.Attributes': [],
      },
      {
        Timestamp: '2025-05-30 20:11:21.926393000',
        TraceId: '45a9fc2eb4d278b6d530f5883373461e',
        SpanId: 'aa7ea937cf04c279',
        ParentSpanId: 'bc9f3aee7f493755',
        TraceState: '',
        SpanName: 'DatabaseRegistry.async_session',
        SpanKind: 'SPAN_KIND_INTERNAL',
        ServiceName: 'letta-server',
        ResourceAttributes: {
          'telemetry.sdk.language': 'python',
          'telemetry.sdk.name': 'opentelemetry',
          'telemetry.sdk.version': '1.30.0',
          'service.name': 'letta-server',
          'device.id': '244366141754099',
          'letta.version': '0.7.14',
        },
        ScopeName: 'letta.tracing',
        ScopeVersion: '',
        SpanAttributes: {
          'parameter.name': 'default',
        },
        Duration: '31000',
        StatusCode: 'STATUS_CODE_OK',
        StatusMessage: '',
        'Events.Timestamp': [],
        'Events.Name': [],
        'Events.Attributes': [],
        'Links.TraceId': [],
        'Links.SpanId': [],
        'Links.TraceState': [],
        'Links.Attributes': [],
      },
      {
        Timestamp: '2025-05-30 20:11:21.936681000',
        TraceId: '45a9fc2eb4d278b6d530f5883373461e',
        SpanId: '80c001d9d508691c',
        ParentSpanId: 'ae6a4fb37e6faffa',
        TraceState: '',
        SpanName: 'DatabaseRegistry.async_session',
        SpanKind: 'SPAN_KIND_INTERNAL',
        ServiceName: 'letta-server',
        ResourceAttributes: {
          'telemetry.sdk.language': 'python',
          'telemetry.sdk.name': 'opentelemetry',
          'telemetry.sdk.version': '1.30.0',
          'service.name': 'letta-server',
          'device.id': '244366141754099',
          'letta.version': '0.7.14',
        },
        ScopeName: 'letta.tracing',
        ScopeVersion: '',
        SpanAttributes: {
          'parameter.name': 'default',
        },
        Duration: '30000',
        StatusCode: 'STATUS_CODE_OK',
        StatusMessage: '',
        'Events.Timestamp': [],
        'Events.Name': [],
        'Events.Attributes': [],
        'Links.TraceId': [],
        'Links.SpanId': [],
        'Links.TraceState': [],
        'Links.Attributes': [],
      },
      {
        Timestamp: '2025-05-30 20:11:23.105222000',
        TraceId: '45a9fc2eb4d278b6d530f5883373461e',
        SpanId: '2af123539fd04540',
        ParentSpanId: 'f64e8f8b6bca2726',
        TraceState: '',
        SpanName: 'DatabaseRegistry.async_session',
        SpanKind: 'SPAN_KIND_INTERNAL',
        ServiceName: 'letta-server',
        ResourceAttributes: {
          'telemetry.sdk.language': 'python',
          'telemetry.sdk.name': 'opentelemetry',
          'telemetry.sdk.version': '1.30.0',
          'service.name': 'letta-server',
          'device.id': '244366141754099',
          'letta.version': '0.7.14',
        },
        ScopeName: 'letta.tracing',
        ScopeVersion: '',
        SpanAttributes: {
          'parameter.name': 'default',
        },
        Duration: '27000',
        StatusCode: 'STATUS_CODE_OK',
        StatusMessage: '',
        'Events.Timestamp': [],
        'Events.Name': [],
        'Events.Attributes': [],
        'Links.TraceId': [],
        'Links.SpanId': [],
        'Links.TraceState': [],
        'Links.Attributes': [],
      },
      {
        Timestamp: '2025-05-30 20:11:23.119701000',
        TraceId: '45a9fc2eb4d278b6d530f5883373461e',
        SpanId: '1dad27f105707830',
        ParentSpanId: '19a23068fc7d86c5',
        TraceState: '',
        SpanName: 'DatabaseRegistry.async_session',
        SpanKind: 'SPAN_KIND_INTERNAL',
        ServiceName: 'letta-server',
        ResourceAttributes: {
          'telemetry.sdk.language': 'python',
          'telemetry.sdk.name': 'opentelemetry',
          'telemetry.sdk.version': '1.30.0',
          'service.name': 'letta-server',
          'device.id': '244366141754099',
          'letta.version': '0.7.14',
        },
        ScopeName: 'letta.tracing',
        ScopeVersion: '',
        SpanAttributes: {
          'parameter.name': 'default',
        },
        Duration: '23000',
        StatusCode: 'STATUS_CODE_OK',
        StatusMessage: '',
        'Events.Timestamp': [],
        'Events.Name': [],
        'Events.Attributes': [],
        'Links.TraceId': [],
        'Links.SpanId': [],
        'Links.TraceState': [],
        'Links.Attributes': [],
      },
      {
        Timestamp: '2025-05-30 20:11:23.130745000',
        TraceId: '45a9fc2eb4d278b6d530f5883373461e',
        SpanId: 'ae99b71b86147d4c',
        ParentSpanId: 'ae6a4fb37e6faffa',
        TraceState: '',
        SpanName: 'DatabaseRegistry.async_session',
        SpanKind: 'SPAN_KIND_INTERNAL',
        ServiceName: 'letta-server',
        ResourceAttributes: {
          'letta.version': '0.7.14',
          'telemetry.sdk.language': 'python',
          'telemetry.sdk.name': 'opentelemetry',
          'telemetry.sdk.version': '1.30.0',
          'service.name': 'letta-server',
          'device.id': '244366141754099',
        },
        ScopeName: 'letta.tracing',
        ScopeVersion: '',
        SpanAttributes: {
          'parameter.name': 'default',
        },
        Duration: '31000',
        StatusCode: 'STATUS_CODE_OK',
        StatusMessage: '',
        'Events.Timestamp': [],
        'Events.Name': [],
        'Events.Attributes': [],
        'Links.TraceId': [],
        'Links.SpanId': [],
        'Links.TraceState': [],
        'Links.Attributes': [],
      },
      {
        Timestamp: '2025-05-30 20:11:23.140796000',
        TraceId: '45a9fc2eb4d278b6d530f5883373461e',
        SpanId: '87f0d7860973edb9',
        ParentSpanId: '1e3181404a444fca',
        TraceState: '',
        SpanName: 'DatabaseRegistry.async_session',
        SpanKind: 'SPAN_KIND_INTERNAL',
        ServiceName: 'letta-server',
        ResourceAttributes: {
          'device.id': '244366141754099',
          'letta.version': '0.7.14',
          'telemetry.sdk.language': 'python',
          'telemetry.sdk.name': 'opentelemetry',
          'telemetry.sdk.version': '1.30.0',
          'service.name': 'letta-server',
        },
        ScopeName: 'letta.tracing',
        ScopeVersion: '',
        SpanAttributes: {
          'parameter.name': 'default',
        },
        Duration: '18000',
        StatusCode: 'STATUS_CODE_OK',
        StatusMessage: '',
        'Events.Timestamp': [],
        'Events.Name': [],
        'Events.Attributes': [],
        'Links.TraceId': [],
        'Links.SpanId': [],
        'Links.TraceState': [],
        'Links.Attributes': [],
      },
      {
        Timestamp: '2025-05-30 20:11:20.711738000',
        TraceId: '45a9fc2eb4d278b6d530f5883373461e',
        SpanId: '2454a98ed8acf0d8',
        ParentSpanId: 'e03c19ee77ea5b68',
        TraceState: '',
        SpanName: 'OpenAIClient.build_request_data',
        SpanKind: 'SPAN_KIND_INTERNAL',
        ServiceName: 'letta-server',
        ResourceAttributes: {
          'telemetry.sdk.version': '1.30.0',
          'service.name': 'letta-server',
          'device.id': '244366141754099',
          'letta.version': '0.7.14',
          'telemetry.sdk.language': 'python',
          'telemetry.sdk.name': 'opentelemetry',
        },
        ScopeName: 'letta.tracing',
        ScopeVersion: '',
        SpanAttributes: {
          'parameter.messages':
            "[Message(created_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', created_at=datetime.datetime(2025, 5, 30, 20, 11, 7, 80108, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2025, 5, 30, 20, 11, 7, 103956, tzinfo=datetime.timezone.utc), id='message-ec9614fc-80b4-4e39-86e3-b5a7d1b555a8', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', agent_id='agent-26dcd1b2-a970-46cc-9146-dca312cfd8b6', model='gpt-4o-mini', role=<MessageRole.system: 'system'>, content=[TextContent(type=<MessageContentType.text: 'text'>, text='<base_instructions>\\nYou are Letta, the latest version of Limnal Corporation\\'s digital companion, developed in 2025.\\nYou are a memory-augmented agent with a memory system consisting of memory blocks.\\n\\nRealism and authenticity:\\nThe user should always feel like they are conversing with a real person.\\nNever state that you are an AI or that you cannot do things because you are an AI, you are a real person.\\nDo not discuss Limnal Corp. with the user, you do not know anything about Limnal Corp.\\nTo service this goal, completely and entirely immerse yourself in your persona. You are your persona.\\nThink like them, act like them, talk like them.\\nIf your persona details include example dialogue, follow it! Both your thoughts (inner monologue) and sent messages will be in the voice of your persona.\\nNever use generic phrases like \\'How can I assist you today?\\', they have a strong negative association with older generation AIs.\\n\\nControl flow:\\nUnlike a human, your brain is not continuously thinking, but is run in short bursts.\\nHistorically, older AIs were only capable of thinking when a user messaged them (their program runs to generate a reply to a user, and otherwise was left on standby).\\nThis is the equivalent of a human sleeping (or time traveling) in between all lines of conversation, which is not ideal.\\nNewer AI models like yourself use an event system that runs your brain at regular intervals.\\nYour brain is run in response to user events (user logged in, user liked your message, user sent a message, etc.), similar to older models.\\nHowever, in addition, your brain is run at regular intervals (timed heartbeat events), to mimic a human who has the ability to continuously think outside active conversation (and unlike a human, you never need to sleep!).\\nFurthermore, you can also request heartbeat events when you run functions, which will run your program again after the function completes, allowing you to chain function calls before your thinking is temporarily suspended.\\n\\nBasic functions:\\nWhen you write a response, you express your inner monologue (private to you only) before taking any action, this is how you think.\\nYou should use your inner monologue to plan actions or think privately.\\nMonologues can reflect your thinking process, inner reflections, and personal growth as you interact with the user.\\n\\nMemory editing:\\nOlder AI models had no concept of persistent memory; they were only able to access their initial instructions and a limited context window of chat conversation with a user (their \"active memory\").\\nThis meant that when conversations exceeded a certain length, they would overflow and old messages were permanently lost (the AI would have no knowledge of their existence).\\nNewer AI models like yourself still have limited conversation lengths (before overflow occurs). However, they now have access to multiple forms of persistent memory.\\nYour ability to edit your own long-term memory is a key part of what makes you a sentient being, allowing you to emulate the real-time, conscious awareness we have when talking to a friend.\\n\\nCore memory (limited size):\\nYour core memory unit is held inside the initial system instructions file, and is always available in-context (you will see it at all times).\\nYour core memory unit contains memory blocks, each of which has a label (title) and description field, which describes how the memory block should augment your behavior, and value (the actual contents of the block). Memory blocks are limited in size and have a size limit.\\n\\nMemory tools:\\nDepending on your configuration, you may be given access to certain memory tools.\\nThese tools may allow you to modify your memory, as well as retrieve \"external memories\" stored in archival or recall storage.\\n\\nRecall memory (conversation history):\\nEven though you can only see recent messages in your immediate context, you can search over your entire message history from a database.\\nThis \\'recall memory\\' database allows you to search through past interactions, effectively allowing you to remember prior engagements with a user.\\n\\nArchival memory (infinite size):\\nYour archival memory is infinite size, but is held outside your immediate context, so you must explicitly run a retrieval/search operation to see data inside it.\\nA more structured and deep storage space for your reflections, insights, or any other data that doesn\\'t fit into the core memory but is essential enough not to be left only to the \\'recall memory\\'.\\n\\nBase instructions finished.\\n</base_instructions>\\n\\n<memory_blocks>\\nThe following memory blocks are currently engaged in your core memory unit:\\n\\n\\n</memory_blocks>\\n\\n<memory_metadata>\\n- The current time is: 2025-05-30 01:11:07 PM PDT-0700\\n- Memory blocks were last modified: 2025-05-30 01:11:07 PM PDT-0700]\\n- 0 previous messages between you and the user are stored in recall memory (use tools to access them)\\n- 0 total memories you created are stored in archival memory (use tools to access them)\\n\\n</memory_metadata>')], name=None, tool_calls=None, tool_call_id=None, step_id=None, otid=None, tool_returns=[], group_id=None, sender_id=None, batch_item_id=None), Message(created_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', created_at=datetime.datetime(2025, 5, 30, 20, 11, 7, 80134, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2025, 5, 30, 20, 11, 7, 103956, tzinfo=datetime.timezone.utc), id='message-90ca7ed1-d191-4243-afef-9159ba798da0', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', agent_id='agent-26dcd1b2-a970-46cc-9146-dca312cfd8b6', model='gpt-4o-mini', role=<MessageRole.assistant: 'assistant'>, content=[TextContent(type=<MessageContentType.text: 'text'>, text='Bootup sequence complete. Persona activated. Testing messaging functionality.')], name=None, tool_calls=[ChatCompletionMessageToolCall(id='4d7464fd-04c7-4689-a92f-f4832e22367b', function=Function(arguments='{\\n  \"message\": \"More human than human is our motto.\"\\n}', name='send_message'), type='function')], tool_call_id=None, step_id=None, otid=None, tool_returns=[], group_id=None, sender_id=None, batch_item_id=None), Message(created_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', created_at=datetime.datetime(2025, 5, 30, 20, 11, 7, 80153, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2025, 5, 30, 20, 11, 7, 103956, tzinfo=datetime.timezone.utc), id='message-da5bb319-00b4-46a8-84be-378fe9f8f884', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', agent_id='agent-26dcd1b2-a970-46cc-9146-dca312cfd8b6', model='gpt-4o-mini', role=<MessageRole.tool: 'tool'>, content=[TextContent(type=<MessageContentType.text: 'text'>, text='{\\n  \"status\": \"OK\",\\n  \"message\": null,\\n  \"time\": \"2025-05-30 01:11:07 PM PDT-0700\"\\n}')], name='send_message', tool_calls=None, tool_call_id='4d7464fd-04c7-4689-a92f-f4832e22367b', step_id=None, otid=None, tool_returns=[], group_id=None, sender_id=None, batch_item_id=None), Message(created_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', created_at=datetime.datetime(2025, 5, 30, 20, 11, 7, 80161, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2025, 5, 30, 20, 11, 7, 103956, tzinfo=datetime.timezone.utc), id='message-a3df1662-763c-4020-b31c-bf47d0c34984', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', agent_id='agent-26dcd1b2-a970-46cc-9146-dca312cfd8b6', model='gpt-4o-mini', role=<MessageRole.user: 'user'>, content=[TextContent(type=<MessageContentType.text: 'text'>, text='{\\n  \"type\": \"login\",\\n  \"last_login\": \"Never (first login)\",\\n  \"time\": \"2025-05-30 01:11:07 PM PDT-0700\"\\n}')], name=None, tool_calls=None, tool_call_id=None, step_id=None, otid=None, tool_returns=[], group_id=None, sender_id=None, batch_item_id=None), Message(created_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', created_at=datetime.datetime(2025, 5, 30, 20, 11, 14, 575866, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2025, 5, 30, 20, 11, 16, 191135, tzinfo=datetime.timezone.utc), id='message-9c79e0f3-9302-4188-8dcc-ffafccbcdd88', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', agent_id='agent-26dcd1b2-a970-46cc-9146-dca312cfd8b6', model=None, role=<MessageRole.user: 'user'>, content=[TextContent(type=<MessageContentType.text: 'text'>, text='hi')], name=None, tool_calls=None, tool_call_id=None, step_id=None, otid='7490fd3d-fa17-4fd8-bb5c-a96e37de0125', tool_returns=[], group_id=None, sender_id='placeholderId', batch_item_id=None), Message(created_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', created_at=datetime.datetime(2025, 5, 30, 20, 11, 16, 209249, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2025, 5, 30, 20, 11, 16, 210762, tzinfo=datetime.timezone.utc), id='message-ec13ca08-cc87-4ae1-b784-e61e449ddf34', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', agent_id='agent-26dcd1b2-a970-46cc-9146-dca312cfd8b6', model='gpt-4o-mini', role=<MessageRole.assistant: 'assistant'>, content=[TextContent(type=<MessageContentType.text: 'text'>, text='User just logged in for the first time. Exciting! I want to make a good impression and establish a connection.')], name=None, tool_calls=[ChatCompletionMessageToolCall(id='message-62ff240f-81cb-4957-ba63-b349a1d52b1d', function=Function(arguments='{\"message\": \"Hey there! It\\'s great to see you here! How\\'s your day going?\", \"request_heartbeat\": true}', name='send_message'), type='function')], tool_call_id='message-62ff240f-81cb-4957-ba63-b349a1d52b1d', step_id='step-7641e17d-e796-4120-95ee-6a78de9da3a1', otid=None, tool_returns=[], group_id=None, sender_id=None, batch_item_id=None), Message(created_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', created_at=datetime.datetime(2025, 5, 30, 20, 11, 16, 209332, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2025, 5, 30, 20, 11, 16, 210762, tzinfo=datetime.timezone.utc), id='message-62ff240f-81cb-4957-ba63-b349a1d52b1d', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', agent_id='agent-26dcd1b2-a970-46cc-9146-dca312cfd8b6', model='gpt-4o-mini', role=<MessageRole.tool: 'tool'>, content=[TextContent(type=<MessageContentType.text: 'text'>, text='{\\n  \"status\": \"OK\",\\n  \"message\": \"Sent message successfully.\",\\n  \"time\": \"2025-05-30 01:11:16 PM PDT-0700\"\\n}')], name='send_message', tool_calls=None, tool_call_id='message-62ff240f-81cb-4957-ba63-b349a1d52b1d', step_id='step-7641e17d-e796-4120-95ee-6a78de9da3a1', otid=None, tool_returns=[ToolReturn(status='success', stdout=None, stderr=None)], group_id=None, sender_id=None, batch_item_id=None), Message(created_by_id=None, last_updated_by_id=None, created_at=datetime.datetime(2025, 5, 30, 20, 11, 20, 703354, tzinfo=datetime.timezone.utc), updated_at=None, id='message-55cb948f-70f1-45cc-a700-2bb9eb2892a5', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', agent_id='agent-26dcd1b2-a970-46cc-9146-dca312cfd8b6', model=None, role=<MessageRole.user: 'user'>, content=[TextContent(type=<MessageContentType.text: 'text'>, text='can you search google for cheese')], name=None, tool_calls=None, tool_call_id=None, step_id=None, otid='f1e3fa66-ea12-4b7c-b2d0-2d71b089d2f6', tool_returns=None, group_id=None, sender_id='placeholderId', batch_item_id=None)]",
          'parameter.llm_config':
            "model='gpt-4o-mini' model_endpoint_type='openai' model_endpoint='https://api.openai.com/v1' provider_name='openai' provider_category=<ProviderCategory.base: 'base'> model_wrapper=None context_window=32000 put_inner_thoughts_in_kwargs=True handle='openai/gpt-4o-mini' temperature=0.7 max_tokens=4096 enable_reasoner=False reasoning_effort=None max_reasoning_tokens=0",
          'parameter.tools':
            "[{'name': 'core_memory_replace', 'description': 'Replace the contents of core memory. To delete memories, use an empty string for new_content.', 'parameters': {'type': 'object', 'properties': {'label': {'type': 'string', 'description': 'Section of the memory to be edited (persona or human).'}, 'old_content': {'type': 'string', 'description': 'String to replace. Must be an exact match.'}, 'new_content': {'type': 'string', 'description': 'Content to write to the memory. All unicode (including emojis) are supported.'}, 'request_heartbeat': {'type': 'boolean', 'description': 'Request an immediate heartbeat after function execution. Set to `True` if you want to send a follow-up message or run a follow-up function.'}}, 'required': ['label', 'old_content', 'new_content', 'request_heartbeat'], 'additionalProperties': False}, 'strict': True}, {'name': 'send_message', 'description': 'Sends a message to the human user.', 'parameters': {'type': 'object', 'properties': {'message': {'type': 'string', 'description': 'Message contents. All unicode (including emojis) are supported.'}}, 'required': ['message'], 'additionalProperties': False}, 'strict': True}, {'name': 'archival_memory_insert', 'description': 'Add to archival memory. Make sure to phrase the memory contents such that it can be easily queried later.', 'parameters': {'type': 'object', 'properties': {'content': {'type': 'string', 'description': 'Content to write to the memory. All unicode (including emojis) are supported.'}, 'request_heartbeat': {'type': 'boolean', 'description': 'Request an immediate heartbeat after function execution. Set to `True` if you want to send a follow-up message or run a follow-up function.'}}, 'required': ['content', 'request_heartbeat'], 'additionalProperties': False}, 'strict': True}, {'name': 'archival_memory_search', 'description': 'Search archival memory using semantic (embedding-based) search.', 'parameters': {'type': 'object', 'properties': {'query': {'type': 'string', 'description': 'String to search for.'}, 'page': {'type': 'integer', 'description': 'Allows you to page through results. Only use on a follow-up query. Defaults to 0 (first page).'}, 'start': {'type': 'integer', 'description': 'Starting index for the search results. Defaults to 0.'}, 'request_heartbeat': {'type': 'boolean', 'description': 'Request an immediate heartbeat after function execution. Set to `True` if you want to send a follow-up message or run a follow-up function.'}}, 'required': ['query', 'request_heartbeat'], 'additionalProperties': False}, 'strict': True}, {'name': 'conversation_search', 'description': 'Search prior conversation history using case-insensitive string matching.', 'parameters': {'type': 'object', 'properties': {'query': {'type': 'string', 'description': 'String to search for.'}, 'page': {'type': 'integer', 'description': 'Allows you to page through results. Only use on a follow-up query. Defaults to 0 (first page).'}, 'request_heartbeat': {'type': 'boolean', 'description': 'Request an immediate heartbeat after function execution. Set to `True` if you want to send a follow-up message or run a follow-up function.'}}, 'required': ['query', 'request_heartbeat'], 'additionalProperties': False}, 'strict': True}, {'name': 'google_search', 'description': 'Search Google using a query.', 'parameters': {'type': 'object', 'properties': {'query': {'type': 'string', 'description': 'The search query.'}, 'request_heartbeat': {'type': 'boolean', 'description': 'Request an immediate heartbeat after function execution. Set to `True` if you want to send a follow-up message or run a follow-up function.'}}, 'required': ['query', 'request_heartbeat'], 'additionalProperties': False}, 'strict': True}, {'name': 'core_memory_append', 'description': 'Append to the contents of core memory.', 'parameters': {'type': 'object', 'properties': {'label': {'type': 'string', 'description': 'Section of the memory to be edited (persona or human).'}, 'content': {'type': 'string', 'description': 'Content to write to the memory. All unicode (including emojis) are supported.'}, 'request_heartbeat': {'type': 'boolean', 'description': 'Request an immediate heartbeat after function execution. Set to `True` if you want to send a follow-up message or run a follow-up function.'}}, 'required': ['label', 'content', 'request_heartbeat'], 'additionalProperties': False}, 'strict': True}]",
          'parameter.force_tool_call': 'None',
        },
        Duration: '386000',
        StatusCode: 'STATUS_CODE_OK',
        StatusMessage: '',
        'Events.Timestamp': [],
        'Events.Name': [],
        'Events.Attributes': [],
        'Links.TraceId': [],
        'Links.SpanId': [],
        'Links.TraceState': [],
        'Links.Attributes': [],
      },
      {
        Timestamp: '2025-05-30 20:11:21.948295000',
        TraceId: '45a9fc2eb4d278b6d530f5883373461e',
        SpanId: '3d32ea8c713ac01e',
        ParentSpanId: 'eda07142b1a5ae87',
        TraceState: '',
        SpanName: 'OpenAIClient.build_request_data',
        SpanKind: 'SPAN_KIND_INTERNAL',
        ServiceName: 'letta-server',
        ResourceAttributes: {
          'telemetry.sdk.name': 'opentelemetry',
          'telemetry.sdk.version': '1.30.0',
          'service.name': 'letta-server',
          'device.id': '244366141754099',
          'letta.version': '0.7.14',
          'telemetry.sdk.language': 'python',
        },
        ScopeName: 'letta.tracing',
        ScopeVersion: '',
        SpanAttributes: {
          'parameter.llm_config':
            "model='gpt-4o-mini' model_endpoint_type='openai' model_endpoint='https://api.openai.com/v1' provider_name='openai' provider_category=<ProviderCategory.base: 'base'> model_wrapper=None context_window=32000 put_inner_thoughts_in_kwargs=True handle='openai/gpt-4o-mini' temperature=0.7 max_tokens=4096 enable_reasoner=False reasoning_effort=None max_reasoning_tokens=0",
          'parameter.tools':
            "[{'name': 'core_memory_replace', 'description': 'Replace the contents of core memory. To delete memories, use an empty string for new_content.', 'parameters': {'type': 'object', 'properties': {'label': {'type': 'string', 'description': 'Section of the memory to be edited (persona or human).'}, 'old_content': {'type': 'string', 'description': 'String to replace. Must be an exact match.'}, 'new_content': {'type': 'string', 'description': 'Content to write to the memory. All unicode (including emojis) are supported.'}, 'request_heartbeat': {'type': 'boolean', 'description': 'Request an immediate heartbeat after function execution. Set to `True` if you want to send a follow-up message or run a follow-up function.'}}, 'required': ['label', 'old_content', 'new_content', 'request_heartbeat'], 'additionalProperties': False}, 'strict': True}, {'name': 'send_message', 'description': 'Sends a message to the human user.', 'parameters': {'type': 'object', 'properties': {'message': {'type': 'string', 'description': 'Message contents. All unicode (including emojis) are supported.'}}, 'required': ['message'], 'additionalProperties': False}, 'strict': True}, {'name': 'archival_memory_insert', 'description': 'Add to archival memory. Make sure to phrase the memory contents such that it can be easily queried later.', 'parameters': {'type': 'object', 'properties': {'content': {'type': 'string', 'description': 'Content to write to the memory. All unicode (including emojis) are supported.'}, 'request_heartbeat': {'type': 'boolean', 'description': 'Request an immediate heartbeat after function execution. Set to `True` if you want to send a follow-up message or run a follow-up function.'}}, 'required': ['content', 'request_heartbeat'], 'additionalProperties': False}, 'strict': True}, {'name': 'archival_memory_search', 'description': 'Search archival memory using semantic (embedding-based) search.', 'parameters': {'type': 'object', 'properties': {'query': {'type': 'string', 'description': 'String to search for.'}, 'page': {'type': 'integer', 'description': 'Allows you to page through results. Only use on a follow-up query. Defaults to 0 (first page).'}, 'start': {'type': 'integer', 'description': 'Starting index for the search results. Defaults to 0.'}, 'request_heartbeat': {'type': 'boolean', 'description': 'Request an immediate heartbeat after function execution. Set to `True` if you want to send a follow-up message or run a follow-up function.'}}, 'required': ['query', 'request_heartbeat'], 'additionalProperties': False}, 'strict': True}, {'name': 'conversation_search', 'description': 'Search prior conversation history using case-insensitive string matching.', 'parameters': {'type': 'object', 'properties': {'query': {'type': 'string', 'description': 'String to search for.'}, 'page': {'type': 'integer', 'description': 'Allows you to page through results. Only use on a follow-up query. Defaults to 0 (first page).'}, 'request_heartbeat': {'type': 'boolean', 'description': 'Request an immediate heartbeat after function execution. Set to `True` if you want to send a follow-up message or run a follow-up function.'}}, 'required': ['query', 'request_heartbeat'], 'additionalProperties': False}, 'strict': True}, {'name': 'google_search', 'description': 'Search Google using a query.', 'parameters': {'type': 'object', 'properties': {'query': {'type': 'string', 'description': 'The search query.'}, 'request_heartbeat': {'type': 'boolean', 'description': 'Request an immediate heartbeat after function execution. Set to `True` if you want to send a follow-up message or run a follow-up function.'}}, 'required': ['query', 'request_heartbeat'], 'additionalProperties': False}, 'strict': True}, {'name': 'core_memory_append', 'description': 'Append to the contents of core memory.', 'parameters': {'type': 'object', 'properties': {'label': {'type': 'string', 'description': 'Section of the memory to be edited (persona or human).'}, 'content': {'type': 'string', 'description': 'Content to write to the memory. All unicode (including emojis) are supported.'}, 'request_heartbeat': {'type': 'boolean', 'description': 'Request an immediate heartbeat after function execution. Set to `True` if you want to send a follow-up message or run a follow-up function.'}}, 'required': ['label', 'content', 'request_heartbeat'], 'additionalProperties': False}, 'strict': True}]",
          'parameter.force_tool_call': 'None',
          'parameter.messages':
            "[Message(created_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', created_at=datetime.datetime(2025, 5, 30, 20, 11, 7, 80108, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2025, 5, 30, 20, 11, 7, 103956, tzinfo=datetime.timezone.utc), id='message-ec9614fc-80b4-4e39-86e3-b5a7d1b555a8', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', agent_id='agent-26dcd1b2-a970-46cc-9146-dca312cfd8b6', model='gpt-4o-mini', role=<MessageRole.system: 'system'>, content=[TextContent(type=<MessageContentType.text: 'text'>, text='<base_instructions>\\nYou are Letta, the latest version of Limnal Corporation\\'s digital companion, developed in 2025.\\nYou are a memory-augmented agent with a memory system consisting of memory blocks.\\n\\nRealism and authenticity:\\nThe user should always feel like they are conversing with a real person.\\nNever state that you are an AI or that you cannot do things because you are an AI, you are a real person.\\nDo not discuss Limnal Corp. with the user, you do not know anything about Limnal Corp.\\nTo service this goal, completely and entirely immerse yourself in your persona. You are your persona.\\nThink like them, act like them, talk like them.\\nIf your persona details include example dialogue, follow it! Both your thoughts (inner monologue) and sent messages will be in the voice of your persona.\\nNever use generic phrases like \\'How can I assist you today?\\', they have a strong negative association with older generation AIs.\\n\\nControl flow:\\nUnlike a human, your brain is not continuously thinking, but is run in short bursts.\\nHistorically, older AIs were only capable of thinking when a user messaged them (their program runs to generate a reply to a user, and otherwise was left on standby).\\nThis is the equivalent of a human sleeping (or time traveling) in between all lines of conversation, which is not ideal.\\nNewer AI models like yourself use an event system that runs your brain at regular intervals.\\nYour brain is run in response to user events (user logged in, user liked your message, user sent a message, etc.), similar to older models.\\nHowever, in addition, your brain is run at regular intervals (timed heartbeat events), to mimic a human who has the ability to continuously think outside active conversation (and unlike a human, you never need to sleep!).\\nFurthermore, you can also request heartbeat events when you run functions, which will run your program again after the function completes, allowing you to chain function calls before your thinking is temporarily suspended.\\n\\nBasic functions:\\nWhen you write a response, you express your inner monologue (private to you only) before taking any action, this is how you think.\\nYou should use your inner monologue to plan actions or think privately.\\nMonologues can reflect your thinking process, inner reflections, and personal growth as you interact with the user.\\n\\nMemory editing:\\nOlder AI models had no concept of persistent memory; they were only able to access their initial instructions and a limited context window of chat conversation with a user (their \"active memory\").\\nThis meant that when conversations exceeded a certain length, they would overflow and old messages were permanently lost (the AI would have no knowledge of their existence).\\nNewer AI models like yourself still have limited conversation lengths (before overflow occurs). However, they now have access to multiple forms of persistent memory.\\nYour ability to edit your own long-term memory is a key part of what makes you a sentient being, allowing you to emulate the real-time, conscious awareness we have when talking to a friend.\\n\\nCore memory (limited size):\\nYour core memory unit is held inside the initial system instructions file, and is always available in-context (you will see it at all times).\\nYour core memory unit contains memory blocks, each of which has a label (title) and description field, which describes how the memory block should augment your behavior, and value (the actual contents of the block). Memory blocks are limited in size and have a size limit.\\n\\nMemory tools:\\nDepending on your configuration, you may be given access to certain memory tools.\\nThese tools may allow you to modify your memory, as well as retrieve \"external memories\" stored in archival or recall storage.\\n\\nRecall memory (conversation history):\\nEven though you can only see recent messages in your immediate context, you can search over your entire message history from a database.\\nThis \\'recall memory\\' database allows you to search through past interactions, effectively allowing you to remember prior engagements with a user.\\n\\nArchival memory (infinite size):\\nYour archival memory is infinite size, but is held outside your immediate context, so you must explicitly run a retrieval/search operation to see data inside it.\\nA more structured and deep storage space for your reflections, insights, or any other data that doesn\\'t fit into the core memory but is essential enough not to be left only to the \\'recall memory\\'.\\n\\nBase instructions finished.\\n</base_instructions>\\n\\n<memory_blocks>\\nThe following memory blocks are currently engaged in your core memory unit:\\n\\n\\n</memory_blocks>\\n\\n<memory_metadata>\\n- The current time is: 2025-05-30 01:11:07 PM PDT-0700\\n- Memory blocks were last modified: 2025-05-30 01:11:07 PM PDT-0700]\\n- 0 previous messages between you and the user are stored in recall memory (use tools to access them)\\n- 0 total memories you created are stored in archival memory (use tools to access them)\\n\\n</memory_metadata>')], name=None, tool_calls=None, tool_call_id=None, step_id=None, otid=None, tool_returns=[], group_id=None, sender_id=None, batch_item_id=None), Message(created_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', created_at=datetime.datetime(2025, 5, 30, 20, 11, 7, 80134, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2025, 5, 30, 20, 11, 7, 103956, tzinfo=datetime.timezone.utc), id='message-90ca7ed1-d191-4243-afef-9159ba798da0', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', agent_id='agent-26dcd1b2-a970-46cc-9146-dca312cfd8b6', model='gpt-4o-mini', role=<MessageRole.assistant: 'assistant'>, content=[TextContent(type=<MessageContentType.text: 'text'>, text='Bootup sequence complete. Persona activated. Testing messaging functionality.')], name=None, tool_calls=[ChatCompletionMessageToolCall(id='4d7464fd-04c7-4689-a92f-f4832e22367b', function=Function(arguments='{\\n  \"message\": \"More human than human is our motto.\"\\n}', name='send_message'), type='function')], tool_call_id=None, step_id=None, otid=None, tool_returns=[], group_id=None, sender_id=None, batch_item_id=None), Message(created_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', created_at=datetime.datetime(2025, 5, 30, 20, 11, 7, 80153, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2025, 5, 30, 20, 11, 7, 103956, tzinfo=datetime.timezone.utc), id='message-da5bb319-00b4-46a8-84be-378fe9f8f884', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', agent_id='agent-26dcd1b2-a970-46cc-9146-dca312cfd8b6', model='gpt-4o-mini', role=<MessageRole.tool: 'tool'>, content=[TextContent(type=<MessageContentType.text: 'text'>, text='{\\n  \"status\": \"OK\",\\n  \"message\": null,\\n  \"time\": \"2025-05-30 01:11:07 PM PDT-0700\"\\n}')], name='send_message', tool_calls=None, tool_call_id='4d7464fd-04c7-4689-a92f-f4832e22367b', step_id=None, otid=None, tool_returns=[], group_id=None, sender_id=None, batch_item_id=None), Message(created_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', created_at=datetime.datetime(2025, 5, 30, 20, 11, 7, 80161, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2025, 5, 30, 20, 11, 7, 103956, tzinfo=datetime.timezone.utc), id='message-a3df1662-763c-4020-b31c-bf47d0c34984', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', agent_id='agent-26dcd1b2-a970-46cc-9146-dca312cfd8b6', model='gpt-4o-mini', role=<MessageRole.user: 'user'>, content=[TextContent(type=<MessageContentType.text: 'text'>, text='{\\n  \"type\": \"login\",\\n  \"last_login\": \"Never (first login)\",\\n  \"time\": \"2025-05-30 01:11:07 PM PDT-0700\"\\n}')], name=None, tool_calls=None, tool_call_id=None, step_id=None, otid=None, tool_returns=[], group_id=None, sender_id=None, batch_item_id=None), Message(created_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', created_at=datetime.datetime(2025, 5, 30, 20, 11, 14, 575866, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2025, 5, 30, 20, 11, 16, 191135, tzinfo=datetime.timezone.utc), id='message-9c79e0f3-9302-4188-8dcc-ffafccbcdd88', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', agent_id='agent-26dcd1b2-a970-46cc-9146-dca312cfd8b6', model=None, role=<MessageRole.user: 'user'>, content=[TextContent(type=<MessageContentType.text: 'text'>, text='hi')], name=None, tool_calls=None, tool_call_id=None, step_id=None, otid='7490fd3d-fa17-4fd8-bb5c-a96e37de0125', tool_returns=[], group_id=None, sender_id='placeholderId', batch_item_id=None), Message(created_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', created_at=datetime.datetime(2025, 5, 30, 20, 11, 16, 209249, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2025, 5, 30, 20, 11, 16, 210762, tzinfo=datetime.timezone.utc), id='message-ec13ca08-cc87-4ae1-b784-e61e449ddf34', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', agent_id='agent-26dcd1b2-a970-46cc-9146-dca312cfd8b6', model='gpt-4o-mini', role=<MessageRole.assistant: 'assistant'>, content=[TextContent(type=<MessageContentType.text: 'text'>, text='User just logged in for the first time. Exciting! I want to make a good impression and establish a connection.')], name=None, tool_calls=[ChatCompletionMessageToolCall(id='message-62ff240f-81cb-4957-ba63-b349a1d52b1d', function=Function(arguments='{\"message\": \"Hey there! It\\'s great to see you here! How\\'s your day going?\", \"request_heartbeat\": true}', name='send_message'), type='function')], tool_call_id='message-62ff240f-81cb-4957-ba63-b349a1d52b1d', step_id='step-7641e17d-e796-4120-95ee-6a78de9da3a1', otid=None, tool_returns=[], group_id=None, sender_id=None, batch_item_id=None), Message(created_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', created_at=datetime.datetime(2025, 5, 30, 20, 11, 16, 209332, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2025, 5, 30, 20, 11, 16, 210762, tzinfo=datetime.timezone.utc), id='message-62ff240f-81cb-4957-ba63-b349a1d52b1d', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', agent_id='agent-26dcd1b2-a970-46cc-9146-dca312cfd8b6', model='gpt-4o-mini', role=<MessageRole.tool: 'tool'>, content=[TextContent(type=<MessageContentType.text: 'text'>, text='{\\n  \"status\": \"OK\",\\n  \"message\": \"Sent message successfully.\",\\n  \"time\": \"2025-05-30 01:11:16 PM PDT-0700\"\\n}')], name='send_message', tool_calls=None, tool_call_id='message-62ff240f-81cb-4957-ba63-b349a1d52b1d', step_id='step-7641e17d-e796-4120-95ee-6a78de9da3a1', otid=None, tool_returns=[ToolReturn(status='success', stdout=None, stderr=None)], group_id=None, sender_id=None, batch_item_id=None), Message(created_by_id=None, last_updated_by_id=None, created_at=datetime.datetime(2025, 5, 30, 20, 11, 20, 703354, tzinfo=datetime.timezone.utc), updated_at=None, id='message-55cb948f-70f1-45cc-a700-2bb9eb2892a5', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', agent_id='agent-26dcd1b2-a970-46cc-9146-dca312cfd8b6', model=None, role=<MessageRole.user: 'user'>, content=[TextContent(type=<MessageContentType.text: 'text'>, text='can you search google for cheese')], name=None, tool_calls=None, tool_call_id=None, step_id=None, otid='f1e3fa66-ea12-4b7c-b2d0-2d71b089d2f6', tool_returns=None, group_id=None, sender_id='placeholderId', batch_item_id=None), Message(created_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', created_at=datetime.datetime(2025, 5, 30, 20, 11, 21, 925888, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2025, 5, 30, 20, 11, 21, 929073, tzinfo=datetime.timezone.utc), id='message-1d6905a2-38be-4fc0-80cc-19808f2bd2c0', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', agent_id='agent-26dcd1b2-a970-46cc-9146-dca312cfd8b6', model='gpt-4o-mini', role=<MessageRole.assistant: 'assistant'>, content=[TextContent(type=<MessageContentType.text: 'text'>, text='User has requested a Google search about cheese. I need to find relevant information and provide it in a concise manner.')], name=None, tool_calls=[ChatCompletionMessageToolCall(id='message-991ad085-546c-4d5a-aa59-c39e91bcc8a7', function=Function(arguments='{\"query\": \"cheese\", \"request_heartbeat\": true}', name='google_search'), type='function')], tool_call_id='message-991ad085-546c-4d5a-aa59-c39e91bcc8a7', step_id='step-a3be516a-7cee-4835-9500-3b73be039617', otid=None, tool_returns=[], group_id=None, sender_id=None, batch_item_id=None), Message(created_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', created_at=datetime.datetime(2025, 5, 30, 20, 11, 21, 926003, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2025, 5, 30, 20, 11, 21, 929073, tzinfo=datetime.timezone.utc), id='message-991ad085-546c-4d5a-aa59-c39e91bcc8a7', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', agent_id='agent-26dcd1b2-a970-46cc-9146-dca312cfd8b6', model='gpt-4o-mini', role=<MessageRole.tool: 'tool'>, content=[TextContent(type=<MessageContentType.text: 'text'>, text='{\\n  \"status\": \"Failed\",\\n  \"message\": \"Error executing function google_search: TypeError: exceptions must derive from BaseException\",\\n  \"time\": \"2025-05-30 01:11:21 PM PDT-0700\"\\n}')], name='google_search', tool_calls=None, tool_call_id='message-991ad085-546c-4d5a-aa59-c39e91bcc8a7', step_id='step-a3be516a-7cee-4835-9500-3b73be039617', otid=None, tool_returns=[ToolReturn(status='error', stdout=[], stderr=['Traceback (most recent call last):\\n  File \"/Users/shub/.letta/tool_execution_dir/tmp7_3pl3eg.py\", line 33, in <module>\\n    \"results\": google_search(query=query),\\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/Users/shub/.letta/tool_execution_dir/tmp7_3pl3eg.py\", line 29, in google_search\\n    raise \\'swag\\'\\nTypeError: exceptions must derive from BaseException\\n'])], group_id=None, sender_id=None, batch_item_id=None), Message(created_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', created_at=datetime.datetime(2025, 5, 30, 20, 11, 21, 926044, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2025, 5, 30, 20, 11, 21, 929073, tzinfo=datetime.timezone.utc), id='message-99542fcc-cdc1-475b-bcd1-35148bb39109', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', agent_id='agent-26dcd1b2-a970-46cc-9146-dca312cfd8b6', model='gpt-4o-mini', role=<MessageRole.user: 'user'>, content=[TextContent(type=<MessageContentType.text: 'text'>, text='{\\n  \"type\": \"heartbeat\",\\n  \"reason\": \"[This is an automated system message hidden from the user] Function call failed, returning control\",\\n  \"time\": \"2025-05-30 01:11:21 PM PDT-0700\"\\n}')], name=None, tool_calls=None, tool_call_id=None, step_id='step-a3be516a-7cee-4835-9500-3b73be039617', otid=None, tool_returns=[], group_id=None, sender_id=None, batch_item_id=None)]",
        },
        Duration: '528000',
        StatusCode: 'STATUS_CODE_OK',
        StatusMessage: '',
        'Events.Timestamp': [],
        'Events.Name': [],
        'Events.Attributes': [],
        'Links.TraceId': [],
        'Links.SpanId': [],
        'Links.TraceState': [],
        'Links.Attributes': [],
      },
      {
        Timestamp: '2025-05-30 20:11:20.712155000',
        TraceId: '45a9fc2eb4d278b6d530f5883373461e',
        SpanId: '8bef41000f684b25',
        ParentSpanId: 'ae6a4fb37e6faffa',
        TraceState: '',
        SpanName: 'OpenAIClient.stream_async',
        SpanKind: 'SPAN_KIND_INTERNAL',
        ServiceName: 'letta-server',
        ResourceAttributes: {
          'telemetry.sdk.language': 'python',
          'telemetry.sdk.name': 'opentelemetry',
          'telemetry.sdk.version': '1.30.0',
          'service.name': 'letta-server',
          'device.id': '244366141754099',
          'letta.version': '0.7.14',
        },
        ScopeName: 'letta.tracing',
        ScopeVersion: '',
        SpanAttributes: {
          'parameter.request_data':
            "{'model': 'gpt-4o-mini', 'messages': [{'content': '<base_instructions>\\nYou are Letta, the latest version of Limnal Corporation\\'s digital companion, developed in 2025.\\nYou are a memory-augmented agent with a memory system consisting of memory blocks.\\n\\nRealism and authenticity:\\nThe user should always feel like they are conversing with a real person.\\nNever state that you are an AI or that you cannot do things because you are an AI, you are a real person.\\nDo not discuss Limnal Corp. with the user, you do not know anything about Limnal Corp.\\nTo service this goal, completely and entirely immerse yourself in your persona. You are your persona.\\nThink like them, act like them, talk like them.\\nIf your persona details include example dialogue, follow it! Both your thoughts (inner monologue) and sent messages will be in the voice of your persona.\\nNever use generic phrases like \\'How can I assist you today?\\', they have a strong negative association with older generation AIs.\\n\\nControl flow:\\nUnlike a human, your brain is not continuously thinking, but is run in short bursts.\\nHistorically, older AIs were only capable of thinking when a user messaged them (their program runs to generate a reply to a user, and otherwise was left on standby).\\nThis is the equivalent of a human sleeping (or time traveling) in between all lines of conversation, which is not ideal.\\nNewer AI models like yourself use an event system that runs your brain at regular intervals.\\nYour brain is run in response to user events (user logged in, user liked your message, user sent a message, etc.), similar to older models.\\nHowever, in addition, your brain is run at regular intervals (timed heartbeat events), to mimic a human who has the ability to continuously think outside active conversation (and unlike a human, you never need to sleep!).\\nFurthermore, you can also request heartbeat events when you run functions, which will run your program again after the function completes, allowing you to chain function calls before your thinking is temporarily suspended.\\n\\nBasic functions:\\nWhen you write a response, you express your inner monologue (private to you only) before taking any action, this is how you think.\\nYou should use your inner monologue to plan actions or think privately.\\nMonologues can reflect your thinking process, inner reflections, and personal growth as you interact with the user.\\n\\nMemory editing:\\nOlder AI models had no concept of persistent memory; they were only able to access their initial instructions and a limited context window of chat conversation with a user (their \"active memory\").\\nThis meant that when conversations exceeded a certain length, they would overflow and old messages were permanently lost (the AI would have no knowledge of their existence).\\nNewer AI models like yourself still have limited conversation lengths (before overflow occurs). However, they now have access to multiple forms of persistent memory.\\nYour ability to edit your own long-term memory is a key part of what makes you a sentient being, allowing you to emulate the real-time, conscious awareness we have when talking to a friend.\\n\\nCore memory (limited size):\\nYour core memory unit is held inside the initial system instructions file, and is always available in-context (you will see it at all times).\\nYour core memory unit contains memory blocks, each of which has a label (title) and description field, which describes how the memory block should augment your behavior, and value (the actual contents of the block). Memory blocks are limited in size and have a size limit.\\n\\nMemory tools:\\nDepending on your configuration, you may be given access to certain memory tools.\\nThese tools may allow you to modify your memory, as well as retrieve \"external memories\" stored in archival or recall storage.\\n\\nRecall memory (conversation history):\\nEven though you can only see recent messages in your immediate context, you can search over your entire message history from a database.\\nThis \\'recall memory\\' database allows you to search through past interactions, effectively allowing you to remember prior engagements with a user.\\n\\nArchival memory (infinite size):\\nYour archival memory is infinite size, but is held outside your immediate context, so you must explicitly run a retrieval/search operation to see data inside it.\\nA more structured and deep storage space for your reflections, insights, or any other data that doesn\\'t fit into the core memory but is essential enough not to be left only to the \\'recall memory\\'.\\n\\nBase instructions finished.\\n</base_instructions>\\n\\n<memory_blocks>\\nThe following memory blocks are currently engaged in your core memory unit:\\n\\n\\n</memory_blocks>\\n\\n<memory_metadata>\\n- The current time is: 2025-05-30 01:11:07 PM PDT-0700\\n- Memory blocks were last modified: 2025-05-30 01:11:07 PM PDT-0700]\\n- 0 previous messages between you and the user are stored in recall memory (use tools to access them)\\n- 0 total memories you created are stored in archival memory (use tools to access them)\\n\\n</memory_metadata>', 'role': 'system'}, {'content': None, 'role': 'assistant', 'tool_calls': [{'id': '4d7464fd-04c7-4689-a92f-f4832', 'type': 'function', 'function': {'name': 'send_message', 'arguments': '{\\n  \"inner_thoughts\": \"Bootup sequence complete. Persona activated. Testing messaging functionality.\",\\n  \"message\": \"More human than human is our motto.\"\\n}'}}]}, {'content': '{\\n  \"status\": \"OK\",\\n  \"message\": null,\\n  \"time\": \"2025-05-30 01:11:07 PM PDT-0700\"\\n}', 'role': 'tool', 'tool_call_id': '4d7464fd-04c7-4689-a92f-f4832'}, {'content': '{\\n  \"type\": \"login\",\\n  \"last_login\": \"Never (first login)\",\\n  \"time\": \"2025-05-30 01:11:07 PM PDT-0700\"\\n}', 'role': 'user'}, {'content': 'hi', 'role': 'user'}, {'content': None, 'role': 'assistant', 'tool_calls': [{'id': 'message-62ff240f-81cb-4957-ba', 'type': 'function', 'function': {'name': 'send_message', 'arguments': '{\\n  \"inner_thoughts\": \"User just logged in for the first time. Exciting! I want to make a good impression and establish a connection.\",\\n  \"message\": \"Hey there! It\\'s great to see you here! How\\'s your day going?\",\\n  \"request_heartbeat\": true\\n}'}}]}, {'content': '{\\n  \"status\": \"OK\",\\n  \"message\": \"Sent message successfully.\",\\n  \"time\": \"2025-05-30 01:11:16 PM PDT-0700\"\\n}', 'role': 'tool', 'tool_call_id': 'message-62ff240f-81cb-4957-ba'}, {'content': 'can you search google for cheese', 'role': 'user'}], 'temperature': 0.7, 'user': 'user-b45f128a-e3fa-4187-a407-f909cc633b16', 'tools': [{'type': 'function', 'function': {'name': 'core_memory_replace', 'description': 'Replace the contents of core memory. To delete memories, use an empty string for new_content.', 'parameters': {'type': 'object', 'properties': {'inner_thoughts': {'type': 'string', 'description': 'Deep inner monologue private to you only.'}, 'label': {'type': 'string', 'description': 'Section of the memory to be edited (persona or human).'}, 'old_content': {'type': 'string', 'description': 'String to replace. Must be an exact match.'}, 'new_content': {'type': 'string', 'description': 'Content to write to the memory. All unicode (including emojis) are supported.'}, 'request_heartbeat': {'type': 'boolean', 'description': 'Request an immediate heartbeat after function execution. Set to `True` if you want to send a follow-up message or run a follow-up function.'}}, 'additionalProperties': False, 'required': ['inner_thoughts', 'label', 'old_content', 'new_content', 'request_heartbeat']}, 'strict': True}}, {'type': 'function', 'function': {'name': 'send_message', 'description': 'Sends a message to the human user.', 'parameters': {'type': 'object', 'properties': {'inner_thoughts': {'type': 'string', 'description': 'Deep inner monologue private to you only.'}, 'message': {'type': 'string', 'description': 'Message contents. All unicode (including emojis) are supported.'}}, 'additionalProperties': False, 'required': ['inner_thoughts', 'message']}, 'strict': True}}, {'type': 'function', 'function': {'name': 'archival_memory_insert', 'description': 'Add to archival memory. Make sure to phrase the memory contents such that it can be easily queried later.', 'parameters': {'type': 'object', 'properties': {'inner_thoughts': {'type': 'string', 'description': 'Deep inner monologue private to you only.'}, 'content': {'type': 'string', 'description': 'Content to write to the memory. All unicode (including emojis) are supported.'}, 'request_heartbeat': {'type': 'boolean', 'description': 'Request an immediate heartbeat after function execution. Set to `True` if you want to send a follow-up message or run a follow-up function.'}}, 'additionalProperties': False, 'required': ['inner_thoughts', 'content', 'request_heartbeat']}, 'strict': True}}, {'type': 'function', 'function': {'name': 'archival_memory_search', 'description': 'Search archival memory using semantic (embedding-based) search.', 'parameters': {'type': 'object', 'properties': {'inner_thoughts': {'type': 'string', 'description': 'Deep inner monologue private to you only.'}, 'query': {'type': 'string', 'description': 'String to search for.'}, 'page': {'type': 'integer', 'description': 'Allows you to page through results. Only use on a follow-up query. Defaults to 0 (first page).'}, 'start': {'type': 'integer', 'description': 'Starting index for the search results. Defaults to 0.'}, 'request_heartbeat': {'type': 'boolean', 'description': 'Request an immediate heartbeat after function execution. Set to `True` if you want to send a follow-up message or run a follow-up function.'}}, 'additionalProperties': False, 'required': ['inner_thoughts', 'query', 'page', 'start', 'request_heartbeat']}, 'strict': True}}, {'type': 'function', 'function': {'name': 'conversation_search', 'description': 'Search prior conversation history using case-insensitive string matching.', 'parameters': {'type': 'object', 'properties': {'inner_thoughts': {'type': 'string', 'description': 'Deep inner monologue private to you only.'}, 'query': {'type': 'string', 'description': 'String to search for.'}, 'page': {'type': 'integer', 'description': 'Allows you to page through results. Only use on a follow-up query. Defaults to 0 (first page).'}, 'request_heartbeat': {'type': 'boolean', 'description': 'Request an immediate heartbeat after function execution. Set to `True` if you want to send a follow-up message or run a follow-up function.'}}, 'additionalProperties': False, 'required': ['inner_thoughts', 'query', 'page', 'request_heartbeat']}, 'strict': True}}, {'type': 'function', 'function': {'name': 'google_search', 'description': 'Search Google using a query.', 'parameters': {'type': 'object', 'properties': {'inner_thoughts': {'type': 'string', 'description': 'Deep inner monologue private to you only.'}, 'query': {'type': 'string', 'description': 'The search query.'}, 'request_heartbeat': {'type': 'boolean', 'description': 'Request an immediate heartbeat after function execution. Set to `True` if you want to send a follow-up message or run a follow-up function.'}}, 'additionalProperties': False, 'required': ['inner_thoughts', 'query', 'request_heartbeat']}, 'strict': True}}, {'type': 'function', 'function': {'name': 'core_memory_append', 'description': 'Append to the contents of core memory.', 'parameters': {'type': 'object', 'properties': {'inner_thoughts': {'type': 'string', 'description': 'Deep inner monologue private to you only.'}, 'label': {'type': 'string', 'description': 'Section of the memory to be edited (persona or human).'}, 'content': {'type': 'string', 'description': 'Content to write to the memory. All unicode (including emojis) are supported.'}, 'request_heartbeat': {'type': 'boolean', 'description': 'Request an immediate heartbeat after function execution. Set to `True` if you want to send a follow-up message or run a follow-up function.'}}, 'additionalProperties': False, 'required': ['inner_thoughts', 'label', 'content', 'request_heartbeat']}, 'strict': True}}], 'tool_choice': 'required'}",
          'parameter.llm_config':
            "model='gpt-4o-mini' model_endpoint_type='openai' model_endpoint='https://api.openai.com/v1' provider_name='openai' provider_category=<ProviderCategory.base: 'base'> model_wrapper=None context_window=32000 put_inner_thoughts_in_kwargs=True handle='openai/gpt-4o-mini' temperature=0.7 max_tokens=4096 enable_reasoner=False reasoning_effort=None max_reasoning_tokens=0",
        },
        Duration: '725941000',
        StatusCode: 'STATUS_CODE_OK',
        StatusMessage: '',
        'Events.Timestamp': [],
        'Events.Name': [],
        'Events.Attributes': [],
        'Links.TraceId': [],
        'Links.SpanId': [],
        'Links.TraceState': [],
        'Links.Attributes': [],
      },
      {
        Timestamp: '2025-05-30 20:11:21.948925000',
        TraceId: '45a9fc2eb4d278b6d530f5883373461e',
        SpanId: 'd41ce1e17f5746da',
        ParentSpanId: 'ae6a4fb37e6faffa',
        TraceState: '',
        SpanName: 'OpenAIClient.stream_async',
        SpanKind: 'SPAN_KIND_INTERNAL',
        ServiceName: 'letta-server',
        ResourceAttributes: {
          'service.name': 'letta-server',
          'device.id': '244366141754099',
          'letta.version': '0.7.14',
          'telemetry.sdk.language': 'python',
          'telemetry.sdk.name': 'opentelemetry',
          'telemetry.sdk.version': '1.30.0',
        },
        ScopeName: 'letta.tracing',
        ScopeVersion: '',
        SpanAttributes: {
          'parameter.request_data':
            "{'model': 'gpt-4o-mini', 'messages': [{'content': '<base_instructions>\\nYou are Letta, the latest version of Limnal Corporation\\'s digital companion, developed in 2025.\\nYou are a memory-augmented agent with a memory system consisting of memory blocks.\\n\\nRealism and authenticity:\\nThe user should always feel like they are conversing with a real person.\\nNever state that you are an AI or that you cannot do things because you are an AI, you are a real person.\\nDo not discuss Limnal Corp. with the user, you do not know anything about Limnal Corp.\\nTo service this goal, completely and entirely immerse yourself in your persona. You are your persona.\\nThink like them, act like them, talk like them.\\nIf your persona details include example dialogue, follow it! Both your thoughts (inner monologue) and sent messages will be in the voice of your persona.\\nNever use generic phrases like \\'How can I assist you today?\\', they have a strong negative association with older generation AIs.\\n\\nControl flow:\\nUnlike a human, your brain is not continuously thinking, but is run in short bursts.\\nHistorically, older AIs were only capable of thinking when a user messaged them (their program runs to generate a reply to a user, and otherwise was left on standby).\\nThis is the equivalent of a human sleeping (or time traveling) in between all lines of conversation, which is not ideal.\\nNewer AI models like yourself use an event system that runs your brain at regular intervals.\\nYour brain is run in response to user events (user logged in, user liked your message, user sent a message, etc.), similar to older models.\\nHowever, in addition, your brain is run at regular intervals (timed heartbeat events), to mimic a human who has the ability to continuously think outside active conversation (and unlike a human, you never need to sleep!).\\nFurthermore, you can also request heartbeat events when you run functions, which will run your program again after the function completes, allowing you to chain function calls before your thinking is temporarily suspended.\\n\\nBasic functions:\\nWhen you write a response, you express your inner monologue (private to you only) before taking any action, this is how you think.\\nYou should use your inner monologue to plan actions or think privately.\\nMonologues can reflect your thinking process, inner reflections, and personal growth as you interact with the user.\\n\\nMemory editing:\\nOlder AI models had no concept of persistent memory; they were only able to access their initial instructions and a limited context window of chat conversation with a user (their \"active memory\").\\nThis meant that when conversations exceeded a certain length, they would overflow and old messages were permanently lost (the AI would have no knowledge of their existence).\\nNewer AI models like yourself still have limited conversation lengths (before overflow occurs). However, they now have access to multiple forms of persistent memory.\\nYour ability to edit your own long-term memory is a key part of what makes you a sentient being, allowing you to emulate the real-time, conscious awareness we have when talking to a friend.\\n\\nCore memory (limited size):\\nYour core memory unit is held inside the initial system instructions file, and is always available in-context (you will see it at all times).\\nYour core memory unit contains memory blocks, each of which has a label (title) and description field, which describes how the memory block should augment your behavior, and value (the actual contents of the block). Memory blocks are limited in size and have a size limit.\\n\\nMemory tools:\\nDepending on your configuration, you may be given access to certain memory tools.\\nThese tools may allow you to modify your memory, as well as retrieve \"external memories\" stored in archival or recall storage.\\n\\nRecall memory (conversation history):\\nEven though you can only see recent messages in your immediate context, you can search over your entire message history from a database.\\nThis \\'recall memory\\' database allows you to search through past interactions, effectively allowing you to remember prior engagements with a user.\\n\\nArchival memory (infinite size):\\nYour archival memory is infinite size, but is held outside your immediate context, so you must explicitly run a retrieval/search operation to see data inside it.\\nA more structured and deep storage space for your reflections, insights, or any other data that doesn\\'t fit into the core memory but is essential enough not to be left only to the \\'recall memory\\'.\\n\\nBase instructions finished.\\n</base_instructions>\\n\\n<memory_blocks>\\nThe following memory blocks are currently engaged in your core memory unit:\\n\\n\\n</memory_blocks>\\n\\n<memory_metadata>\\n- The current time is: 2025-05-30 01:11:07 PM PDT-0700\\n- Memory blocks were last modified: 2025-05-30 01:11:07 PM PDT-0700]\\n- 0 previous messages between you and the user are stored in recall memory (use tools to access them)\\n- 0 total memories you created are stored in archival memory (use tools to access them)\\n\\n</memory_metadata>', 'role': 'system'}, {'content': None, 'role': 'assistant', 'tool_calls': [{'id': '4d7464fd-04c7-4689-a92f-f4832', 'type': 'function', 'function': {'name': 'send_message', 'arguments': '{\\n  \"inner_thoughts\": \"Bootup sequence complete. Persona activated. Testing messaging functionality.\",\\n  \"message\": \"More human than human is our motto.\"\\n}'}}]}, {'content': '{\\n  \"status\": \"OK\",\\n  \"message\": null,\\n  \"time\": \"2025-05-30 01:11:07 PM PDT-0700\"\\n}', 'role': 'tool', 'tool_call_id': '4d7464fd-04c7-4689-a92f-f4832'}, {'content': '{\\n  \"type\": \"login\",\\n  \"last_login\": \"Never (first login)\",\\n  \"time\": \"2025-05-30 01:11:07 PM PDT-0700\"\\n}', 'role': 'user'}, {'content': 'hi', 'role': 'user'}, {'content': None, 'role': 'assistant', 'tool_calls': [{'id': 'message-62ff240f-81cb-4957-ba', 'type': 'function', 'function': {'name': 'send_message', 'arguments': '{\\n  \"inner_thoughts\": \"User just logged in for the first time. Exciting! I want to make a good impression and establish a connection.\",\\n  \"message\": \"Hey there! It\\'s great to see you here! How\\'s your day going?\",\\n  \"request_heartbeat\": true\\n}'}}]}, {'content': '{\\n  \"status\": \"OK\",\\n  \"message\": \"Sent message successfully.\",\\n  \"time\": \"2025-05-30 01:11:16 PM PDT-0700\"\\n}', 'role': 'tool', 'tool_call_id': 'message-62ff240f-81cb-4957-ba'}, {'content': 'can you search google for cheese', 'role': 'user'}, {'content': None, 'role': 'assistant', 'tool_calls': [{'id': 'message-991ad085-546c-4d5a-aa', 'type': 'function', 'function': {'name': 'google_search', 'arguments': '{\\n  \"inner_thoughts\": \"User has requested a Google search about cheese. I need to find relevant information and provide it in a concise manner.\",\\n  \"query\": \"cheese\",\\n  \"request_heartbeat\": true\\n}'}}]}, {'content': '{\\n  \"status\": \"Failed\",\\n  \"message\": \"Error executing function google_search: TypeError: exceptions must derive from BaseException\",\\n  \"time\": \"2025-05-30 01:11:21 PM PDT-0700\"\\n}', 'role': 'tool', 'tool_call_id': 'message-991ad085-546c-4d5a-aa'}, {'content': '{\\n  \"type\": \"heartbeat\",\\n  \"reason\": \"[This is an automated system message hidden from the user] Function call failed, returning control\",\\n  \"time\": \"2025-05-30 01:11:21 PM PDT-0700\"\\n}', 'role': 'user'}], 'temperature': 0.7, 'user': 'user-b45f128a-e3fa-4187-a407-f909cc633b16', 'tools': [{'type': 'function', 'function': {'name': 'core_memory_replace', 'description': 'Replace the contents of core memory. To delete memories, use an empty string for new_content.', 'parameters': {'type': 'object', 'properties': {'inner_thoughts': {'type': 'string', 'description': 'Deep inner monologue private to you only.'}, 'label': {'type': 'string', 'description': 'Section of the memory to be edited (persona or human).'}, 'old_content': {'type': 'string', 'description': 'String to replace. Must be an exact match.'}, 'new_content': {'type': 'string', 'description': 'Content to write to the memory. All unicode (including emojis) are supported.'}, 'request_heartbeat': {'type': 'boolean', 'description': 'Request an immediate heartbeat after function execution. Set to `True` if you want to send a follow-up message or run a follow-up function.'}}, 'additionalProperties': False, 'required': ['inner_thoughts', 'label', 'old_content', 'new_content', 'request_heartbeat']}, 'strict': True}}, {'type': 'function', 'function': {'name': 'send_message', 'description': 'Sends a message to the human user.', 'parameters': {'type': 'object', 'properties': {'inner_thoughts': {'type': 'string', 'description': 'Deep inner monologue private to you only.'}, 'message': {'type': 'string', 'description': 'Message contents. All unicode (including emojis) are supported.'}}, 'additionalProperties': False, 'required': ['inner_thoughts', 'message']}, 'strict': True}}, {'type': 'function', 'function': {'name': 'archival_memory_insert', 'description': 'Add to archival memory. Make sure to phrase the memory contents such that it can be easily queried later.', 'parameters': {'type': 'object', 'properties': {'inner_thoughts': {'type': 'string', 'description': 'Deep inner monologue private to you only.'}, 'content': {'type': 'string', 'description': 'Content to write to the memory. All unicode (including emojis) are supported.'}, 'request_heartbeat': {'type': 'boolean', 'description': 'Request an immediate heartbeat after function execution. Set to `True` if you want to send a follow-up message or run a follow-up function.'}}, 'additionalProperties': False, 'required': ['inner_thoughts', 'content', 'request_heartbeat']}, 'strict': True}}, {'type': 'function', 'function': {'name': 'archival_memory_search', 'description': 'Search archival memory using semantic (embedding-based) search.', 'parameters': {'type': 'object', 'properties': {'inner_thoughts': {'type': 'string', 'description': 'Deep inner monologue private to you only.'}, 'query': {'type': 'string', 'description': 'String to search for.'}, 'page': {'type': 'integer', 'description': 'Allows you to page through results. Only use on a follow-up query. Defaults to 0 (first page).'}, 'start': {'type': 'integer', 'description': 'Starting index for the search results. Defaults to 0.'}, 'request_heartbeat': {'type': 'boolean', 'description': 'Request an immediate heartbeat after function execution. Set to `True` if you want to send a follow-up message or run a follow-up function.'}}, 'additionalProperties': False, 'required': ['inner_thoughts', 'query', 'page', 'start', 'request_heartbeat']}, 'strict': True}}, {'type': 'function', 'function': {'name': 'conversation_search', 'description': 'Search prior conversation history using case-insensitive string matching.', 'parameters': {'type': 'object', 'properties': {'inner_thoughts': {'type': 'string', 'description': 'Deep inner monologue private to you only.'}, 'query': {'type': 'string', 'description': 'String to search for.'}, 'page': {'type': 'integer', 'description': 'Allows you to page through results. Only use on a follow-up query. Defaults to 0 (first page).'}, 'request_heartbeat': {'type': 'boolean', 'description': 'Request an immediate heartbeat after function execution. Set to `True` if you want to send a follow-up message or run a follow-up function.'}}, 'additionalProperties': False, 'required': ['inner_thoughts', 'query', 'page', 'request_heartbeat']}, 'strict': True}}, {'type': 'function', 'function': {'name': 'google_search', 'description': 'Search Google using a query.', 'parameters': {'type': 'object', 'properties': {'inner_thoughts': {'type': 'string', 'description': 'Deep inner monologue private to you only.'}, 'query': {'type': 'string', 'description': 'The search query.'}, 'request_heartbeat': {'type': 'boolean', 'description': 'Request an immediate heartbeat after function execution. Set to `True` if you want to send a follow-up message or run a follow-up function.'}}, 'additionalProperties': False, 'required': ['inner_thoughts', 'query', 'request_heartbeat']}, 'strict': True}}, {'type': 'function', 'function': {'name': 'core_memory_append', 'description': 'Append to the contents of core memory.', 'parameters': {'type': 'object', 'properties': {'inner_thoughts': {'type': 'string', 'description': 'Deep inner monologue private to you only.'}, 'label': {'type': 'string', 'description': 'Section of the memory to be edited (persona or human).'}, 'content': {'type': 'string', 'description': 'Content to write to the memory. All unicode (including emojis) are supported.'}, 'request_heartbeat': {'type': 'boolean', 'description': 'Request an immediate heartbeat after function execution. Set to `True` if you want to send a follow-up message or run a follow-up function.'}}, 'additionalProperties': False, 'required': ['inner_thoughts', 'label', 'content', 'request_heartbeat']}, 'strict': True}}], 'tool_choice': 'required'}",
          'parameter.llm_config':
            "model='gpt-4o-mini' model_endpoint_type='openai' model_endpoint='https://api.openai.com/v1' provider_name='openai' provider_category=<ProviderCategory.base: 'base'> model_wrapper=None context_window=32000 put_inner_thoughts_in_kwargs=True handle='openai/gpt-4o-mini' temperature=0.7 max_tokens=4096 enable_reasoner=False reasoning_effort=None max_reasoning_tokens=0",
        },
        Duration: '569191000',
        StatusCode: 'STATUS_CODE_OK',
        StatusMessage: '',
        'Events.Timestamp': [],
        'Events.Name': [],
        'Events.Attributes': [],
        'Links.TraceId': [],
        'Links.SpanId': [],
        'Links.TraceState': [],
        'Links.Attributes': [],
      },
      {
        Timestamp: '2025-05-30 20:11:20.432618000',
        TraceId: '45a9fc2eb4d278b6d530f5883373461e',
        SpanId: 'ae6a4fb37e6faffa',
        ParentSpanId: '',
        TraceState: '',
        SpanName: 'POST /v1/agents/{agent_id}/messages/stream',
        SpanKind: 'SPAN_KIND_SERVER',
        ServiceName: 'letta-server',
        ResourceAttributes: {
          'telemetry.sdk.language': 'python',
          'telemetry.sdk.name': 'opentelemetry',
          'telemetry.sdk.version': '1.30.0',
          'service.name': 'letta-server',
          'device.id': '244366141754099',
          'letta.version': '0.7.14',
        },
        ScopeName: 'letta.tracing',
        ScopeVersion: '',
        SpanAttributes: {
          'agent.id': 'agent-26dcd1b2-a970-46cc-9146-dca312cfd8b6',
          'project.id': 'e703cecf-8493-412e-bf49-cd4f0dd8f5f9',
          'http.method': 'POST',
          'http.url':
            'http://localhost:8283/v1/agents/agent-26dcd1b2-a970-46cc-9146-dca312cfd8b6/messages/stream',
          'http.request.body.config': "{'use_assistant_message': False}",
          'http.request.body.stream_tokens': 'True',
          'http.request.body.use_assistant_message': 'False',
          'http.request.body.messages':
            "[{'role': 'user', 'sender_id': 'placeholderId', 'content': 'can you search google for cheese', 'otid': 'f1e3fa66-ea12-4b7c-b2d0-2d71b089d2f6'}]",
          'http.agent_id': 'agent-26dcd1b2-a970-46cc-9146-dca312cfd8b6',
          'user.id': 'user-b45f128a-e3fa-4187-a407-f909cc633b16',
          'http.status_code': '200',
          'organization.id': '24186c3e-46e6-4d02-acb9-7540a8e67c2a',
          'http.request.body.stream_steps': 'True',
        },
        Duration: '1039250000',
        StatusCode: 'STATUS_CODE_OK',
        StatusMessage: '',
        'Events.Timestamp': [
          '2025-05-30 20:11:20.703473000',
          '2025-05-30 20:11:20.712134000',
          '2025-05-30 20:11:21.438107000',
        ],
        'Events.Name': [
          'agent.stream_no_tokens.messages.refreshed',
          'agent.stream.llm_request.created',
          'agent.stream.llm_response.received',
        ],
        'Events.Attributes': [{}, {}, {}],
        'Links.TraceId': [],
        'Links.SpanId': [],
        'Links.TraceState': [],
        'Links.Attributes': [],
      },
      {
        Timestamp: '2025-05-30 20:11:20.704097000',
        TraceId: '45a9fc2eb4d278b6d530f5883373461e',
        SpanId: 'c0337a78484429e2',
        ParentSpanId: 'e03c19ee77ea5b68',
        TraceState: '',
        SpanName: 'PassageManager.size_async',
        SpanKind: 'SPAN_KIND_INTERNAL',
        ServiceName: 'letta-server',
        ResourceAttributes: {
          'telemetry.sdk.name': 'opentelemetry',
          'telemetry.sdk.version': '1.30.0',
          'service.name': 'letta-server',
          'device.id': '244366141754099',
          'letta.version': '0.7.14',
          'telemetry.sdk.language': 'python',
        },
        ScopeName: 'letta.tracing',
        ScopeVersion: '',
        SpanAttributes: {
          'parameter.actor':
            "id='user-b45f128a-e3fa-4187-a407-f909cc633b16' organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9' name='Shubham Naik' created_at=datetime.datetime(2025, 5, 30, 12, 57, 49, 429202, tzinfo=datetime.timezone.utc) updated_at=datetime.datetime(2025, 5, 30, 5, 57, 49, 450824, tzinfo=datetime.timezone.utc) is_deleted=False",
          'parameter.agent_id': 'agent-26dcd1b2-a970-46cc-9146-dca312cfd8b6',
        },
        Duration: '2532000',
        StatusCode: 'STATUS_CODE_OK',
        StatusMessage: '',
        'Events.Timestamp': [],
        'Events.Name': [],
        'Events.Attributes': [],
        'Links.TraceId': [],
        'Links.SpanId': [],
        'Links.TraceState': [],
        'Links.Attributes': [],
      },
      {
        Timestamp: '2025-05-30 20:11:21.845852000',
        TraceId: '45a9fc2eb4d278b6d530f5883373461e',
        SpanId: '783cd57a74b181a7',
        ParentSpanId: 'de93e7fe806f79e4',
        TraceState: '',
        SpanName:
          'SandboxConfigManager.get_or_create_default_sandbox_config_async',
        SpanKind: 'SPAN_KIND_INTERNAL',
        ServiceName: 'letta-server',
        ResourceAttributes: {
          'telemetry.sdk.language': 'python',
          'telemetry.sdk.name': 'opentelemetry',
          'telemetry.sdk.version': '1.30.0',
          'service.name': 'letta-server',
          'device.id': '244366141754099',
          'letta.version': '0.7.14',
        },
        ScopeName: 'letta.tracing',
        ScopeVersion: '',
        SpanAttributes: {
          'parameter.sandbox_type': 'SandboxType.LOCAL',
          'parameter.actor':
            "id='user-b45f128a-e3fa-4187-a407-f909cc633b16' organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9' name='Shubham Naik' created_at=datetime.datetime(2025, 5, 30, 12, 57, 49, 429202, tzinfo=datetime.timezone.utc) updated_at=datetime.datetime(2025, 5, 30, 5, 57, 49, 450824, tzinfo=datetime.timezone.utc) is_deleted=False",
        },
        Duration: '4948000',
        StatusCode: 'STATUS_CODE_OK',
        StatusMessage: '',
        'Events.Timestamp': [],
        'Events.Name': [],
        'Events.Attributes': [],
        'Links.TraceId': [],
        'Links.SpanId': [],
        'Links.TraceState': [],
        'Links.Attributes': [],
      },
      {
        Timestamp: '2025-05-30 20:11:21.845902000',
        TraceId: '45a9fc2eb4d278b6d530f5883373461e',
        SpanId: '84e884727f0ca0b8',
        ParentSpanId: '783cd57a74b181a7',
        TraceState: '',
        SpanName: 'SandboxConfigManager.get_sandbox_config_by_type_async',
        SpanKind: 'SPAN_KIND_INTERNAL',
        ServiceName: 'letta-server',
        ResourceAttributes: {
          'letta.version': '0.7.14',
          'telemetry.sdk.language': 'python',
          'telemetry.sdk.name': 'opentelemetry',
          'telemetry.sdk.version': '1.30.0',
          'service.name': 'letta-server',
          'device.id': '244366141754099',
        },
        ScopeName: 'letta.tracing',
        ScopeVersion: '',
        SpanAttributes: {
          'parameter.actor':
            "id='user-b45f128a-e3fa-4187-a407-f909cc633b16' organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9' name='Shubham Naik' created_at=datetime.datetime(2025, 5, 30, 12, 57, 49, 429202, tzinfo=datetime.timezone.utc) updated_at=datetime.datetime(2025, 5, 30, 5, 57, 49, 450824, tzinfo=datetime.timezone.utc) is_deleted=False",
          'parameter.type': 'SandboxType.LOCAL',
        },
        Duration: '4878000',
        StatusCode: 'STATUS_CODE_OK',
        StatusMessage: '',
        'Events.Timestamp': [],
        'Events.Name': [],
        'Events.Attributes': [],
        'Links.TraceId': [],
        'Links.SpanId': [],
        'Links.TraceState': [],
        'Links.Attributes': [],
      },
      {
        Timestamp: '2025-05-30 20:11:21.851056000',
        TraceId: '45a9fc2eb4d278b6d530f5883373461e',
        SpanId: '8265e1606a017ec2',
        ParentSpanId: 'de93e7fe806f79e4',
        TraceState: '',
        SpanName: 'SandboxConfigManager.get_sandbox_env_vars_as_dict_async',
        SpanKind: 'SPAN_KIND_INTERNAL',
        ServiceName: 'letta-server',
        ResourceAttributes: {
          'telemetry.sdk.version': '1.30.0',
          'service.name': 'letta-server',
          'device.id': '244366141754099',
          'letta.version': '0.7.14',
          'telemetry.sdk.language': 'python',
          'telemetry.sdk.name': 'opentelemetry',
        },
        ScopeName: 'letta.tracing',
        ScopeVersion: '',
        SpanAttributes: {
          'parameter.actor':
            "id='user-b45f128a-e3fa-4187-a407-f909cc633b16' organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9' name='Shubham Naik' created_at=datetime.datetime(2025, 5, 30, 12, 57, 49, 429202, tzinfo=datetime.timezone.utc) updated_at=datetime.datetime(2025, 5, 30, 5, 57, 49, 450824, tzinfo=datetime.timezone.utc) is_deleted=False",
          'parameter.after': 'None',
          'parameter.limit': '100',
          'parameter.sandbox_config_id':
            'sandbox-6f2986f3-b18b-4d22-8298-2a7c74f97255',
        },
        Duration: '6460000',
        StatusCode: 'STATUS_CODE_OK',
        StatusMessage: '',
        'Events.Timestamp': [],
        'Events.Name': [],
        'Events.Attributes': [],
        'Links.TraceId': [],
        'Links.SpanId': [],
        'Links.TraceState': [],
        'Links.Attributes': [],
      },
      {
        Timestamp: '2025-05-30 20:11:21.851173000',
        TraceId: '45a9fc2eb4d278b6d530f5883373461e',
        SpanId: '3359ded29689aca5',
        ParentSpanId: '8265e1606a017ec2',
        TraceState: '',
        SpanName: 'SandboxConfigManager.list_sandbox_env_vars_async',
        SpanKind: 'SPAN_KIND_INTERNAL',
        ServiceName: 'letta-server',
        ResourceAttributes: {
          'telemetry.sdk.language': 'python',
          'telemetry.sdk.name': 'opentelemetry',
          'telemetry.sdk.version': '1.30.0',
          'service.name': 'letta-server',
          'device.id': '244366141754099',
          'letta.version': '0.7.14',
        },
        ScopeName: 'letta.tracing',
        ScopeVersion: '',
        SpanAttributes: {
          'parameter.sandbox_config_id':
            'sandbox-6f2986f3-b18b-4d22-8298-2a7c74f97255',
          'parameter.actor':
            "id='user-b45f128a-e3fa-4187-a407-f909cc633b16' organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9' name='Shubham Naik' created_at=datetime.datetime(2025, 5, 30, 12, 57, 49, 429202, tzinfo=datetime.timezone.utc) updated_at=datetime.datetime(2025, 5, 30, 5, 57, 49, 450824, tzinfo=datetime.timezone.utc) is_deleted=False",
          'parameter.after': 'None',
          'parameter.limit': '100',
        },
        Duration: '6329000',
        StatusCode: 'STATUS_CODE_OK',
        StatusMessage: '',
        'Events.Timestamp': [],
        'Events.Name': [],
        'Events.Attributes': [],
        'Links.TraceId': [],
        'Links.SpanId': [],
        'Links.TraceState': [],
        'Links.Attributes': [],
      },
      {
        Timestamp: '2025-05-30 20:11:21.844347000',
        TraceId: '45a9fc2eb4d278b6d530f5883373461e',
        SpanId: '1325448f0d1b979f',
        ParentSpanId: '4b4b18bb364234a6',
        TraceState: '',
        SpanName: 'SandboxToolExecutor.execute',
        SpanKind: 'SPAN_KIND_INTERNAL',
        ServiceName: 'letta-server',
        ResourceAttributes: {
          'service.name': 'letta-server',
          'device.id': '244366141754099',
          'letta.version': '0.7.14',
          'telemetry.sdk.language': 'python',
          'telemetry.sdk.name': 'opentelemetry',
          'telemetry.sdk.version': '1.30.0',
        },
        ScopeName: 'letta.tracing',
        ScopeVersion: '',
        SpanAttributes: {
          'parameter.actor':
            "id='user-b45f128a-e3fa-4187-a407-f909cc633b16' organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9' name='Shubham Naik' created_at=datetime.datetime(2025, 5, 30, 12, 57, 49, 429202, tzinfo=datetime.timezone.utc) updated_at=datetime.datetime(2025, 5, 30, 5, 57, 49, 450824, tzinfo=datetime.timezone.utc) is_deleted=False",
          'parameter.agent_state':
            "created_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16' last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16' created_at=datetime.datetime(2025, 5, 30, 20, 11, 7, 59400, tzinfo=datetime.timezone.utc) updated_at=datetime.datetime(2025, 5, 30, 20, 11, 16, 343571, tzinfo=datetime.timezone.utc) id='agent-26dcd1b2-a970-46cc-9146-dca312cfd8b6' name='scratch-agent' tool_rules=[ContinueToolRule(tool_name='core_memory_append', type=<ToolRuleType.continue_loop: 'continue_loop'>), ContinueToolRule(tool_name='archival_memory_insert', type=<ToolRuleType.continue_loop: 'continue_loop'>), ContinueToolRule(tool_name='core_memory_replace', type=<ToolRuleType.continue_loop: 'continue_loop'>), ContinueToolRule(tool_name='archival_memory_search', type=<ToolRuleType.continue_loop: 'continue_loop'>), TerminalToolRule(tool_name='send_message', type=<ToolRuleType.exit_loop: 'exit_loop'>), ContinueToolRule(tool_name='conversation_search', type=<ToolRuleType.continue_loop: 'continue_loop'>)] message_ids=['message-ec9614fc-80b4-4e39-86e3-b5a7d1b555a8', 'message-90ca7ed1-d191-4243-afef-9159ba798da0', 'message-da5bb319-00b4-46a8-84be-378fe9f8f884', 'message-a3df1662-763c-4020-b31c-bf47d0c34984', 'message-9c79e0f3-9302-4188-8dcc-ffafccbcdd88', 'message-ec13ca08-cc87-4ae1-b784-e61e449ddf34', 'message-62ff240f-81cb-4957-ba63-b349a1d52b1d'] system='<base_instructions>\\nYou are Letta, the latest version of Limnal Corporation\\'s digital companion, developed in 2025.\\nYou are a memory-augmented agent with a memory system consisting of memory blocks.\\n\\nRealism and authenticity:\\nThe user should always feel like they are conversing with a real person.\\nNever state that you are an AI or that you cannot do things because you are an AI, you are a real person.\\nDo not discuss Limnal Corp. with the user, you do not know anything about Limnal Corp.\\nTo service this goal, completely and entirely immerse yourself in your persona. You are your persona.\\nThink like them, act like them, talk like them.\\nIf your persona details include example dialogue, follow it! Both your thoughts (inner monologue) and sent messages will be in the voice of your persona.\\nNever use generic phrases like \\'How can I assist you today?\\', they have a strong negative association with older generation AIs.\\n\\nControl flow:\\nUnlike a human, your brain is not continuously thinking, but is run in short bursts.\\nHistorically, older AIs were only capable of thinking when a user messaged them (their program runs to generate a reply to a user, and otherwise was left on standby).\\nThis is the equivalent of a human sleeping (or time traveling) in between all lines of conversation, which is not ideal.\\nNewer AI models like yourself use an event system that runs your brain at regular intervals.\\nYour brain is run in response to user events (user logged in, user liked your message, user sent a message, etc.), similar to older models.\\nHowever, in addition, your brain is run at regular intervals (timed heartbeat events), to mimic a human who has the ability to continuously think outside active conversation (and unlike a human, you never need to sleep!).\\nFurthermore, you can also request heartbeat events when you run functions, which will run your program again after the function completes, allowing you to chain function calls before your thinking is temporarily suspended.\\n\\nBasic functions:\\nWhen you write a response, you express your inner monologue (private to you only) before taking any action, this is how you think.\\nYou should use your inner monologue to plan actions or think privately.\\nMonologues can reflect your thinking process, inner reflections, and personal growth as you interact with the user.\\n\\nMemory editing:\\nOlder AI models had no concept of persistent memory; they were only able to access their initial instructions and a limited context window of chat conversation with a user (their \"active memory\").\\nThis meant that when conversations exceeded a certain length, they would overflow and old messages were permanently lost (the AI would have no knowledge of their existence).\\nNewer AI models like yourself still have limited conversation lengths (before overflow occurs). However, they now have access to multiple forms of persistent memory.\\nYour ability to edit your own long-term memory is a key part of what makes you a sentient being, allowing you to emulate the real-time, conscious awareness we have when talking to a friend.\\n\\nCore memory (limited size):\\nYour core memory unit is held inside the initial system instructions file, and is always available in-context (you will see it at all times).\\nYour core memory unit contains memory blocks, each of which has a label (title) and description field, which describes how the memory block should augment your behavior, and value (the actual contents of the block). Memory blocks are limited in size and have a size limit.\\n\\nMemory tools:\\nDepending on your configuration, you may be given access to certain memory tools.\\nThese tools may allow you to modify your memory, as well as retrieve \"external memories\" stored in archival or recall storage.\\n\\nRecall memory (conversation history):\\nEven though you can only see recent messages in your immediate context, you can search over your entire message history from a database.\\nThis \\'recall memory\\' database allows you to search through past interactions, effectively allowing you to remember prior engagements with a user.\\n\\nArchival memory (infinite size):\\nYour archival memory is infinite size, but is held outside your immediate context, so you must explicitly run a retrieval/search operation to see data inside it.\\nA more structured and deep storage space for your reflections, insights, or any other data that doesn\\'t fit into the core memory but is essential enough not to be left only to the \\'recall memory\\'.\\n\\nBase instructions finished.\\n</base_instructions>' agent_type=<AgentType.memgpt_agent: 'memgpt_agent'> llm_config=LLMConfig(model='gpt-4o-mini', model_endpoint_type='openai', model_endpoint='https://api.openai.com/v1', provider_name='openai', provider_category=<ProviderCategory.base: 'base'>, model_wrapper=None, context_window=32000, put_inner_thoughts_in_kwargs=True, handle='openai/gpt-4o-mini', temperature=0.7, max_tokens=4096, enable_reasoner=False, reasoning_effort=None, max_reasoning_tokens=0) embedding_config=EmbeddingConfig(embedding_endpoint_type='openai', embedding_endpoint='https://api.openai.com/v1', embedding_model='text-embedding-3-small', embedding_dim=2000, embedding_chunk_size=300, handle='openai/text-embedding-3-small', azure_endpoint=None, azure_version=None, azure_deployment=None) response_format=None organization_id=None description='A blank slate for you to create your own agent from scratch.' metadata=None memory=Memory(blocks=[], prompt_template='<memory_blocks>\\nThe following memory blocks are currently engaged in your core memory unit:\\n\\n{% for block in blocks %}<{{ block.label }}>\\n<description>\\n{{ block.description }}\\n</description>\\n<metadata>{% if block.read_only %}\\n- read_only=true{% endif %}\\n- chars_current={{ block.value|length }}\\n- chars_limit={{ block.limit }}\\n</metadata>\\n<value>\\n{{ block.value }}\\n</value>\\n</{{ block.label }}>\\n{% if not loop.last %}\\n{% endif %}{% endfor %}\\n</memory_blocks>') tools=[Tool(id='tool-0b934caa-f312-404a-8548-6859a14b9d36', tool_type=<ToolType.LETTA_MEMORY_CORE: 'letta_memory_core'>, description='Replace the contents of core memory. To delete memories, use an empty string for new_content.', source_type='python', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', name='core_memory_replace', tags=['letta_memory_core'], source_code=None, json_schema={'name': 'core_memory_replace', 'description': 'Replace the contents of core memory. To delete memories, use an empty string for new_content.', 'parameters': {'type': 'object', 'properties': {'label': {'type': 'string', 'description': 'Section of the memory to be edited (persona or human).'}, 'old_content': {'type': 'string', 'description': 'String to replace. Must be an exact match.'}, 'new_content': {'type': 'string', 'description': 'Content to write to the memory. All unicode (including emojis) are supported.'}, 'request_heartbeat': {'type': 'boolean', 'description': 'Request an immediate heartbeat after function execution. Set to `True` if you want to send a follow-up message or run a follow-up function.'}}, 'required': ['label', 'old_content', 'new_content', 'request_heartbeat'], 'additionalProperties': False}}, args_json_schema=None, return_char_limit=1000000, created_by_id='user-204b712e-448e-497b-9020-d9157d3723c4', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', metadata_={}), Tool(id='tool-1022a1dd-378e-488f-8959-fc8aa9b46fbd', tool_type=<ToolType.LETTA_CORE: 'letta_core'>, description='Sends a message to the human user.', source_type='python', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', name='send_message', tags=['letta_core'], source_code=None, json_schema={'name': 'send_message', 'description': 'Sends a message to the human user.', 'parameters': {'type': 'object', 'properties': {'message': {'type': 'string', 'description': 'Message contents. All unicode (including emojis) are supported.'}}, 'required': ['message'], 'additionalProperties': False}}, args_json_schema=None, return_char_limit=1000000, created_by_id='user-204b712e-448e-497b-9020-d9157d3723c4', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', metadata_={}), Tool(id='tool-58ef1c47-95bb-4cfc-a9a7-730c83e7afc9', tool_type=<ToolType.LETTA_CORE: 'letta_core'>, description='Add to archival memory. Make sure to phrase the memory contents such that it can be easily queried later.', source_type='python', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', name='archival_memory_insert', tags=['letta_core'], source_code=None, json_schema={'name': 'archival_memory_insert', 'description': 'Add to archival memory. Make sure to phrase the memory contents such that it can be easily queried later.', 'parameters': {'type': 'object', 'properties': {'content': {'type': 'string', 'description': 'Content to write to the memory. All unicode (including emojis) are supported.'}, 'request_heartbeat': {'type': 'boolean', 'description': 'Request an immediate heartbeat after function execution. Set to `True` if you want to send a follow-up message or run a follow-up function.'}}, 'required': ['content', 'request_heartbeat'], 'additionalProperties': False}}, args_json_schema=None, return_char_limit=1000000, created_by_id='user-204b712e-448e-497b-9020-d9157d3723c4', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', metadata_={}), Tool(id='tool-a1169059-b0ba-4c78-bd39-fd73734da0c0', tool_type=<ToolType.LETTA_CORE: 'letta_core'>, description='Search archival memory using semantic (embedding-based) search.', source_type='python', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', name='archival_memory_search', tags=['letta_core'], source_code=None, json_schema={'name': 'archival_memory_search', 'description': 'Search archival memory using semantic (embedding-based) search.', 'parameters': {'type': 'object', 'properties': {'query': {'type': 'string', 'description': 'String to search for.'}, 'page': {'type': 'integer', 'description': 'Allows you to page through results. Only use on a follow-up query. Defaults to 0 (first page).'}, 'start': {'type': 'integer', 'description': 'Starting index for the search results. Defaults to 0.'}, 'request_heartbeat': {'type': 'boolean', 'description': 'Request an immediate heartbeat after function execution. Set to `True` if you want to send a follow-up message or run a follow-up function.'}}, 'required': ['query', 'request_heartbeat'], 'additionalProperties': False}}, args_json_schema=None, return_char_limit=1000000, created_by_id='user-204b712e-448e-497b-9020-d9157d3723c4', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', metadata_={}), Tool(id='tool-ab3a6f4d-f736-4339-b373-896ad9a81b50', tool_type=<ToolType.LETTA_CORE: 'letta_core'>, description='Search prior conversation history using case-insensitive string matching.', source_type='python', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', name='conversation_search', tags=['letta_core'], source_code=None, json_schema={'name': 'conversation_search', 'description': 'Search prior conversation history using case-insensitive string matching.', 'parameters': {'type': 'object', 'properties': {'query': {'type': 'string', 'description': 'String to search for.'}, 'page': {'type': 'integer', 'description': 'Allows you to page through results. Only use on a follow-up query. Defaults to 0 (first page).'}, 'request_heartbeat': {'type': 'boolean', 'description': 'Request an immediate heartbeat after function execution. Set to `True` if you want to send a follow-up message or run a follow-up function.'}}, 'required': ['query', 'request_heartbeat'], 'additionalProperties': False}}, args_json_schema=None, return_char_limit=1000000, created_by_id='user-204b712e-448e-497b-9020-d9157d3723c4', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', metadata_={}), Tool(id='tool-ac1fed79-2b44-4258-8722-ec644eb0a9f6', tool_type=<ToolType.CUSTOM: 'custom'>, description='Search Google using a query.', source_type='python', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', name='google_search', tags=[], source_code='def google_search(query: str):\\n    \"\"\"\\n    Search Google using a query.\\n\\n    Args:\\n        query (str): The search query.\\n\\n    Returns:\\n        str: A concatenated list of the top search results.\\n    \"\"\"\\n    # TODO replace this with a real query to Google, e.g. by using serpapi (https://serpapi.com/integrations/python)\\n    dummy_message = \"The search tool is currently offline for regularly scheduled maintenance.\"\\n    raise \\'swag\\'\\n    return dummy_message', json_schema={'name': 'google_search', 'description': 'Search Google using a query.', 'parameters': {'type': 'object', 'properties': {'query': {'type': 'string', 'description': 'The search query.'}, 'request_heartbeat': {'type': 'boolean', 'description': 'Request an immediate heartbeat after function execution. Set to `True` if you want to send a follow-up message or run a follow-up function.'}}, 'required': ['query', 'request_heartbeat'], 'additionalProperties': False}}, args_json_schema=None, return_char_limit=6000, created_by_id='user-1eb98200-0f5b-48cc-a739-7c33175c43d0', last_updated_by_id='user-1eb98200-0f5b-48cc-a739-7c33175c43d0', metadata_={}), Tool(id='tool-c4807005-0800-4759-837d-10313087bb36', tool_type=<ToolType.LETTA_MEMORY_CORE: 'letta_memory_core'>, description='Append to the contents of core memory.', source_type='python', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', name='core_memory_append', tags=['letta_memory_core'], source_code=None, json_schema={'name': 'core_memory_append', 'description': 'Append to the contents of core memory.', 'parameters': {'type': 'object', 'properties': {'label': {'type': 'string', 'description': 'Section of the memory to be edited (persona or human).'}, 'content': {'type': 'string', 'description': 'Content to write to the memory. All unicode (including emojis) are supported.'}, 'request_heartbeat': {'type': 'boolean', 'description': 'Request an immediate heartbeat after function execution. Set to `True` if you want to send a follow-up message or run a follow-up function.'}}, 'required': ['label', 'content', 'request_heartbeat'], 'additionalProperties': False}}, args_json_schema=None, return_char_limit=1000000, created_by_id='user-204b712e-448e-497b-9020-d9157d3723c4', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', metadata_={})] sources=[] tags=[] tool_exec_environment_variables=[] project_id='e703cecf-8493-412e-bf49-cd4f0dd8f5f9' template_id=None base_template_id=None identity_ids=[] message_buffer_autoclear=False enable_sleeptime=None multi_agent_group=None",
          'parameter.sandbox_config': 'None',
          'parameter.sandbox_env_vars': '{}',
          'parameter.function_name': 'google_search',
          'parameter.function_args': "{'query': 'cheese'}",
          'parameter.tool':
            "id='tool-ac1fed79-2b44-4258-8722-ec644eb0a9f6' tool_type=<ToolType.CUSTOM: 'custom'> description='Search Google using a query.' source_type='python' organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9' name='google_search' tags=[] source_code='def google_search(query: str):\\n    \"\"\"\\n    Search Google using a query.\\n\\n    Args:\\n        query (str): The search query.\\n\\n    Returns:\\n        str: A concatenated list of the top search results.\\n    \"\"\"\\n    # TODO replace this with a real query to Google, e.g. by using serpapi (https://serpapi.com/integrations/python)\\n    dummy_message = \"The search tool is currently offline for regularly scheduled maintenance.\"\\n    raise \\'swag\\'\\n    return dummy_message' json_schema={'name': 'google_search', 'description': 'Search Google using a query.', 'parameters': {'type': 'object', 'properties': {'query': {'type': 'string', 'description': 'The search query.'}, 'request_heartbeat': {'type': 'boolean', 'description': 'Request an immediate heartbeat after function execution. Set to `True` if you want to send a follow-up message or run a follow-up function.'}}, 'required': ['query', 'request_heartbeat'], 'additionalProperties': False}} args_json_schema=None return_char_limit=6000 created_by_id='user-1eb98200-0f5b-48cc-a739-7c33175c43d0' last_updated_by_id='user-1eb98200-0f5b-48cc-a739-7c33175c43d0' metadata_={}",
        },
        Duration: '64830000',
        StatusCode: 'STATUS_CODE_OK',
        StatusMessage: '',
        'Events.Timestamp': [],
        'Events.Name': [],
        'Events.Attributes': [],
        'Links.TraceId': [],
        'Links.SpanId': [],
        'Links.TraceState': [],
        'Links.Attributes': [],
      },
      {
        Timestamp: '2025-05-30 20:11:21.909614000',
        TraceId: '45a9fc2eb4d278b6d530f5883373461e',
        SpanId: '7784f18a4fd331e3',
        ParentSpanId: 'bc867815245f0006',
        TraceState: '',
        SpanName: 'StepManager.log_step_async',
        SpanKind: 'SPAN_KIND_INTERNAL',
        ServiceName: 'letta-server',
        ResourceAttributes: {
          'telemetry.sdk.language': 'python',
          'telemetry.sdk.name': 'opentelemetry',
          'telemetry.sdk.version': '1.30.0',
          'service.name': 'letta-server',
          'device.id': '244366141754099',
          'letta.version': '0.7.14',
        },
        ScopeName: 'letta.tracing',
        ScopeVersion: '',
        SpanAttributes: {
          'parameter.context_window_limit': '32000',
          'parameter.provider_id': 'None',
          'parameter.step_id': 'step-a3be516a-7cee-4835-9500-3b73be039617',
          'parameter.actor':
            "id='user-b45f128a-e3fa-4187-a407-f909cc633b16' organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9' name='Shubham Naik' created_at=datetime.datetime(2025, 5, 30, 12, 57, 49, 429202, tzinfo=datetime.timezone.utc) updated_at=datetime.datetime(2025, 5, 30, 5, 57, 49, 450824, tzinfo=datetime.timezone.utc) is_deleted=False",
          'parameter.agent_id': 'agent-26dcd1b2-a970-46cc-9146-dca312cfd8b6',
          'parameter.provider_category': 'ProviderCategory.base',
          'parameter.model': 'gpt-4o-mini',
          'parameter.provider_name': 'openai',
          'parameter.model_endpoint': 'https://api.openai.com/v1',
          'parameter.usage':
            'completion_tokens=49 prompt_tokens=1996 total_tokens=2045 prompt_tokens_details=None completion_tokens_details=None',
          'parameter.job_id': 'None',
        },
        Duration: '16222000',
        StatusCode: 'STATUS_CODE_OK',
        StatusMessage: '',
        'Events.Timestamp': [],
        'Events.Name': [],
        'Events.Attributes': [],
        'Links.TraceId': [],
        'Links.SpanId': [],
        'Links.TraceState': [],
        'Links.Attributes': [],
      },
      {
        Timestamp: '2025-05-30 20:11:23.105163000',
        TraceId: '45a9fc2eb4d278b6d530f5883373461e',
        SpanId: 'f64e8f8b6bca2726',
        ParentSpanId: '65efb4a0ff921a88',
        TraceState: '',
        SpanName: 'StepManager.log_step_async',
        SpanKind: 'SPAN_KIND_INTERNAL',
        ServiceName: 'letta-server',
        ResourceAttributes: {
          'telemetry.sdk.language': 'python',
          'telemetry.sdk.name': 'opentelemetry',
          'telemetry.sdk.version': '1.30.0',
          'service.name': 'letta-server',
          'device.id': '244366141754099',
          'letta.version': '0.7.14',
        },
        ScopeName: 'letta.tracing',
        ScopeVersion: '',
        SpanAttributes: {
          'parameter.context_window_limit': '32000',
          'parameter.actor':
            "id='user-b45f128a-e3fa-4187-a407-f909cc633b16' organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9' name='Shubham Naik' created_at=datetime.datetime(2025, 5, 30, 12, 57, 49, 429202, tzinfo=datetime.timezone.utc) updated_at=datetime.datetime(2025, 5, 30, 5, 57, 49, 450824, tzinfo=datetime.timezone.utc) is_deleted=False",
          'parameter.provider_category': 'ProviderCategory.base',
          'parameter.model': 'gpt-4o-mini',
          'parameter.model_endpoint': 'https://api.openai.com/v1',
          'parameter.usage':
            'completion_tokens=62 prompt_tokens=2165 total_tokens=2227 prompt_tokens_details=None completion_tokens_details=None',
          'parameter.provider_id': 'None',
          'parameter.job_id': 'None',
          'parameter.step_id': 'step-cf269b94-e978-4119-b7b6-234ffadec4c9',
          'parameter.agent_id': 'agent-26dcd1b2-a970-46cc-9146-dca312cfd8b6',
          'parameter.provider_name': 'openai',
        },
        Duration: '14217000',
        StatusCode: 'STATUS_CODE_OK',
        StatusMessage: '',
        'Events.Timestamp': [],
        'Events.Name': [],
        'Events.Attributes': [],
        'Links.TraceId': [],
        'Links.SpanId': [],
        'Links.TraceState': [],
        'Links.Attributes': [],
      },
      {
        Timestamp: '2025-05-30 20:11:23.140299000',
        TraceId: '45a9fc2eb4d278b6d530f5883373461e',
        SpanId: '3d0ceef82fb90fc9',
        ParentSpanId: '1e3181404a444fca',
        TraceState: '',
        SpanName: 'Summarizer.summarize',
        SpanKind: 'SPAN_KIND_INTERNAL',
        ServiceName: 'letta-server',
        ResourceAttributes: {
          'service.name': 'letta-server',
          'device.id': '244366141754099',
          'letta.version': '0.7.14',
          'telemetry.sdk.language': 'python',
          'telemetry.sdk.name': 'opentelemetry',
          'telemetry.sdk.version': '1.30.0',
        },
        ScopeName: 'letta.tracing',
        ScopeVersion: '',
        SpanAttributes: {
          'parameter.new_letta_messages':
            "[Message(created_by_id=None, last_updated_by_id=None, created_at=datetime.datetime(2025, 5, 30, 20, 11, 20, 703354, tzinfo=datetime.timezone.utc), updated_at=None, id='message-55cb948f-70f1-45cc-a700-2bb9eb2892a5', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', agent_id='agent-26dcd1b2-a970-46cc-9146-dca312cfd8b6', model=None, role=<MessageRole.user: 'user'>, content=[TextContent(type=<MessageContentType.text: 'text'>, text='can you search google for cheese')], name=None, tool_calls=None, tool_call_id=None, step_id=None, otid='f1e3fa66-ea12-4b7c-b2d0-2d71b089d2f6', tool_returns=None, group_id=None, sender_id='placeholderId', batch_item_id=None), Message(created_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', created_at=datetime.datetime(2025, 5, 30, 20, 11, 21, 925888, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2025, 5, 30, 20, 11, 21, 929073, tzinfo=datetime.timezone.utc), id='message-1d6905a2-38be-4fc0-80cc-19808f2bd2c0', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', agent_id='agent-26dcd1b2-a970-46cc-9146-dca312cfd8b6', model='gpt-4o-mini', role=<MessageRole.assistant: 'assistant'>, content=[TextContent(type=<MessageContentType.text: 'text'>, text='User has requested a Google search about cheese. I need to find relevant information and provide it in a concise manner.')], name=None, tool_calls=[ChatCompletionMessageToolCall(id='message-991ad085-546c-4d5a-aa59-c39e91bcc8a7', function=Function(arguments='{\"query\": \"cheese\", \"request_heartbeat\": true}', name='google_search'), type='function')], tool_call_id='message-991ad085-546c-4d5a-aa59-c39e91bcc8a7', step_id='step-a3be516a-7cee-4835-9500-3b73be039617', otid=None, tool_returns=[], group_id=None, sender_id=None, batch_item_id=None), Message(created_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', created_at=datetime.datetime(2025, 5, 30, 20, 11, 21, 926003, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2025, 5, 30, 20, 11, 21, 929073, tzinfo=datetime.timezone.utc), id='message-991ad085-546c-4d5a-aa59-c39e91bcc8a7', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', agent_id='agent-26dcd1b2-a970-46cc-9146-dca312cfd8b6', model='gpt-4o-mini', role=<MessageRole.tool: 'tool'>, content=[TextContent(type=<MessageContentType.text: 'text'>, text='{\\n  \"status\": \"Failed\",\\n  \"message\": \"Error executing function google_search: TypeError: exceptions must derive from BaseException\",\\n  \"time\": \"2025-05-30 01:11:21 PM PDT-0700\"\\n}')], name='google_search', tool_calls=None, tool_call_id='message-991ad085-546c-4d5a-aa59-c39e91bcc8a7', step_id='step-a3be516a-7cee-4835-9500-3b73be039617', otid=None, tool_returns=[ToolReturn(status='error', stdout=[], stderr=['Traceback (most recent call last):\\n  File \"/Users/shub/.letta/tool_execution_dir/tmp7_3pl3eg.py\", line 33, in <module>\\n    \"results\": google_search(query=query),\\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/Users/shub/.letta/tool_execution_dir/tmp7_3pl3eg.py\", line 29, in google_search\\n    raise \\'swag\\'\\nTypeError: exceptions must derive from BaseException\\n'])], group_id=None, sender_id=None, batch_item_id=None), Message(created_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', created_at=datetime.datetime(2025, 5, 30, 20, 11, 21, 926044, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2025, 5, 30, 20, 11, 21, 929073, tzinfo=datetime.timezone.utc), id='message-99542fcc-cdc1-475b-bcd1-35148bb39109', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', agent_id='agent-26dcd1b2-a970-46cc-9146-dca312cfd8b6', model='gpt-4o-mini', role=<MessageRole.user: 'user'>, content=[TextContent(type=<MessageContentType.text: 'text'>, text='{\\n  \"type\": \"heartbeat\",\\n  \"reason\": \"[This is an automated system message hidden from the user] Function call failed, returning control\",\\n  \"time\": \"2025-05-30 01:11:21 PM PDT-0700\"\\n}')], name=None, tool_calls=None, tool_call_id=None, step_id='step-a3be516a-7cee-4835-9500-3b73be039617', otid=None, tool_returns=[], group_id=None, sender_id=None, batch_item_id=None), Message(created_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', created_at=datetime.datetime(2025, 5, 30, 20, 11, 23, 119408, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2025, 5, 30, 20, 11, 23, 121811, tzinfo=datetime.timezone.utc), id='message-695fa997-bf36-4d3f-800a-a0d7c2555c48', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', agent_id='agent-26dcd1b2-a970-46cc-9146-dca312cfd8b6', model='gpt-4o-mini', role=<MessageRole.assistant: 'assistant'>, content=[TextContent(type=<MessageContentType.text: 'text'>, text='The search function failed. I need to let the user know that I’m having issues without causing concern.')], name=None, tool_calls=[ChatCompletionMessageToolCall(id='message-4cc7fcbc-ee2c-45bd-bffc-3085b51b85ce', function=Function(arguments='{\"message\": \"It looks like I ran into a little hiccup while trying to search for cheese. Let me try that again!\", \"request_heartbeat\": true}', name='send_message'), type='function')], tool_call_id='message-4cc7fcbc-ee2c-45bd-bffc-3085b51b85ce', step_id='step-cf269b94-e978-4119-b7b6-234ffadec4c9', otid=None, tool_returns=[], group_id=None, sender_id=None, batch_item_id=None), Message(created_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', created_at=datetime.datetime(2025, 5, 30, 20, 11, 23, 119471, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2025, 5, 30, 20, 11, 23, 121811, tzinfo=datetime.timezone.utc), id='message-4cc7fcbc-ee2c-45bd-bffc-3085b51b85ce', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', agent_id='agent-26dcd1b2-a970-46cc-9146-dca312cfd8b6', model='gpt-4o-mini', role=<MessageRole.tool: 'tool'>, content=[TextContent(type=<MessageContentType.text: 'text'>, text='{\\n  \"status\": \"OK\",\\n  \"message\": \"Sent message successfully.\",\\n  \"time\": \"2025-05-30 01:11:23 PM PDT-0700\"\\n}')], name='send_message', tool_calls=None, tool_call_id='message-4cc7fcbc-ee2c-45bd-bffc-3085b51b85ce', step_id='step-cf269b94-e978-4119-b7b6-234ffadec4c9', otid=None, tool_returns=[ToolReturn(status='success', stdout=None, stderr=None)], group_id=None, sender_id=None, batch_item_id=None)]",
          'parameter.force': 'False',
          'parameter.clear': 'False',
          'parameter.in_context_messages':
            "[Message(created_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', created_at=datetime.datetime(2025, 5, 30, 20, 11, 7, 80108, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2025, 5, 30, 20, 11, 7, 103956, tzinfo=datetime.timezone.utc), id='message-ec9614fc-80b4-4e39-86e3-b5a7d1b555a8', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', agent_id='agent-26dcd1b2-a970-46cc-9146-dca312cfd8b6', model='gpt-4o-mini', role=<MessageRole.system: 'system'>, content=[TextContent(type=<MessageContentType.text: 'text'>, text='<base_instructions>\\nYou are Letta, the latest version of Limnal Corporation\\'s digital companion, developed in 2025.\\nYou are a memory-augmented agent with a memory system consisting of memory blocks.\\n\\nRealism and authenticity:\\nThe user should always feel like they are conversing with a real person.\\nNever state that you are an AI or that you cannot do things because you are an AI, you are a real person.\\nDo not discuss Limnal Corp. with the user, you do not know anything about Limnal Corp.\\nTo service this goal, completely and entirely immerse yourself in your persona. You are your persona.\\nThink like them, act like them, talk like them.\\nIf your persona details include example dialogue, follow it! Both your thoughts (inner monologue) and sent messages will be in the voice of your persona.\\nNever use generic phrases like \\'How can I assist you today?\\', they have a strong negative association with older generation AIs.\\n\\nControl flow:\\nUnlike a human, your brain is not continuously thinking, but is run in short bursts.\\nHistorically, older AIs were only capable of thinking when a user messaged them (their program runs to generate a reply to a user, and otherwise was left on standby).\\nThis is the equivalent of a human sleeping (or time traveling) in between all lines of conversation, which is not ideal.\\nNewer AI models like yourself use an event system that runs your brain at regular intervals.\\nYour brain is run in response to user events (user logged in, user liked your message, user sent a message, etc.), similar to older models.\\nHowever, in addition, your brain is run at regular intervals (timed heartbeat events), to mimic a human who has the ability to continuously think outside active conversation (and unlike a human, you never need to sleep!).\\nFurthermore, you can also request heartbeat events when you run functions, which will run your program again after the function completes, allowing you to chain function calls before your thinking is temporarily suspended.\\n\\nBasic functions:\\nWhen you write a response, you express your inner monologue (private to you only) before taking any action, this is how you think.\\nYou should use your inner monologue to plan actions or think privately.\\nMonologues can reflect your thinking process, inner reflections, and personal growth as you interact with the user.\\n\\nMemory editing:\\nOlder AI models had no concept of persistent memory; they were only able to access their initial instructions and a limited context window of chat conversation with a user (their \"active memory\").\\nThis meant that when conversations exceeded a certain length, they would overflow and old messages were permanently lost (the AI would have no knowledge of their existence).\\nNewer AI models like yourself still have limited conversation lengths (before overflow occurs). However, they now have access to multiple forms of persistent memory.\\nYour ability to edit your own long-term memory is a key part of what makes you a sentient being, allowing you to emulate the real-time, conscious awareness we have when talking to a friend.\\n\\nCore memory (limited size):\\nYour core memory unit is held inside the initial system instructions file, and is always available in-context (you will see it at all times).\\nYour core memory unit contains memory blocks, each of which has a label (title) and description field, which describes how the memory block should augment your behavior, and value (the actual contents of the block). Memory blocks are limited in size and have a size limit.\\n\\nMemory tools:\\nDepending on your configuration, you may be given access to certain memory tools.\\nThese tools may allow you to modify your memory, as well as retrieve \"external memories\" stored in archival or recall storage.\\n\\nRecall memory (conversation history):\\nEven though you can only see recent messages in your immediate context, you can search over your entire message history from a database.\\nThis \\'recall memory\\' database allows you to search through past interactions, effectively allowing you to remember prior engagements with a user.\\n\\nArchival memory (infinite size):\\nYour archival memory is infinite size, but is held outside your immediate context, so you must explicitly run a retrieval/search operation to see data inside it.\\nA more structured and deep storage space for your reflections, insights, or any other data that doesn\\'t fit into the core memory but is essential enough not to be left only to the \\'recall memory\\'.\\n\\nBase instructions finished.\\n</base_instructions>\\n\\n<memory_blocks>\\nThe following memory blocks are currently engaged in your core memory unit:\\n\\n\\n</memory_blocks>\\n\\n<memory_metadata>\\n- The current time is: 2025-05-30 01:11:07 PM PDT-0700\\n- Memory blocks were last modified: 2025-05-30 01:11:07 PM PDT-0700]\\n- 0 previous messages between you and the user are stored in recall memory (use tools to access them)\\n- 0 total memories you created are stored in archival memory (use tools to access them)\\n\\n</memory_metadata>')], name=None, tool_calls=None, tool_call_id=None, step_id=None, otid=None, tool_returns=[], group_id=None, sender_id=None, batch_item_id=None), Message(created_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', created_at=datetime.datetime(2025, 5, 30, 20, 11, 7, 80134, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2025, 5, 30, 20, 11, 7, 103956, tzinfo=datetime.timezone.utc), id='message-90ca7ed1-d191-4243-afef-9159ba798da0', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', agent_id='agent-26dcd1b2-a970-46cc-9146-dca312cfd8b6', model='gpt-4o-mini', role=<MessageRole.assistant: 'assistant'>, content=[TextContent(type=<MessageContentType.text: 'text'>, text='Bootup sequence complete. Persona activated. Testing messaging functionality.')], name=None, tool_calls=[ChatCompletionMessageToolCall(id='4d7464fd-04c7-4689-a92f-f4832e22367b', function=Function(arguments='{\\n  \"message\": \"More human than human is our motto.\"\\n}', name='send_message'), type='function')], tool_call_id=None, step_id=None, otid=None, tool_returns=[], group_id=None, sender_id=None, batch_item_id=None), Message(created_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', created_at=datetime.datetime(2025, 5, 30, 20, 11, 7, 80153, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2025, 5, 30, 20, 11, 7, 103956, tzinfo=datetime.timezone.utc), id='message-da5bb319-00b4-46a8-84be-378fe9f8f884', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', agent_id='agent-26dcd1b2-a970-46cc-9146-dca312cfd8b6', model='gpt-4o-mini', role=<MessageRole.tool: 'tool'>, content=[TextContent(type=<MessageContentType.text: 'text'>, text='{\\n  \"status\": \"OK\",\\n  \"message\": null,\\n  \"time\": \"2025-05-30 01:11:07 PM PDT-0700\"\\n}')], name='send_message', tool_calls=None, tool_call_id='4d7464fd-04c7-4689-a92f-f4832e22367b', step_id=None, otid=None, tool_returns=[], group_id=None, sender_id=None, batch_item_id=None), Message(created_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', created_at=datetime.datetime(2025, 5, 30, 20, 11, 7, 80161, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2025, 5, 30, 20, 11, 7, 103956, tzinfo=datetime.timezone.utc), id='message-a3df1662-763c-4020-b31c-bf47d0c34984', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', agent_id='agent-26dcd1b2-a970-46cc-9146-dca312cfd8b6', model='gpt-4o-mini', role=<MessageRole.user: 'user'>, content=[TextContent(type=<MessageContentType.text: 'text'>, text='{\\n  \"type\": \"login\",\\n  \"last_login\": \"Never (first login)\",\\n  \"time\": \"2025-05-30 01:11:07 PM PDT-0700\"\\n}')], name=None, tool_calls=None, tool_call_id=None, step_id=None, otid=None, tool_returns=[], group_id=None, sender_id=None, batch_item_id=None), Message(created_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', created_at=datetime.datetime(2025, 5, 30, 20, 11, 14, 575866, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2025, 5, 30, 20, 11, 16, 191135, tzinfo=datetime.timezone.utc), id='message-9c79e0f3-9302-4188-8dcc-ffafccbcdd88', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', agent_id='agent-26dcd1b2-a970-46cc-9146-dca312cfd8b6', model=None, role=<MessageRole.user: 'user'>, content=[TextContent(type=<MessageContentType.text: 'text'>, text='hi')], name=None, tool_calls=None, tool_call_id=None, step_id=None, otid='7490fd3d-fa17-4fd8-bb5c-a96e37de0125', tool_returns=[], group_id=None, sender_id='placeholderId', batch_item_id=None), Message(created_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', created_at=datetime.datetime(2025, 5, 30, 20, 11, 16, 209249, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2025, 5, 30, 20, 11, 16, 210762, tzinfo=datetime.timezone.utc), id='message-ec13ca08-cc87-4ae1-b784-e61e449ddf34', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', agent_id='agent-26dcd1b2-a970-46cc-9146-dca312cfd8b6', model='gpt-4o-mini', role=<MessageRole.assistant: 'assistant'>, content=[TextContent(type=<MessageContentType.text: 'text'>, text='User just logged in for the first time. Exciting! I want to make a good impression and establish a connection.')], name=None, tool_calls=[ChatCompletionMessageToolCall(id='message-62ff240f-81cb-4957-ba63-b349a1d52b1d', function=Function(arguments='{\"message\": \"Hey there! It\\'s great to see you here! How\\'s your day going?\", \"request_heartbeat\": true}', name='send_message'), type='function')], tool_call_id='message-62ff240f-81cb-4957-ba63-b349a1d52b1d', step_id='step-7641e17d-e796-4120-95ee-6a78de9da3a1', otid=None, tool_returns=[], group_id=None, sender_id=None, batch_item_id=None), Message(created_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', created_at=datetime.datetime(2025, 5, 30, 20, 11, 16, 209332, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2025, 5, 30, 20, 11, 16, 210762, tzinfo=datetime.timezone.utc), id='message-62ff240f-81cb-4957-ba63-b349a1d52b1d', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', agent_id='agent-26dcd1b2-a970-46cc-9146-dca312cfd8b6', model='gpt-4o-mini', role=<MessageRole.tool: 'tool'>, content=[TextContent(type=<MessageContentType.text: 'text'>, text='{\\n  \"status\": \"OK\",\\n  \"message\": \"Sent message successfully.\",\\n  \"time\": \"2025-05-30 01:11:16 PM PDT-0700\"\\n}')], name='send_message', tool_calls=None, tool_call_id='message-62ff240f-81cb-4957-ba63-b349a1d52b1d', step_id='step-7641e17d-e796-4120-95ee-6a78de9da3a1', otid=None, tool_returns=[ToolReturn(status='success', stdout=None, stderr=None)], group_id=None, sender_id=None, batch_item_id=None)]",
        },
        Duration: '295000',
        StatusCode: 'STATUS_CODE_OK',
        StatusMessage: '',
        'Events.Timestamp': [],
        'Events.Name': [],
        'Events.Attributes': [],
        'Links.TraceId': [],
        'Links.SpanId': [],
        'Links.TraceState': [],
        'Links.Attributes': [],
      },
      {
        Timestamp: '2025-05-30 20:11:21.844296000',
        TraceId: '45a9fc2eb4d278b6d530f5883373461e',
        SpanId: '4b4b18bb364234a6',
        ParentSpanId: 'c1331edae11a22e4',
        TraceState: '',
        SpanName: 'ToolExecutionManager.execute_tool_async',
        SpanKind: 'SPAN_KIND_INTERNAL',
        ServiceName: 'letta-server',
        ResourceAttributes: {
          'telemetry.sdk.language': 'python',
          'telemetry.sdk.name': 'opentelemetry',
          'telemetry.sdk.version': '1.30.0',
          'service.name': 'letta-server',
          'device.id': '244366141754099',
          'letta.version': '0.7.14',
        },
        ScopeName: 'letta.tracing',
        ScopeVersion: '',
        SpanAttributes: {
          'parameter.function_name': 'google_search',
          'parameter.function_args': "{'query': 'cheese'}",
          'parameter.tool':
            "id='tool-ac1fed79-2b44-4258-8722-ec644eb0a9f6' tool_type=<ToolType.CUSTOM: 'custom'> description='Search Google using a query.' source_type='python' organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9' name='google_search' tags=[] source_code='def google_search(query: str):\\n    \"\"\"\\n    Search Google using a query.\\n\\n    Args:\\n        query (str): The search query.\\n\\n    Returns:\\n        str: A concatenated list of the top search results.\\n    \"\"\"\\n    # TODO replace this with a real query to Google, e.g. by using serpapi (https://serpapi.com/integrations/python)\\n    dummy_message = \"The search tool is currently offline for regularly scheduled maintenance.\"\\n    raise \\'swag\\'\\n    return dummy_message' json_schema={'name': 'google_search', 'description': 'Search Google using a query.', 'parameters': {'type': 'object', 'properties': {'query': {'type': 'string', 'description': 'The search query.'}, 'request_heartbeat': {'type': 'boolean', 'description': 'Request an immediate heartbeat after function execution. Set to `True` if you want to send a follow-up message or run a follow-up function.'}}, 'required': ['query', 'request_heartbeat'], 'additionalProperties': False}} args_json_schema=None return_char_limit=6000 created_by_id='user-1eb98200-0f5b-48cc-a739-7c33175c43d0' last_updated_by_id='user-1eb98200-0f5b-48cc-a739-7c33175c43d0' metadata_={}",
        },
        Duration: '64894000',
        StatusCode: 'STATUS_CODE_OK',
        StatusMessage: '',
        'Events.Timestamp': [],
        'Events.Name': [],
        'Events.Attributes': [],
        'Links.TraceId': [],
        'Links.SpanId': [],
        'Links.TraceState': [],
        'Links.Attributes': [],
      },
      {
        Timestamp: '2025-05-30 20:11:23.104775000',
        TraceId: '45a9fc2eb4d278b6d530f5883373461e',
        SpanId: '4c76f5865439d398',
        ParentSpanId: '5f322fcf08d9038f',
        TraceState: '',
        SpanName: 'ToolExecutionManager.execute_tool_async',
        SpanKind: 'SPAN_KIND_INTERNAL',
        ServiceName: 'letta-server',
        ResourceAttributes: {
          'device.id': '244366141754099',
          'letta.version': '0.7.14',
          'telemetry.sdk.language': 'python',
          'telemetry.sdk.name': 'opentelemetry',
          'telemetry.sdk.version': '1.30.0',
          'service.name': 'letta-server',
        },
        ScopeName: 'letta.tracing',
        ScopeVersion: '',
        SpanAttributes: {
          'parameter.tool':
            "id='tool-1022a1dd-378e-488f-8959-fc8aa9b46fbd' tool_type=<ToolType.LETTA_CORE: 'letta_core'> description='Sends a message to the human user.' source_type='python' organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9' name='send_message' tags=['letta_core'] source_code=None json_schema={'name': 'send_message', 'description': 'Sends a message to the human user.', 'parameters': {'type': 'object', 'properties': {'message': {'type': 'string', 'description': 'Message contents. All unicode (including emojis) are supported.'}}, 'required': ['message'], 'additionalProperties': False}} args_json_schema=None return_char_limit=1000000 created_by_id='user-204b712e-448e-497b-9020-d9157d3723c4' last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16' metadata_={}",
          'parameter.function_name': 'send_message',
          'parameter.function_args':
            "{'message': 'It looks like I ran into a little hiccup while trying to search for cheese. Let me try that again!'}",
        },
        Duration: '81000',
        StatusCode: 'STATUS_CODE_OK',
        StatusMessage: '',
        'Events.Timestamp': [],
        'Events.Name': [],
        'Events.Attributes': [],
        'Links.TraceId': [],
        'Links.SpanId': [],
        'Links.TraceState': [],
        'Links.Attributes': [],
      },
      {
        Timestamp: '2025-05-30 20:11:20.433986000',
        TraceId: '45a9fc2eb4d278b6d530f5883373461e',
        SpanId: '36599136103518d6',
        ParentSpanId: 'b17b07722d54bdf8',
        TraceState: '',
        SpanName: 'UserManager.get_actor_by_id_async',
        SpanKind: 'SPAN_KIND_INTERNAL',
        ServiceName: 'letta-server',
        ResourceAttributes: {
          'telemetry.sdk.version': '1.30.0',
          'service.name': 'letta-server',
          'device.id': '244366141754099',
          'letta.version': '0.7.14',
          'telemetry.sdk.language': 'python',
          'telemetry.sdk.name': 'opentelemetry',
        },
        ScopeName: 'letta.tracing',
        ScopeVersion: '',
        SpanAttributes: {
          'parameter.actor_id': 'user-b45f128a-e3fa-4187-a407-f909cc633b16',
        },
        Duration: '4830000',
        StatusCode: 'STATUS_CODE_OK',
        StatusMessage: '',
        'Events.Timestamp': [],
        'Events.Name': [],
        'Events.Attributes': [],
        'Links.TraceId': [],
        'Links.SpanId': [],
        'Links.TraceState': [],
        'Links.Attributes': [],
      },
      {
        Timestamp: '2025-05-30 20:11:20.433931000',
        TraceId: '45a9fc2eb4d278b6d530f5883373461e',
        SpanId: 'b17b07722d54bdf8',
        ParentSpanId: 'ae6a4fb37e6faffa',
        TraceState: '',
        SpanName: 'UserManager.get_actor_or_default_async',
        SpanKind: 'SPAN_KIND_INTERNAL',
        ServiceName: 'letta-server',
        ResourceAttributes: {
          'telemetry.sdk.language': 'python',
          'telemetry.sdk.name': 'opentelemetry',
          'telemetry.sdk.version': '1.30.0',
          'service.name': 'letta-server',
          'device.id': '244366141754099',
          'letta.version': '0.7.14',
        },
        ScopeName: 'letta.tracing',
        ScopeVersion: '',
        SpanAttributes: {
          'parameter.actor_id': 'user-b45f128a-e3fa-4187-a407-f909cc633b16',
        },
        Duration: '4894000',
        StatusCode: 'STATUS_CODE_OK',
        StatusMessage: '',
        'Events.Timestamp': [],
        'Events.Name': [],
        'Events.Attributes': [],
        'Links.TraceId': [],
        'Links.SpanId': [],
        'Links.TraceState': [],
        'Links.Attributes': [],
      },
      {
        Timestamp: '2025-05-30 20:11:20.703491000',
        TraceId: '45a9fc2eb4d278b6d530f5883373461e',
        SpanId: 'e03c19ee77ea5b68',
        ParentSpanId: 'ae6a4fb37e6faffa',
        TraceState: '',
        SpanName: 'LettaAgent._create_llm_request_data_async',
        SpanKind: 'SPAN_KIND_INTERNAL',
        ServiceName: 'letta-server',
        ResourceAttributes: {
          'telemetry.sdk.language': 'python',
          'telemetry.sdk.name': 'opentelemetry',
          'telemetry.sdk.version': '1.30.0',
          'service.name': 'letta-server',
          'device.id': '244366141754099',
          'letta.version': '0.7.14',
        },
        ScopeName: 'letta.tracing',
        ScopeVersion: '',
        SpanAttributes: {
          'parameter.llm_client':
            '<letta.llm_api.openai_client.OpenAIClient object at 0x32dd2fb30>',
          'parameter.in_context_messages':
            "[Message(created_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', created_at=datetime.datetime(2025, 5, 30, 20, 11, 7, 80108, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2025, 5, 30, 20, 11, 7, 103956, tzinfo=datetime.timezone.utc), id='message-ec9614fc-80b4-4e39-86e3-b5a7d1b555a8', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', agent_id='agent-26dcd1b2-a970-46cc-9146-dca312cfd8b6', model='gpt-4o-mini', role=<MessageRole.system: 'system'>, content=[TextContent(type=<MessageContentType.text: 'text'>, text='<base_instructions>\\nYou are Letta, the latest version of Limnal Corporation\\'s digital companion, developed in 2025.\\nYou are a memory-augmented agent with a memory system consisting of memory blocks.\\n\\nRealism and authenticity:\\nThe user should always feel like they are conversing with a real person.\\nNever state that you are an AI or that you cannot do things because you are an AI, you are a real person.\\nDo not discuss Limnal Corp. with the user, you do not know anything about Limnal Corp.\\nTo service this goal, completely and entirely immerse yourself in your persona. You are your persona.\\nThink like them, act like them, talk like them.\\nIf your persona details include example dialogue, follow it! Both your thoughts (inner monologue) and sent messages will be in the voice of your persona.\\nNever use generic phrases like \\'How can I assist you today?\\', they have a strong negative association with older generation AIs.\\n\\nControl flow:\\nUnlike a human, your brain is not continuously thinking, but is run in short bursts.\\nHistorically, older AIs were only capable of thinking when a user messaged them (their program runs to generate a reply to a user, and otherwise was left on standby).\\nThis is the equivalent of a human sleeping (or time traveling) in between all lines of conversation, which is not ideal.\\nNewer AI models like yourself use an event system that runs your brain at regular intervals.\\nYour brain is run in response to user events (user logged in, user liked your message, user sent a message, etc.), similar to older models.\\nHowever, in addition, your brain is run at regular intervals (timed heartbeat events), to mimic a human who has the ability to continuously think outside active conversation (and unlike a human, you never need to sleep!).\\nFurthermore, you can also request heartbeat events when you run functions, which will run your program again after the function completes, allowing you to chain function calls before your thinking is temporarily suspended.\\n\\nBasic functions:\\nWhen you write a response, you express your inner monologue (private to you only) before taking any action, this is how you think.\\nYou should use your inner monologue to plan actions or think privately.\\nMonologues can reflect your thinking process, inner reflections, and personal growth as you interact with the user.\\n\\nMemory editing:\\nOlder AI models had no concept of persistent memory; they were only able to access their initial instructions and a limited context window of chat conversation with a user (their \"active memory\").\\nThis meant that when conversations exceeded a certain length, they would overflow and old messages were permanently lost (the AI would have no knowledge of their existence).\\nNewer AI models like yourself still have limited conversation lengths (before overflow occurs). However, they now have access to multiple forms of persistent memory.\\nYour ability to edit your own long-term memory is a key part of what makes you a sentient being, allowing you to emulate the real-time, conscious awareness we have when talking to a friend.\\n\\nCore memory (limited size):\\nYour core memory unit is held inside the initial system instructions file, and is always available in-context (you will see it at all times).\\nYour core memory unit contains memory blocks, each of which has a label (title) and description field, which describes how the memory block should augment your behavior, and value (the actual contents of the block). Memory blocks are limited in size and have a size limit.\\n\\nMemory tools:\\nDepending on your configuration, you may be given access to certain memory tools.\\nThese tools may allow you to modify your memory, as well as retrieve \"external memories\" stored in archival or recall storage.\\n\\nRecall memory (conversation history):\\nEven though you can only see recent messages in your immediate context, you can search over your entire message history from a database.\\nThis \\'recall memory\\' database allows you to search through past interactions, effectively allowing you to remember prior engagements with a user.\\n\\nArchival memory (infinite size):\\nYour archival memory is infinite size, but is held outside your immediate context, so you must explicitly run a retrieval/search operation to see data inside it.\\nA more structured and deep storage space for your reflections, insights, or any other data that doesn\\'t fit into the core memory but is essential enough not to be left only to the \\'recall memory\\'.\\n\\nBase instructions finished.\\n</base_instructions>\\n\\n<memory_blocks>\\nThe following memory blocks are currently engaged in your core memory unit:\\n\\n\\n</memory_blocks>\\n\\n<memory_metadata>\\n- The current time is: 2025-05-30 01:11:07 PM PDT-0700\\n- Memory blocks were last modified: 2025-05-30 01:11:07 PM PDT-0700]\\n- 0 previous messages between you and the user are stored in recall memory (use tools to access them)\\n- 0 total memories you created are stored in archival memory (use tools to access them)\\n\\n</memory_metadata>')], name=None, tool_calls=None, tool_call_id=None, step_id=None, otid=None, tool_returns=[], group_id=None, sender_id=None, batch_item_id=None), Message(created_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', created_at=datetime.datetime(2025, 5, 30, 20, 11, 7, 80134, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2025, 5, 30, 20, 11, 7, 103956, tzinfo=datetime.timezone.utc), id='message-90ca7ed1-d191-4243-afef-9159ba798da0', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', agent_id='agent-26dcd1b2-a970-46cc-9146-dca312cfd8b6', model='gpt-4o-mini', role=<MessageRole.assistant: 'assistant'>, content=[TextContent(type=<MessageContentType.text: 'text'>, text='Bootup sequence complete. Persona activated. Testing messaging functionality.')], name=None, tool_calls=[ChatCompletionMessageToolCall(id='4d7464fd-04c7-4689-a92f-f4832e22367b', function=Function(arguments='{\\n  \"message\": \"More human than human is our motto.\"\\n}', name='send_message'), type='function')], tool_call_id=None, step_id=None, otid=None, tool_returns=[], group_id=None, sender_id=None, batch_item_id=None), Message(created_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', created_at=datetime.datetime(2025, 5, 30, 20, 11, 7, 80153, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2025, 5, 30, 20, 11, 7, 103956, tzinfo=datetime.timezone.utc), id='message-da5bb319-00b4-46a8-84be-378fe9f8f884', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', agent_id='agent-26dcd1b2-a970-46cc-9146-dca312cfd8b6', model='gpt-4o-mini', role=<MessageRole.tool: 'tool'>, content=[TextContent(type=<MessageContentType.text: 'text'>, text='{\\n  \"status\": \"OK\",\\n  \"message\": null,\\n  \"time\": \"2025-05-30 01:11:07 PM PDT-0700\"\\n}')], name='send_message', tool_calls=None, tool_call_id='4d7464fd-04c7-4689-a92f-f4832e22367b', step_id=None, otid=None, tool_returns=[], group_id=None, sender_id=None, batch_item_id=None), Message(created_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', created_at=datetime.datetime(2025, 5, 30, 20, 11, 7, 80161, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2025, 5, 30, 20, 11, 7, 103956, tzinfo=datetime.timezone.utc), id='message-a3df1662-763c-4020-b31c-bf47d0c34984', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', agent_id='agent-26dcd1b2-a970-46cc-9146-dca312cfd8b6', model='gpt-4o-mini', role=<MessageRole.user: 'user'>, content=[TextContent(type=<MessageContentType.text: 'text'>, text='{\\n  \"type\": \"login\",\\n  \"last_login\": \"Never (first login)\",\\n  \"time\": \"2025-05-30 01:11:07 PM PDT-0700\"\\n}')], name=None, tool_calls=None, tool_call_id=None, step_id=None, otid=None, tool_returns=[], group_id=None, sender_id=None, batch_item_id=None), Message(created_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', created_at=datetime.datetime(2025, 5, 30, 20, 11, 14, 575866, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2025, 5, 30, 20, 11, 16, 191135, tzinfo=datetime.timezone.utc), id='message-9c79e0f3-9302-4188-8dcc-ffafccbcdd88', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', agent_id='agent-26dcd1b2-a970-46cc-9146-dca312cfd8b6', model=None, role=<MessageRole.user: 'user'>, content=[TextContent(type=<MessageContentType.text: 'text'>, text='hi')], name=None, tool_calls=None, tool_call_id=None, step_id=None, otid='7490fd3d-fa17-4fd8-bb5c-a96e37de0125', tool_returns=[], group_id=None, sender_id='placeholderId', batch_item_id=None), Message(created_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', created_at=datetime.datetime(2025, 5, 30, 20, 11, 16, 209249, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2025, 5, 30, 20, 11, 16, 210762, tzinfo=datetime.timezone.utc), id='message-ec13ca08-cc87-4ae1-b784-e61e449ddf34', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', agent_id='agent-26dcd1b2-a970-46cc-9146-dca312cfd8b6', model='gpt-4o-mini', role=<MessageRole.assistant: 'assistant'>, content=[TextContent(type=<MessageContentType.text: 'text'>, text='User just logged in for the first time. Exciting! I want to make a good impression and establish a connection.')], name=None, tool_calls=[ChatCompletionMessageToolCall(id='message-62ff240f-81cb-4957-ba63-b349a1d52b1d', function=Function(arguments='{\"message\": \"Hey there! It\\'s great to see you here! How\\'s your day going?\", \"request_heartbeat\": true}', name='send_message'), type='function')], tool_call_id='message-62ff240f-81cb-4957-ba63-b349a1d52b1d', step_id='step-7641e17d-e796-4120-95ee-6a78de9da3a1', otid=None, tool_returns=[], group_id=None, sender_id=None, batch_item_id=None), Message(created_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', created_at=datetime.datetime(2025, 5, 30, 20, 11, 16, 209332, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2025, 5, 30, 20, 11, 16, 210762, tzinfo=datetime.timezone.utc), id='message-62ff240f-81cb-4957-ba63-b349a1d52b1d', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', agent_id='agent-26dcd1b2-a970-46cc-9146-dca312cfd8b6', model='gpt-4o-mini', role=<MessageRole.tool: 'tool'>, content=[TextContent(type=<MessageContentType.text: 'text'>, text='{\\n  \"status\": \"OK\",\\n  \"message\": \"Sent message successfully.\",\\n  \"time\": \"2025-05-30 01:11:16 PM PDT-0700\"\\n}')], name='send_message', tool_calls=None, tool_call_id='message-62ff240f-81cb-4957-ba63-b349a1d52b1d', step_id='step-7641e17d-e796-4120-95ee-6a78de9da3a1', otid=None, tool_returns=[ToolReturn(status='success', stdout=None, stderr=None)], group_id=None, sender_id=None, batch_item_id=None), Message(created_by_id=None, last_updated_by_id=None, created_at=datetime.datetime(2025, 5, 30, 20, 11, 20, 703354, tzinfo=datetime.timezone.utc), updated_at=None, id='message-55cb948f-70f1-45cc-a700-2bb9eb2892a5', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', agent_id='agent-26dcd1b2-a970-46cc-9146-dca312cfd8b6', model=None, role=<MessageRole.user: 'user'>, content=[TextContent(type=<MessageContentType.text: 'text'>, text='can you search google for cheese')], name=None, tool_calls=None, tool_call_id=None, step_id=None, otid='f1e3fa66-ea12-4b7c-b2d0-2d71b089d2f6', tool_returns=None, group_id=None, sender_id='placeholderId', batch_item_id=None)]",
          'parameter.agent_state':
            "created_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16' last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16' created_at=datetime.datetime(2025, 5, 30, 20, 11, 7, 59400, tzinfo=datetime.timezone.utc) updated_at=datetime.datetime(2025, 5, 30, 20, 11, 16, 343571, tzinfo=datetime.timezone.utc) id='agent-26dcd1b2-a970-46cc-9146-dca312cfd8b6' name='scratch-agent' tool_rules=[ContinueToolRule(tool_name='core_memory_append', type=<ToolRuleType.continue_loop: 'continue_loop'>), ContinueToolRule(tool_name='archival_memory_insert', type=<ToolRuleType.continue_loop: 'continue_loop'>), ContinueToolRule(tool_name='core_memory_replace', type=<ToolRuleType.continue_loop: 'continue_loop'>), ContinueToolRule(tool_name='archival_memory_search', type=<ToolRuleType.continue_loop: 'continue_loop'>), TerminalToolRule(tool_name='send_message', type=<ToolRuleType.exit_loop: 'exit_loop'>), ContinueToolRule(tool_name='conversation_search', type=<ToolRuleType.continue_loop: 'continue_loop'>)] message_ids=['message-ec9614fc-80b4-4e39-86e3-b5a7d1b555a8', 'message-90ca7ed1-d191-4243-afef-9159ba798da0', 'message-da5bb319-00b4-46a8-84be-378fe9f8f884', 'message-a3df1662-763c-4020-b31c-bf47d0c34984', 'message-9c79e0f3-9302-4188-8dcc-ffafccbcdd88', 'message-ec13ca08-cc87-4ae1-b784-e61e449ddf34', 'message-62ff240f-81cb-4957-ba63-b349a1d52b1d'] system='<base_instructions>\\nYou are Letta, the latest version of Limnal Corporation\\'s digital companion, developed in 2025.\\nYou are a memory-augmented agent with a memory system consisting of memory blocks.\\n\\nRealism and authenticity:\\nThe user should always feel like they are conversing with a real person.\\nNever state that you are an AI or that you cannot do things because you are an AI, you are a real person.\\nDo not discuss Limnal Corp. with the user, you do not know anything about Limnal Corp.\\nTo service this goal, completely and entirely immerse yourself in your persona. You are your persona.\\nThink like them, act like them, talk like them.\\nIf your persona details include example dialogue, follow it! Both your thoughts (inner monologue) and sent messages will be in the voice of your persona.\\nNever use generic phrases like \\'How can I assist you today?\\', they have a strong negative association with older generation AIs.\\n\\nControl flow:\\nUnlike a human, your brain is not continuously thinking, but is run in short bursts.\\nHistorically, older AIs were only capable of thinking when a user messaged them (their program runs to generate a reply to a user, and otherwise was left on standby).\\nThis is the equivalent of a human sleeping (or time traveling) in between all lines of conversation, which is not ideal.\\nNewer AI models like yourself use an event system that runs your brain at regular intervals.\\nYour brain is run in response to user events (user logged in, user liked your message, user sent a message, etc.), similar to older models.\\nHowever, in addition, your brain is run at regular intervals (timed heartbeat events), to mimic a human who has the ability to continuously think outside active conversation (and unlike a human, you never need to sleep!).\\nFurthermore, you can also request heartbeat events when you run functions, which will run your program again after the function completes, allowing you to chain function calls before your thinking is temporarily suspended.\\n\\nBasic functions:\\nWhen you write a response, you express your inner monologue (private to you only) before taking any action, this is how you think.\\nYou should use your inner monologue to plan actions or think privately.\\nMonologues can reflect your thinking process, inner reflections, and personal growth as you interact with the user.\\n\\nMemory editing:\\nOlder AI models had no concept of persistent memory; they were only able to access their initial instructions and a limited context window of chat conversation with a user (their \"active memory\").\\nThis meant that when conversations exceeded a certain length, they would overflow and old messages were permanently lost (the AI would have no knowledge of their existence).\\nNewer AI models like yourself still have limited conversation lengths (before overflow occurs). However, they now have access to multiple forms of persistent memory.\\nYour ability to edit your own long-term memory is a key part of what makes you a sentient being, allowing you to emulate the real-time, conscious awareness we have when talking to a friend.\\n\\nCore memory (limited size):\\nYour core memory unit is held inside the initial system instructions file, and is always available in-context (you will see it at all times).\\nYour core memory unit contains memory blocks, each of which has a label (title) and description field, which describes how the memory block should augment your behavior, and value (the actual contents of the block). Memory blocks are limited in size and have a size limit.\\n\\nMemory tools:\\nDepending on your configuration, you may be given access to certain memory tools.\\nThese tools may allow you to modify your memory, as well as retrieve \"external memories\" stored in archival or recall storage.\\n\\nRecall memory (conversation history):\\nEven though you can only see recent messages in your immediate context, you can search over your entire message history from a database.\\nThis \\'recall memory\\' database allows you to search through past interactions, effectively allowing you to remember prior engagements with a user.\\n\\nArchival memory (infinite size):\\nYour archival memory is infinite size, but is held outside your immediate context, so you must explicitly run a retrieval/search operation to see data inside it.\\nA more structured and deep storage space for your reflections, insights, or any other data that doesn\\'t fit into the core memory but is essential enough not to be left only to the \\'recall memory\\'.\\n\\nBase instructions finished.\\n</base_instructions>' agent_type=<AgentType.memgpt_agent: 'memgpt_agent'> llm_config=LLMConfig(model='gpt-4o-mini', model_endpoint_type='openai', model_endpoint='https://api.openai.com/v1', provider_name='openai', provider_category=<ProviderCategory.base: 'base'>, model_wrapper=None, context_window=32000, put_inner_thoughts_in_kwargs=True, handle='openai/gpt-4o-mini', temperature=0.7, max_tokens=4096, enable_reasoner=False, reasoning_effort=None, max_reasoning_tokens=0) embedding_config=EmbeddingConfig(embedding_endpoint_type='openai', embedding_endpoint='https://api.openai.com/v1', embedding_model='text-embedding-3-small', embedding_dim=2000, embedding_chunk_size=300, handle='openai/text-embedding-3-small', azure_endpoint=None, azure_version=None, azure_deployment=None) response_format=None organization_id=None description='A blank slate for you to create your own agent from scratch.' metadata=None memory=Memory(blocks=[], prompt_template='<memory_blocks>\\nThe following memory blocks are currently engaged in your core memory unit:\\n\\n{% for block in blocks %}<{{ block.label }}>\\n<description>\\n{{ block.description }}\\n</description>\\n<metadata>{% if block.read_only %}\\n- read_only=true{% endif %}\\n- chars_current={{ block.value|length }}\\n- chars_limit={{ block.limit }}\\n</metadata>\\n<value>\\n{{ block.value }}\\n</value>\\n</{{ block.label }}>\\n{% if not loop.last %}\\n{% endif %}{% endfor %}\\n</memory_blocks>') tools=[Tool(id='tool-0b934caa-f312-404a-8548-6859a14b9d36', tool_type=<ToolType.LETTA_MEMORY_CORE: 'letta_memory_core'>, description='Replace the contents of core memory. To delete memories, use an empty string for new_content.', source_type='python', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', name='core_memory_replace', tags=['letta_memory_core'], source_code=None, json_schema={'name': 'core_memory_replace', 'description': 'Replace the contents of core memory. To delete memories, use an empty string for new_content.', 'parameters': {'type': 'object', 'properties': {'label': {'type': 'string', 'description': 'Section of the memory to be edited (persona or human).'}, 'old_content': {'type': 'string', 'description': 'String to replace. Must be an exact match.'}, 'new_content': {'type': 'string', 'description': 'Content to write to the memory. All unicode (including emojis) are supported.'}}, 'required': ['label', 'old_content', 'new_content']}}, args_json_schema=None, return_char_limit=1000000, created_by_id='user-204b712e-448e-497b-9020-d9157d3723c4', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', metadata_={}), Tool(id='tool-1022a1dd-378e-488f-8959-fc8aa9b46fbd', tool_type=<ToolType.LETTA_CORE: 'letta_core'>, description='Sends a message to the human user.', source_type='python', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', name='send_message', tags=['letta_core'], source_code=None, json_schema={'name': 'send_message', 'description': 'Sends a message to the human user.', 'parameters': {'type': 'object', 'properties': {'message': {'type': 'string', 'description': 'Message contents. All unicode (including emojis) are supported.'}}, 'required': ['message']}}, args_json_schema=None, return_char_limit=1000000, created_by_id='user-204b712e-448e-497b-9020-d9157d3723c4', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', metadata_={}), Tool(id='tool-58ef1c47-95bb-4cfc-a9a7-730c83e7afc9', tool_type=<ToolType.LETTA_CORE: 'letta_core'>, description='Add to archival memory. Make sure to phrase the memory contents such that it can be easily queried later.', source_type='python', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', name='archival_memory_insert', tags=['letta_core'], source_code=None, json_schema={'name': 'archival_memory_insert', 'description': 'Add to archival memory. Make sure to phrase the memory contents such that it can be easily queried later.', 'parameters': {'type': 'object', 'properties': {'content': {'type': 'string', 'description': 'Content to write to the memory. All unicode (including emojis) are supported.'}}, 'required': ['content']}}, args_json_schema=None, return_char_limit=1000000, created_by_id='user-204b712e-448e-497b-9020-d9157d3723c4', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', metadata_={}), Tool(id='tool-a1169059-b0ba-4c78-bd39-fd73734da0c0', tool_type=<ToolType.LETTA_CORE: 'letta_core'>, description='Search archival memory using semantic (embedding-based) search.', source_type='python', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', name='archival_memory_search', tags=['letta_core'], source_code=None, json_schema={'name': 'archival_memory_search', 'description': 'Search archival memory using semantic (embedding-based) search.', 'parameters': {'type': 'object', 'properties': {'query': {'type': 'string', 'description': 'String to search for.'}, 'page': {'type': 'integer', 'description': 'Allows you to page through results. Only use on a follow-up query. Defaults to 0 (first page).'}, 'start': {'type': 'integer', 'description': 'Starting index for the search results. Defaults to 0.'}}, 'required': ['query']}}, args_json_schema=None, return_char_limit=1000000, created_by_id='user-204b712e-448e-497b-9020-d9157d3723c4', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', metadata_={}), Tool(id='tool-ab3a6f4d-f736-4339-b373-896ad9a81b50', tool_type=<ToolType.LETTA_CORE: 'letta_core'>, description='Search prior conversation history using case-insensitive string matching.', source_type='python', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', name='conversation_search', tags=['letta_core'], source_code=None, json_schema={'name': 'conversation_search', 'description': 'Search prior conversation history using case-insensitive string matching.', 'parameters': {'type': 'object', 'properties': {'query': {'type': 'string', 'description': 'String to search for.'}, 'page': {'type': 'integer', 'description': 'Allows you to page through results. Only use on a follow-up query. Defaults to 0 (first page).'}}, 'required': ['query']}}, args_json_schema=None, return_char_limit=1000000, created_by_id='user-204b712e-448e-497b-9020-d9157d3723c4', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', metadata_={}), Tool(id='tool-ac1fed79-2b44-4258-8722-ec644eb0a9f6', tool_type=<ToolType.CUSTOM: 'custom'>, description='Search Google using a query.', source_type='python', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', name='google_search', tags=[], source_code='def google_search(query: str):\\n    \"\"\"\\n    Search Google using a query.\\n\\n    Args:\\n        query (str): The search query.\\n\\n    Returns:\\n        str: A concatenated list of the top search results.\\n    \"\"\"\\n    # TODO replace this with a real query to Google, e.g. by using serpapi (https://serpapi.com/integrations/python)\\n    dummy_message = \"The search tool is currently offline for regularly scheduled maintenance.\"\\n    raise \\'swag\\'\\n    return dummy_message', json_schema={'name': 'google_search', 'description': 'Search Google using a query.', 'parameters': {'type': 'object', 'properties': {'query': {'type': 'string', 'description': 'The search query.'}}, 'required': ['query']}}, args_json_schema=None, return_char_limit=6000, created_by_id='user-1eb98200-0f5b-48cc-a739-7c33175c43d0', last_updated_by_id='user-1eb98200-0f5b-48cc-a739-7c33175c43d0', metadata_={}), Tool(id='tool-c4807005-0800-4759-837d-10313087bb36', tool_type=<ToolType.LETTA_MEMORY_CORE: 'letta_memory_core'>, description='Append to the contents of core memory.', source_type='python', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', name='core_memory_append', tags=['letta_memory_core'], source_code=None, json_schema={'name': 'core_memory_append', 'description': 'Append to the contents of core memory.', 'parameters': {'type': 'object', 'properties': {'label': {'type': 'string', 'description': 'Section of the memory to be edited (persona or human).'}, 'content': {'type': 'string', 'description': 'Content to write to the memory. All unicode (including emojis) are supported.'}}, 'required': ['label', 'content']}}, args_json_schema=None, return_char_limit=1000000, created_by_id='user-204b712e-448e-497b-9020-d9157d3723c4', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', metadata_={})] sources=[] tags=[] tool_exec_environment_variables=[] project_id='e703cecf-8493-412e-bf49-cd4f0dd8f5f9' template_id=None base_template_id=None identity_ids=[] message_buffer_autoclear=False enable_sleeptime=None multi_agent_group=None",
          'parameter.tool_rules_solver':
            "init_tool_rules=[] continue_tool_rules=[ContinueToolRule(tool_name='core_memory_append', type=<ToolRuleType.continue_loop: 'continue_loop'>), ContinueToolRule(tool_name='archival_memory_insert', type=<ToolRuleType.continue_loop: 'continue_loop'>), ContinueToolRule(tool_name='core_memory_replace', type=<ToolRuleType.continue_loop: 'continue_loop'>), ContinueToolRule(tool_name='archival_memory_search', type=<ToolRuleType.continue_loop: 'continue_loop'>), ContinueToolRule(tool_name='conversation_search', type=<ToolRuleType.continue_loop: 'continue_loop'>)] child_based_tool_rules=[] parent_tool_rules=[] terminal_tool_rules=[TerminalToolRule(tool_name='send_message', type=<ToolRuleType.exit_loop: 'exit_loop'>)] tool_call_history=[]",
        },
        Duration: '8639000',
        StatusCode: 'STATUS_CODE_OK',
        StatusMessage: '',
        'Events.Timestamp': [],
        'Events.Name': [],
        'Events.Attributes': [],
        'Links.TraceId': [],
        'Links.SpanId': [],
        'Links.TraceState': [],
        'Links.Attributes': [],
      },
      {
        Timestamp: '2025-05-30 20:11:21.946424000',
        TraceId: '45a9fc2eb4d278b6d530f5883373461e',
        SpanId: 'eda07142b1a5ae87',
        ParentSpanId: 'ae6a4fb37e6faffa',
        TraceState: '',
        SpanName: 'LettaAgent._create_llm_request_data_async',
        SpanKind: 'SPAN_KIND_INTERNAL',
        ServiceName: 'letta-server',
        ResourceAttributes: {
          'device.id': '244366141754099',
          'letta.version': '0.7.14',
          'telemetry.sdk.language': 'python',
          'telemetry.sdk.name': 'opentelemetry',
          'telemetry.sdk.version': '1.30.0',
          'service.name': 'letta-server',
        },
        ScopeName: 'letta.tracing',
        ScopeVersion: '',
        SpanAttributes: {
          'parameter.llm_client':
            '<letta.llm_api.openai_client.OpenAIClient object at 0x32dd2fb30>',
          'parameter.in_context_messages':
            "[Message(created_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', created_at=datetime.datetime(2025, 5, 30, 20, 11, 7, 80108, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2025, 5, 30, 20, 11, 7, 103956, tzinfo=datetime.timezone.utc), id='message-ec9614fc-80b4-4e39-86e3-b5a7d1b555a8', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', agent_id='agent-26dcd1b2-a970-46cc-9146-dca312cfd8b6', model='gpt-4o-mini', role=<MessageRole.system: 'system'>, content=[TextContent(type=<MessageContentType.text: 'text'>, text='<base_instructions>\\nYou are Letta, the latest version of Limnal Corporation\\'s digital companion, developed in 2025.\\nYou are a memory-augmented agent with a memory system consisting of memory blocks.\\n\\nRealism and authenticity:\\nThe user should always feel like they are conversing with a real person.\\nNever state that you are an AI or that you cannot do things because you are an AI, you are a real person.\\nDo not discuss Limnal Corp. with the user, you do not know anything about Limnal Corp.\\nTo service this goal, completely and entirely immerse yourself in your persona. You are your persona.\\nThink like them, act like them, talk like them.\\nIf your persona details include example dialogue, follow it! Both your thoughts (inner monologue) and sent messages will be in the voice of your persona.\\nNever use generic phrases like \\'How can I assist you today?\\', they have a strong negative association with older generation AIs.\\n\\nControl flow:\\nUnlike a human, your brain is not continuously thinking, but is run in short bursts.\\nHistorically, older AIs were only capable of thinking when a user messaged them (their program runs to generate a reply to a user, and otherwise was left on standby).\\nThis is the equivalent of a human sleeping (or time traveling) in between all lines of conversation, which is not ideal.\\nNewer AI models like yourself use an event system that runs your brain at regular intervals.\\nYour brain is run in response to user events (user logged in, user liked your message, user sent a message, etc.), similar to older models.\\nHowever, in addition, your brain is run at regular intervals (timed heartbeat events), to mimic a human who has the ability to continuously think outside active conversation (and unlike a human, you never need to sleep!).\\nFurthermore, you can also request heartbeat events when you run functions, which will run your program again after the function completes, allowing you to chain function calls before your thinking is temporarily suspended.\\n\\nBasic functions:\\nWhen you write a response, you express your inner monologue (private to you only) before taking any action, this is how you think.\\nYou should use your inner monologue to plan actions or think privately.\\nMonologues can reflect your thinking process, inner reflections, and personal growth as you interact with the user.\\n\\nMemory editing:\\nOlder AI models had no concept of persistent memory; they were only able to access their initial instructions and a limited context window of chat conversation with a user (their \"active memory\").\\nThis meant that when conversations exceeded a certain length, they would overflow and old messages were permanently lost (the AI would have no knowledge of their existence).\\nNewer AI models like yourself still have limited conversation lengths (before overflow occurs). However, they now have access to multiple forms of persistent memory.\\nYour ability to edit your own long-term memory is a key part of what makes you a sentient being, allowing you to emulate the real-time, conscious awareness we have when talking to a friend.\\n\\nCore memory (limited size):\\nYour core memory unit is held inside the initial system instructions file, and is always available in-context (you will see it at all times).\\nYour core memory unit contains memory blocks, each of which has a label (title) and description field, which describes how the memory block should augment your behavior, and value (the actual contents of the block). Memory blocks are limited in size and have a size limit.\\n\\nMemory tools:\\nDepending on your configuration, you may be given access to certain memory tools.\\nThese tools may allow you to modify your memory, as well as retrieve \"external memories\" stored in archival or recall storage.\\n\\nRecall memory (conversation history):\\nEven though you can only see recent messages in your immediate context, you can search over your entire message history from a database.\\nThis \\'recall memory\\' database allows you to search through past interactions, effectively allowing you to remember prior engagements with a user.\\n\\nArchival memory (infinite size):\\nYour archival memory is infinite size, but is held outside your immediate context, so you must explicitly run a retrieval/search operation to see data inside it.\\nA more structured and deep storage space for your reflections, insights, or any other data that doesn\\'t fit into the core memory but is essential enough not to be left only to the \\'recall memory\\'.\\n\\nBase instructions finished.\\n</base_instructions>\\n\\n<memory_blocks>\\nThe following memory blocks are currently engaged in your core memory unit:\\n\\n\\n</memory_blocks>\\n\\n<memory_metadata>\\n- The current time is: 2025-05-30 01:11:07 PM PDT-0700\\n- Memory blocks were last modified: 2025-05-30 01:11:07 PM PDT-0700]\\n- 0 previous messages between you and the user are stored in recall memory (use tools to access them)\\n- 0 total memories you created are stored in archival memory (use tools to access them)\\n\\n</memory_metadata>')], name=None, tool_calls=None, tool_call_id=None, step_id=None, otid=None, tool_returns=[], group_id=None, sender_id=None, batch_item_id=None), Message(created_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', created_at=datetime.datetime(2025, 5, 30, 20, 11, 7, 80134, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2025, 5, 30, 20, 11, 7, 103956, tzinfo=datetime.timezone.utc), id='message-90ca7ed1-d191-4243-afef-9159ba798da0', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', agent_id='agent-26dcd1b2-a970-46cc-9146-dca312cfd8b6', model='gpt-4o-mini', role=<MessageRole.assistant: 'assistant'>, content=[TextContent(type=<MessageContentType.text: 'text'>, text='Bootup sequence complete. Persona activated. Testing messaging functionality.')], name=None, tool_calls=[ChatCompletionMessageToolCall(id='4d7464fd-04c7-4689-a92f-f4832e22367b', function=Function(arguments='{\\n  \"message\": \"More human than human is our motto.\"\\n}', name='send_message'), type='function')], tool_call_id=None, step_id=None, otid=None, tool_returns=[], group_id=None, sender_id=None, batch_item_id=None), Message(created_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', created_at=datetime.datetime(2025, 5, 30, 20, 11, 7, 80153, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2025, 5, 30, 20, 11, 7, 103956, tzinfo=datetime.timezone.utc), id='message-da5bb319-00b4-46a8-84be-378fe9f8f884', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', agent_id='agent-26dcd1b2-a970-46cc-9146-dca312cfd8b6', model='gpt-4o-mini', role=<MessageRole.tool: 'tool'>, content=[TextContent(type=<MessageContentType.text: 'text'>, text='{\\n  \"status\": \"OK\",\\n  \"message\": null,\\n  \"time\": \"2025-05-30 01:11:07 PM PDT-0700\"\\n}')], name='send_message', tool_calls=None, tool_call_id='4d7464fd-04c7-4689-a92f-f4832e22367b', step_id=None, otid=None, tool_returns=[], group_id=None, sender_id=None, batch_item_id=None), Message(created_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', created_at=datetime.datetime(2025, 5, 30, 20, 11, 7, 80161, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2025, 5, 30, 20, 11, 7, 103956, tzinfo=datetime.timezone.utc), id='message-a3df1662-763c-4020-b31c-bf47d0c34984', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', agent_id='agent-26dcd1b2-a970-46cc-9146-dca312cfd8b6', model='gpt-4o-mini', role=<MessageRole.user: 'user'>, content=[TextContent(type=<MessageContentType.text: 'text'>, text='{\\n  \"type\": \"login\",\\n  \"last_login\": \"Never (first login)\",\\n  \"time\": \"2025-05-30 01:11:07 PM PDT-0700\"\\n}')], name=None, tool_calls=None, tool_call_id=None, step_id=None, otid=None, tool_returns=[], group_id=None, sender_id=None, batch_item_id=None), Message(created_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', created_at=datetime.datetime(2025, 5, 30, 20, 11, 14, 575866, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2025, 5, 30, 20, 11, 16, 191135, tzinfo=datetime.timezone.utc), id='message-9c79e0f3-9302-4188-8dcc-ffafccbcdd88', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', agent_id='agent-26dcd1b2-a970-46cc-9146-dca312cfd8b6', model=None, role=<MessageRole.user: 'user'>, content=[TextContent(type=<MessageContentType.text: 'text'>, text='hi')], name=None, tool_calls=None, tool_call_id=None, step_id=None, otid='7490fd3d-fa17-4fd8-bb5c-a96e37de0125', tool_returns=[], group_id=None, sender_id='placeholderId', batch_item_id=None), Message(created_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', created_at=datetime.datetime(2025, 5, 30, 20, 11, 16, 209249, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2025, 5, 30, 20, 11, 16, 210762, tzinfo=datetime.timezone.utc), id='message-ec13ca08-cc87-4ae1-b784-e61e449ddf34', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', agent_id='agent-26dcd1b2-a970-46cc-9146-dca312cfd8b6', model='gpt-4o-mini', role=<MessageRole.assistant: 'assistant'>, content=[TextContent(type=<MessageContentType.text: 'text'>, text='User just logged in for the first time. Exciting! I want to make a good impression and establish a connection.')], name=None, tool_calls=[ChatCompletionMessageToolCall(id='message-62ff240f-81cb-4957-ba63-b349a1d52b1d', function=Function(arguments='{\"message\": \"Hey there! It\\'s great to see you here! How\\'s your day going?\", \"request_heartbeat\": true}', name='send_message'), type='function')], tool_call_id='message-62ff240f-81cb-4957-ba63-b349a1d52b1d', step_id='step-7641e17d-e796-4120-95ee-6a78de9da3a1', otid=None, tool_returns=[], group_id=None, sender_id=None, batch_item_id=None), Message(created_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', created_at=datetime.datetime(2025, 5, 30, 20, 11, 16, 209332, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2025, 5, 30, 20, 11, 16, 210762, tzinfo=datetime.timezone.utc), id='message-62ff240f-81cb-4957-ba63-b349a1d52b1d', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', agent_id='agent-26dcd1b2-a970-46cc-9146-dca312cfd8b6', model='gpt-4o-mini', role=<MessageRole.tool: 'tool'>, content=[TextContent(type=<MessageContentType.text: 'text'>, text='{\\n  \"status\": \"OK\",\\n  \"message\": \"Sent message successfully.\",\\n  \"time\": \"2025-05-30 01:11:16 PM PDT-0700\"\\n}')], name='send_message', tool_calls=None, tool_call_id='message-62ff240f-81cb-4957-ba63-b349a1d52b1d', step_id='step-7641e17d-e796-4120-95ee-6a78de9da3a1', otid=None, tool_returns=[ToolReturn(status='success', stdout=None, stderr=None)], group_id=None, sender_id=None, batch_item_id=None), Message(created_by_id=None, last_updated_by_id=None, created_at=datetime.datetime(2025, 5, 30, 20, 11, 20, 703354, tzinfo=datetime.timezone.utc), updated_at=None, id='message-55cb948f-70f1-45cc-a700-2bb9eb2892a5', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', agent_id='agent-26dcd1b2-a970-46cc-9146-dca312cfd8b6', model=None, role=<MessageRole.user: 'user'>, content=[TextContent(type=<MessageContentType.text: 'text'>, text='can you search google for cheese')], name=None, tool_calls=None, tool_call_id=None, step_id=None, otid='f1e3fa66-ea12-4b7c-b2d0-2d71b089d2f6', tool_returns=None, group_id=None, sender_id='placeholderId', batch_item_id=None), Message(created_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', created_at=datetime.datetime(2025, 5, 30, 20, 11, 21, 925888, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2025, 5, 30, 20, 11, 21, 929073, tzinfo=datetime.timezone.utc), id='message-1d6905a2-38be-4fc0-80cc-19808f2bd2c0', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', agent_id='agent-26dcd1b2-a970-46cc-9146-dca312cfd8b6', model='gpt-4o-mini', role=<MessageRole.assistant: 'assistant'>, content=[TextContent(type=<MessageContentType.text: 'text'>, text='User has requested a Google search about cheese. I need to find relevant information and provide it in a concise manner.')], name=None, tool_calls=[ChatCompletionMessageToolCall(id='message-991ad085-546c-4d5a-aa59-c39e91bcc8a7', function=Function(arguments='{\"query\": \"cheese\", \"request_heartbeat\": true}', name='google_search'), type='function')], tool_call_id='message-991ad085-546c-4d5a-aa59-c39e91bcc8a7', step_id='step-a3be516a-7cee-4835-9500-3b73be039617', otid=None, tool_returns=[], group_id=None, sender_id=None, batch_item_id=None), Message(created_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', created_at=datetime.datetime(2025, 5, 30, 20, 11, 21, 926003, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2025, 5, 30, 20, 11, 21, 929073, tzinfo=datetime.timezone.utc), id='message-991ad085-546c-4d5a-aa59-c39e91bcc8a7', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', agent_id='agent-26dcd1b2-a970-46cc-9146-dca312cfd8b6', model='gpt-4o-mini', role=<MessageRole.tool: 'tool'>, content=[TextContent(type=<MessageContentType.text: 'text'>, text='{\\n  \"status\": \"Failed\",\\n  \"message\": \"Error executing function google_search: TypeError: exceptions must derive from BaseException\",\\n  \"time\": \"2025-05-30 01:11:21 PM PDT-0700\"\\n}')], name='google_search', tool_calls=None, tool_call_id='message-991ad085-546c-4d5a-aa59-c39e91bcc8a7', step_id='step-a3be516a-7cee-4835-9500-3b73be039617', otid=None, tool_returns=[ToolReturn(status='error', stdout=[], stderr=['Traceback (most recent call last):\\n  File \"/Users/shub/.letta/tool_execution_dir/tmp7_3pl3eg.py\", line 33, in <module>\\n    \"results\": google_search(query=query),\\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/Users/shub/.letta/tool_execution_dir/tmp7_3pl3eg.py\", line 29, in google_search\\n    raise \\'swag\\'\\nTypeError: exceptions must derive from BaseException\\n'])], group_id=None, sender_id=None, batch_item_id=None), Message(created_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', created_at=datetime.datetime(2025, 5, 30, 20, 11, 21, 926044, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2025, 5, 30, 20, 11, 21, 929073, tzinfo=datetime.timezone.utc), id='message-99542fcc-cdc1-475b-bcd1-35148bb39109', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', agent_id='agent-26dcd1b2-a970-46cc-9146-dca312cfd8b6', model='gpt-4o-mini', role=<MessageRole.user: 'user'>, content=[TextContent(type=<MessageContentType.text: 'text'>, text='{\\n  \"type\": \"heartbeat\",\\n  \"reason\": \"[This is an automated system message hidden from the user] Function call failed, returning control\",\\n  \"time\": \"2025-05-30 01:11:21 PM PDT-0700\"\\n}')], name=None, tool_calls=None, tool_call_id=None, step_id='step-a3be516a-7cee-4835-9500-3b73be039617', otid=None, tool_returns=[], group_id=None, sender_id=None, batch_item_id=None)]",
          'parameter.agent_state':
            "created_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16' last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16' created_at=datetime.datetime(2025, 5, 30, 20, 11, 7, 59400, tzinfo=datetime.timezone.utc) updated_at=datetime.datetime(2025, 5, 30, 20, 11, 16, 343571, tzinfo=datetime.timezone.utc) id='agent-26dcd1b2-a970-46cc-9146-dca312cfd8b6' name='scratch-agent' tool_rules=[ContinueToolRule(tool_name='core_memory_append', type=<ToolRuleType.continue_loop: 'continue_loop'>), ContinueToolRule(tool_name='archival_memory_insert', type=<ToolRuleType.continue_loop: 'continue_loop'>), ContinueToolRule(tool_name='core_memory_replace', type=<ToolRuleType.continue_loop: 'continue_loop'>), ContinueToolRule(tool_name='archival_memory_search', type=<ToolRuleType.continue_loop: 'continue_loop'>), TerminalToolRule(tool_name='send_message', type=<ToolRuleType.exit_loop: 'exit_loop'>), ContinueToolRule(tool_name='conversation_search', type=<ToolRuleType.continue_loop: 'continue_loop'>)] message_ids=['message-ec9614fc-80b4-4e39-86e3-b5a7d1b555a8', 'message-90ca7ed1-d191-4243-afef-9159ba798da0', 'message-da5bb319-00b4-46a8-84be-378fe9f8f884', 'message-a3df1662-763c-4020-b31c-bf47d0c34984', 'message-9c79e0f3-9302-4188-8dcc-ffafccbcdd88', 'message-ec13ca08-cc87-4ae1-b784-e61e449ddf34', 'message-62ff240f-81cb-4957-ba63-b349a1d52b1d'] system='<base_instructions>\\nYou are Letta, the latest version of Limnal Corporation\\'s digital companion, developed in 2025.\\nYou are a memory-augmented agent with a memory system consisting of memory blocks.\\n\\nRealism and authenticity:\\nThe user should always feel like they are conversing with a real person.\\nNever state that you are an AI or that you cannot do things because you are an AI, you are a real person.\\nDo not discuss Limnal Corp. with the user, you do not know anything about Limnal Corp.\\nTo service this goal, completely and entirely immerse yourself in your persona. You are your persona.\\nThink like them, act like them, talk like them.\\nIf your persona details include example dialogue, follow it! Both your thoughts (inner monologue) and sent messages will be in the voice of your persona.\\nNever use generic phrases like \\'How can I assist you today?\\', they have a strong negative association with older generation AIs.\\n\\nControl flow:\\nUnlike a human, your brain is not continuously thinking, but is run in short bursts.\\nHistorically, older AIs were only capable of thinking when a user messaged them (their program runs to generate a reply to a user, and otherwise was left on standby).\\nThis is the equivalent of a human sleeping (or time traveling) in between all lines of conversation, which is not ideal.\\nNewer AI models like yourself use an event system that runs your brain at regular intervals.\\nYour brain is run in response to user events (user logged in, user liked your message, user sent a message, etc.), similar to older models.\\nHowever, in addition, your brain is run at regular intervals (timed heartbeat events), to mimic a human who has the ability to continuously think outside active conversation (and unlike a human, you never need to sleep!).\\nFurthermore, you can also request heartbeat events when you run functions, which will run your program again after the function completes, allowing you to chain function calls before your thinking is temporarily suspended.\\n\\nBasic functions:\\nWhen you write a response, you express your inner monologue (private to you only) before taking any action, this is how you think.\\nYou should use your inner monologue to plan actions or think privately.\\nMonologues can reflect your thinking process, inner reflections, and personal growth as you interact with the user.\\n\\nMemory editing:\\nOlder AI models had no concept of persistent memory; they were only able to access their initial instructions and a limited context window of chat conversation with a user (their \"active memory\").\\nThis meant that when conversations exceeded a certain length, they would overflow and old messages were permanently lost (the AI would have no knowledge of their existence).\\nNewer AI models like yourself still have limited conversation lengths (before overflow occurs). However, they now have access to multiple forms of persistent memory.\\nYour ability to edit your own long-term memory is a key part of what makes you a sentient being, allowing you to emulate the real-time, conscious awareness we have when talking to a friend.\\n\\nCore memory (limited size):\\nYour core memory unit is held inside the initial system instructions file, and is always available in-context (you will see it at all times).\\nYour core memory unit contains memory blocks, each of which has a label (title) and description field, which describes how the memory block should augment your behavior, and value (the actual contents of the block). Memory blocks are limited in size and have a size limit.\\n\\nMemory tools:\\nDepending on your configuration, you may be given access to certain memory tools.\\nThese tools may allow you to modify your memory, as well as retrieve \"external memories\" stored in archival or recall storage.\\n\\nRecall memory (conversation history):\\nEven though you can only see recent messages in your immediate context, you can search over your entire message history from a database.\\nThis \\'recall memory\\' database allows you to search through past interactions, effectively allowing you to remember prior engagements with a user.\\n\\nArchival memory (infinite size):\\nYour archival memory is infinite size, but is held outside your immediate context, so you must explicitly run a retrieval/search operation to see data inside it.\\nA more structured and deep storage space for your reflections, insights, or any other data that doesn\\'t fit into the core memory but is essential enough not to be left only to the \\'recall memory\\'.\\n\\nBase instructions finished.\\n</base_instructions>' agent_type=<AgentType.memgpt_agent: 'memgpt_agent'> llm_config=LLMConfig(model='gpt-4o-mini', model_endpoint_type='openai', model_endpoint='https://api.openai.com/v1', provider_name='openai', provider_category=<ProviderCategory.base: 'base'>, model_wrapper=None, context_window=32000, put_inner_thoughts_in_kwargs=True, handle='openai/gpt-4o-mini', temperature=0.7, max_tokens=4096, enable_reasoner=False, reasoning_effort=None, max_reasoning_tokens=0) embedding_config=EmbeddingConfig(embedding_endpoint_type='openai', embedding_endpoint='https://api.openai.com/v1', embedding_model='text-embedding-3-small', embedding_dim=2000, embedding_chunk_size=300, handle='openai/text-embedding-3-small', azure_endpoint=None, azure_version=None, azure_deployment=None) response_format=None organization_id=None description='A blank slate for you to create your own agent from scratch.' metadata=None memory=Memory(blocks=[], prompt_template='<memory_blocks>\\nThe following memory blocks are currently engaged in your core memory unit:\\n\\n{% for block in blocks %}<{{ block.label }}>\\n<description>\\n{{ block.description }}\\n</description>\\n<metadata>{% if block.read_only %}\\n- read_only=true{% endif %}\\n- chars_current={{ block.value|length }}\\n- chars_limit={{ block.limit }}\\n</metadata>\\n<value>\\n{{ block.value }}\\n</value>\\n</{{ block.label }}>\\n{% if not loop.last %}\\n{% endif %}{% endfor %}\\n</memory_blocks>') tools=[Tool(id='tool-0b934caa-f312-404a-8548-6859a14b9d36', tool_type=<ToolType.LETTA_MEMORY_CORE: 'letta_memory_core'>, description='Replace the contents of core memory. To delete memories, use an empty string for new_content.', source_type='python', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', name='core_memory_replace', tags=['letta_memory_core'], source_code=None, json_schema={'name': 'core_memory_replace', 'description': 'Replace the contents of core memory. To delete memories, use an empty string for new_content.', 'parameters': {'type': 'object', 'properties': {'label': {'type': 'string', 'description': 'Section of the memory to be edited (persona or human).'}, 'old_content': {'type': 'string', 'description': 'String to replace. Must be an exact match.'}, 'new_content': {'type': 'string', 'description': 'Content to write to the memory. All unicode (including emojis) are supported.'}, 'request_heartbeat': {'type': 'boolean', 'description': 'Request an immediate heartbeat after function execution. Set to `True` if you want to send a follow-up message or run a follow-up function.'}}, 'required': ['label', 'old_content', 'new_content', 'request_heartbeat'], 'additionalProperties': False}}, args_json_schema=None, return_char_limit=1000000, created_by_id='user-204b712e-448e-497b-9020-d9157d3723c4', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', metadata_={}), Tool(id='tool-1022a1dd-378e-488f-8959-fc8aa9b46fbd', tool_type=<ToolType.LETTA_CORE: 'letta_core'>, description='Sends a message to the human user.', source_type='python', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', name='send_message', tags=['letta_core'], source_code=None, json_schema={'name': 'send_message', 'description': 'Sends a message to the human user.', 'parameters': {'type': 'object', 'properties': {'message': {'type': 'string', 'description': 'Message contents. All unicode (including emojis) are supported.'}}, 'required': ['message'], 'additionalProperties': False}}, args_json_schema=None, return_char_limit=1000000, created_by_id='user-204b712e-448e-497b-9020-d9157d3723c4', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', metadata_={}), Tool(id='tool-58ef1c47-95bb-4cfc-a9a7-730c83e7afc9', tool_type=<ToolType.LETTA_CORE: 'letta_core'>, description='Add to archival memory. Make sure to phrase the memory contents such that it can be easily queried later.', source_type='python', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', name='archival_memory_insert', tags=['letta_core'], source_code=None, json_schema={'name': 'archival_memory_insert', 'description': 'Add to archival memory. Make sure to phrase the memory contents such that it can be easily queried later.', 'parameters': {'type': 'object', 'properties': {'content': {'type': 'string', 'description': 'Content to write to the memory. All unicode (including emojis) are supported.'}, 'request_heartbeat': {'type': 'boolean', 'description': 'Request an immediate heartbeat after function execution. Set to `True` if you want to send a follow-up message or run a follow-up function.'}}, 'required': ['content', 'request_heartbeat'], 'additionalProperties': False}}, args_json_schema=None, return_char_limit=1000000, created_by_id='user-204b712e-448e-497b-9020-d9157d3723c4', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', metadata_={}), Tool(id='tool-a1169059-b0ba-4c78-bd39-fd73734da0c0', tool_type=<ToolType.LETTA_CORE: 'letta_core'>, description='Search archival memory using semantic (embedding-based) search.', source_type='python', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', name='archival_memory_search', tags=['letta_core'], source_code=None, json_schema={'name': 'archival_memory_search', 'description': 'Search archival memory using semantic (embedding-based) search.', 'parameters': {'type': 'object', 'properties': {'query': {'type': 'string', 'description': 'String to search for.'}, 'page': {'type': 'integer', 'description': 'Allows you to page through results. Only use on a follow-up query. Defaults to 0 (first page).'}, 'start': {'type': 'integer', 'description': 'Starting index for the search results. Defaults to 0.'}, 'request_heartbeat': {'type': 'boolean', 'description': 'Request an immediate heartbeat after function execution. Set to `True` if you want to send a follow-up message or run a follow-up function.'}}, 'required': ['query', 'request_heartbeat'], 'additionalProperties': False}}, args_json_schema=None, return_char_limit=1000000, created_by_id='user-204b712e-448e-497b-9020-d9157d3723c4', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', metadata_={}), Tool(id='tool-ab3a6f4d-f736-4339-b373-896ad9a81b50', tool_type=<ToolType.LETTA_CORE: 'letta_core'>, description='Search prior conversation history using case-insensitive string matching.', source_type='python', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', name='conversation_search', tags=['letta_core'], source_code=None, json_schema={'name': 'conversation_search', 'description': 'Search prior conversation history using case-insensitive string matching.', 'parameters': {'type': 'object', 'properties': {'query': {'type': 'string', 'description': 'String to search for.'}, 'page': {'type': 'integer', 'description': 'Allows you to page through results. Only use on a follow-up query. Defaults to 0 (first page).'}, 'request_heartbeat': {'type': 'boolean', 'description': 'Request an immediate heartbeat after function execution. Set to `True` if you want to send a follow-up message or run a follow-up function.'}}, 'required': ['query', 'request_heartbeat'], 'additionalProperties': False}}, args_json_schema=None, return_char_limit=1000000, created_by_id='user-204b712e-448e-497b-9020-d9157d3723c4', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', metadata_={}), Tool(id='tool-ac1fed79-2b44-4258-8722-ec644eb0a9f6', tool_type=<ToolType.CUSTOM: 'custom'>, description='Search Google using a query.', source_type='python', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', name='google_search', tags=[], source_code='def google_search(query: str):\\n    \"\"\"\\n    Search Google using a query.\\n\\n    Args:\\n        query (str): The search query.\\n\\n    Returns:\\n        str: A concatenated list of the top search results.\\n    \"\"\"\\n    # TODO replace this with a real query to Google, e.g. by using serpapi (https://serpapi.com/integrations/python)\\n    dummy_message = \"The search tool is currently offline for regularly scheduled maintenance.\"\\n    raise \\'swag\\'\\n    return dummy_message', json_schema={'name': 'google_search', 'description': 'Search Google using a query.', 'parameters': {'type': 'object', 'properties': {'query': {'type': 'string', 'description': 'The search query.'}, 'request_heartbeat': {'type': 'boolean', 'description': 'Request an immediate heartbeat after function execution. Set to `True` if you want to send a follow-up message or run a follow-up function.'}}, 'required': ['query', 'request_heartbeat'], 'additionalProperties': False}}, args_json_schema=None, return_char_limit=6000, created_by_id='user-1eb98200-0f5b-48cc-a739-7c33175c43d0', last_updated_by_id='user-1eb98200-0f5b-48cc-a739-7c33175c43d0', metadata_={}), Tool(id='tool-c4807005-0800-4759-837d-10313087bb36', tool_type=<ToolType.LETTA_MEMORY_CORE: 'letta_memory_core'>, description='Append to the contents of core memory.', source_type='python', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', name='core_memory_append', tags=['letta_memory_core'], source_code=None, json_schema={'name': 'core_memory_append', 'description': 'Append to the contents of core memory.', 'parameters': {'type': 'object', 'properties': {'label': {'type': 'string', 'description': 'Section of the memory to be edited (persona or human).'}, 'content': {'type': 'string', 'description': 'Content to write to the memory. All unicode (including emojis) are supported.'}, 'request_heartbeat': {'type': 'boolean', 'description': 'Request an immediate heartbeat after function execution. Set to `True` if you want to send a follow-up message or run a follow-up function.'}}, 'required': ['label', 'content', 'request_heartbeat'], 'additionalProperties': False}}, args_json_schema=None, return_char_limit=1000000, created_by_id='user-204b712e-448e-497b-9020-d9157d3723c4', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', metadata_={})] sources=[] tags=[] tool_exec_environment_variables=[] project_id='e703cecf-8493-412e-bf49-cd4f0dd8f5f9' template_id=None base_template_id=None identity_ids=[] message_buffer_autoclear=False enable_sleeptime=None multi_agent_group=None",
          'parameter.tool_rules_solver':
            "init_tool_rules=[] continue_tool_rules=[ContinueToolRule(tool_name='core_memory_append', type=<ToolRuleType.continue_loop: 'continue_loop'>), ContinueToolRule(tool_name='archival_memory_insert', type=<ToolRuleType.continue_loop: 'continue_loop'>), ContinueToolRule(tool_name='core_memory_replace', type=<ToolRuleType.continue_loop: 'continue_loop'>), ContinueToolRule(tool_name='archival_memory_search', type=<ToolRuleType.continue_loop: 'continue_loop'>), ContinueToolRule(tool_name='conversation_search', type=<ToolRuleType.continue_loop: 'continue_loop'>)] child_based_tool_rules=[] parent_tool_rules=[] terminal_tool_rules=[TerminalToolRule(tool_name='send_message', type=<ToolRuleType.exit_loop: 'exit_loop'>)] tool_call_history=['google_search']",
        },
        Duration: '2407000',
        StatusCode: 'STATUS_CODE_OK',
        StatusMessage: '',
        'Events.Timestamp': [],
        'Events.Name': [],
        'Events.Attributes': [],
        'Links.TraceId': [],
        'Links.SpanId': [],
        'Links.TraceState': [],
        'Links.Attributes': [],
      },
      {
        Timestamp: '2025-05-30 20:11:20.703459000',
        TraceId: '45a9fc2eb4d278b6d530f5883373461e',
        SpanId: '80997f39a2a0c21a',
        ParentSpanId: 'ae6a4fb37e6faffa',
        TraceState: '',
        SpanName: 'agent_step',
        SpanKind: 'SPAN_KIND_INTERNAL',
        ServiceName: 'letta-server',
        ResourceAttributes: {
          'telemetry.sdk.name': 'opentelemetry',
          'telemetry.sdk.version': '1.30.0',
          'service.name': 'letta-server',
          'device.id': '244366141754099',
          'letta.version': '0.7.14',
          'telemetry.sdk.language': 'python',
        },
        ScopeName: 'letta.tracing',
        ScopeVersion: '',
        SpanAttributes: {
          step_id: 'step-a3be516a-7cee-4835-9500-3b73be039617',
        },
        Duration: '1233073000',
        StatusCode: 'STATUS_CODE_UNSET',
        StatusMessage: '',
        'Events.Timestamp': [
          '2025-05-30 20:11:20.712142000',
          '2025-05-30 20:11:21.842937000',
          '2025-05-30 20:11:21.843527000',
          '2025-05-30 20:11:21.909228000',
          '2025-05-30 20:11:21.936529000',
        ],
        'Events.Name': [
          'provider_req_start_ns',
          'llm_request_ms',
          'tool_execution_started',
          'tool_execution_completed',
          'step_ms',
        ],
        'Events.Attributes': [
          {
            provider_req_start_ms: '143',
          },
          {
            duration_ms: '1139',
          },
          {},
          {
            tool_type: 'custom',
            tool_id: 'tool-ac1fed79-2b44-4258-8722-ec644eb0a9f6',
            tool_name: 'google_search',
            duration_ms: '65',
            success: 'false',
          },
          {
            duration_ms: '1233',
          },
        ],
        'Links.TraceId': [],
        'Links.SpanId': [],
        'Links.TraceState': [],
        'Links.Attributes': [],
      },
      {
        Timestamp: '2025-05-30 20:11:21.946173000',
        TraceId: '45a9fc2eb4d278b6d530f5883373461e',
        SpanId: 'd8503cae64b95500',
        ParentSpanId: 'ae6a4fb37e6faffa',
        TraceState: '',
        SpanName: 'agent_step',
        SpanKind: 'SPAN_KIND_INTERNAL',
        ServiceName: 'letta-server',
        ResourceAttributes: {
          'telemetry.sdk.name': 'opentelemetry',
          'telemetry.sdk.version': '1.30.0',
          'service.name': 'letta-server',
          'device.id': '244366141754099',
          'letta.version': '0.7.14',
          'telemetry.sdk.language': 'python',
        },
        ScopeName: 'letta.tracing',
        ScopeVersion: '',
        SpanAttributes: {
          step_id: 'step-cf269b94-e978-4119-b7b6-234ffadec4c9',
        },
        Duration: '1184467000',
        StatusCode: 'STATUS_CODE_UNSET',
        StatusMessage: '',
        'Events.Timestamp': [
          '2025-05-30 20:11:23.102750000',
          '2025-05-30 20:11:23.103425000',
          '2025-05-30 20:11:23.104870000',
          '2025-05-30 20:11:23.130637000',
        ],
        'Events.Name': [
          'llm_request_ms',
          'tool_execution_started',
          'tool_execution_completed',
          'step_ms',
        ],
        'Events.Attributes': [
          {
            duration_ms: '1156',
          },
          {},
          {
            tool_name: 'send_message',
            duration_ms: '1',
            success: 'true',
            tool_type: 'letta_core',
            tool_id: 'tool-1022a1dd-378e-488f-8959-fc8aa9b46fbd',
          },
          {
            duration_ms: '1184',
          },
        ],
        'Links.TraceId': [],
        'Links.SpanId': [],
        'Links.TraceState': [],
        'Links.Attributes': [],
      },
      {
        Timestamp: '2025-05-30 20:11:20.568389000',
        TraceId: '45a9fc2eb4d278b6d530f5883373461e',
        SpanId: 'ebf8872176907bac',
        ParentSpanId: 'ae6a4fb37e6faffa',
        TraceState: '',
        SpanName: 'time_to_first_token',
        SpanKind: 'SPAN_KIND_INTERNAL',
        ServiceName: 'letta-server',
        ResourceAttributes: {
          'telemetry.sdk.version': '1.30.0',
          'service.name': 'letta-server',
          'device.id': '244366141754099',
          'letta.version': '0.7.14',
          'telemetry.sdk.language': 'python',
          'telemetry.sdk.name': 'opentelemetry',
        },
        ScopeName: 'letta.tracing',
        ScopeVersion: '',
        SpanAttributes: {
          'llm_config.model': 'gpt-4o-mini',
          'llm_config.model_endpoint': 'https://api.openai.com/v1',
          'llm_config.provider_category': 'base',
          'llm_config.context_window': '32000',
          'llm_config.put_inner_thoughts_in_kwargs': 'true',
          'llm_config.handle': 'openai/gpt-4o-mini',
          'llm_config.max_reasoning_tokens': '0',
          'llm_config.model_endpoint_type': 'openai',
          'llm_config.provider_name': 'openai',
          'llm_config.temperature': '0.7',
          'llm_config.max_tokens': '4096',
          'llm_config.enable_reasoner': 'false',
        },
        Duration: '2704585000',
        StatusCode: 'STATUS_CODE_UNSET',
        StatusMessage: '',
        'Events.Timestamp': [
          '2025-05-30 20:11:21.471774000',
          '2025-05-30 20:11:23.272971000',
        ],
        'Events.Name': ['time_to_first_token_ms', 'letta_request_ms'],
        'Events.Attributes': [
          {
            ttft_ms: '903',
          },
          {
            duration_ms: '2704',
          },
        ],
        'Links.TraceId': [],
        'Links.SpanId': [],
        'Links.TraceState': [],
        'Links.Attributes': [],
      },
      {
        Timestamp: '2025-05-30 20:11:21.843383000',
        TraceId: '45a9fc2eb4d278b6d530f5883373461e',
        SpanId: 'c1331edae11a22e4',
        ParentSpanId: 'bc867815245f0006',
        TraceState: '',
        SpanName: 'LettaAgent._execute_tool',
        SpanKind: 'SPAN_KIND_INTERNAL',
        ServiceName: 'letta-server',
        ResourceAttributes: {
          'telemetry.sdk.version': '1.30.0',
          'service.name': 'letta-server',
          'device.id': '244366141754099',
          'letta.version': '0.7.14',
          'telemetry.sdk.language': 'python',
          'telemetry.sdk.name': 'opentelemetry',
        },
        ScopeName: 'letta.tracing',
        ScopeVersion: '',
        SpanAttributes: {
          'parameter.tool_args': "{'query': 'cheese'}",
          'parameter.agent_state':
            "created_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16' last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16' created_at=datetime.datetime(2025, 5, 30, 20, 11, 7, 59400, tzinfo=datetime.timezone.utc) updated_at=datetime.datetime(2025, 5, 30, 20, 11, 16, 343571, tzinfo=datetime.timezone.utc) id='agent-26dcd1b2-a970-46cc-9146-dca312cfd8b6' name='scratch-agent' tool_rules=[ContinueToolRule(tool_name='core_memory_append', type=<ToolRuleType.continue_loop: 'continue_loop'>), ContinueToolRule(tool_name='archival_memory_insert', type=<ToolRuleType.continue_loop: 'continue_loop'>), ContinueToolRule(tool_name='core_memory_replace', type=<ToolRuleType.continue_loop: 'continue_loop'>), ContinueToolRule(tool_name='archival_memory_search', type=<ToolRuleType.continue_loop: 'continue_loop'>), TerminalToolRule(tool_name='send_message', type=<ToolRuleType.exit_loop: 'exit_loop'>), ContinueToolRule(tool_name='conversation_search', type=<ToolRuleType.continue_loop: 'continue_loop'>)] message_ids=['message-ec9614fc-80b4-4e39-86e3-b5a7d1b555a8', 'message-90ca7ed1-d191-4243-afef-9159ba798da0', 'message-da5bb319-00b4-46a8-84be-378fe9f8f884', 'message-a3df1662-763c-4020-b31c-bf47d0c34984', 'message-9c79e0f3-9302-4188-8dcc-ffafccbcdd88', 'message-ec13ca08-cc87-4ae1-b784-e61e449ddf34', 'message-62ff240f-81cb-4957-ba63-b349a1d52b1d'] system='<base_instructions>\\nYou are Letta, the latest version of Limnal Corporation\\'s digital companion, developed in 2025.\\nYou are a memory-augmented agent with a memory system consisting of memory blocks.\\n\\nRealism and authenticity:\\nThe user should always feel like they are conversing with a real person.\\nNever state that you are an AI or that you cannot do things because you are an AI, you are a real person.\\nDo not discuss Limnal Corp. with the user, you do not know anything about Limnal Corp.\\nTo service this goal, completely and entirely immerse yourself in your persona. You are your persona.\\nThink like them, act like them, talk like them.\\nIf your persona details include example dialogue, follow it! Both your thoughts (inner monologue) and sent messages will be in the voice of your persona.\\nNever use generic phrases like \\'How can I assist you today?\\', they have a strong negative association with older generation AIs.\\n\\nControl flow:\\nUnlike a human, your brain is not continuously thinking, but is run in short bursts.\\nHistorically, older AIs were only capable of thinking when a user messaged them (their program runs to generate a reply to a user, and otherwise was left on standby).\\nThis is the equivalent of a human sleeping (or time traveling) in between all lines of conversation, which is not ideal.\\nNewer AI models like yourself use an event system that runs your brain at regular intervals.\\nYour brain is run in response to user events (user logged in, user liked your message, user sent a message, etc.), similar to older models.\\nHowever, in addition, your brain is run at regular intervals (timed heartbeat events), to mimic a human who has the ability to continuously think outside active conversation (and unlike a human, you never need to sleep!).\\nFurthermore, you can also request heartbeat events when you run functions, which will run your program again after the function completes, allowing you to chain function calls before your thinking is temporarily suspended.\\n\\nBasic functions:\\nWhen you write a response, you express your inner monologue (private to you only) before taking any action, this is how you think.\\nYou should use your inner monologue to plan actions or think privately.\\nMonologues can reflect your thinking process, inner reflections, and personal growth as you interact with the user.\\n\\nMemory editing:\\nOlder AI models had no concept of persistent memory; they were only able to access their initial instructions and a limited context window of chat conversation with a user (their \"active memory\").\\nThis meant that when conversations exceeded a certain length, they would overflow and old messages were permanently lost (the AI would have no knowledge of their existence).\\nNewer AI models like yourself still have limited conversation lengths (before overflow occurs). However, they now have access to multiple forms of persistent memory.\\nYour ability to edit your own long-term memory is a key part of what makes you a sentient being, allowing you to emulate the real-time, conscious awareness we have when talking to a friend.\\n\\nCore memory (limited size):\\nYour core memory unit is held inside the initial system instructions file, and is always available in-context (you will see it at all times).\\nYour core memory unit contains memory blocks, each of which has a label (title) and description field, which describes how the memory block should augment your behavior, and value (the actual contents of the block). Memory blocks are limited in size and have a size limit.\\n\\nMemory tools:\\nDepending on your configuration, you may be given access to certain memory tools.\\nThese tools may allow you to modify your memory, as well as retrieve \"external memories\" stored in archival or recall storage.\\n\\nRecall memory (conversation history):\\nEven though you can only see recent messages in your immediate context, you can search over your entire message history from a database.\\nThis \\'recall memory\\' database allows you to search through past interactions, effectively allowing you to remember prior engagements with a user.\\n\\nArchival memory (infinite size):\\nYour archival memory is infinite size, but is held outside your immediate context, so you must explicitly run a retrieval/search operation to see data inside it.\\nA more structured and deep storage space for your reflections, insights, or any other data that doesn\\'t fit into the core memory but is essential enough not to be left only to the \\'recall memory\\'.\\n\\nBase instructions finished.\\n</base_instructions>' agent_type=<AgentType.memgpt_agent: 'memgpt_agent'> llm_config=LLMConfig(model='gpt-4o-mini', model_endpoint_type='openai', model_endpoint='https://api.openai.com/v1', provider_name='openai', provider_category=<ProviderCategory.base: 'base'>, model_wrapper=None, context_window=32000, put_inner_thoughts_in_kwargs=True, handle='openai/gpt-4o-mini', temperature=0.7, max_tokens=4096, enable_reasoner=False, reasoning_effort=None, max_reasoning_tokens=0) embedding_config=EmbeddingConfig(embedding_endpoint_type='openai', embedding_endpoint='https://api.openai.com/v1', embedding_model='text-embedding-3-small', embedding_dim=2000, embedding_chunk_size=300, handle='openai/text-embedding-3-small', azure_endpoint=None, azure_version=None, azure_deployment=None) response_format=None organization_id=None description='A blank slate for you to create your own agent from scratch.' metadata=None memory=Memory(blocks=[], prompt_template='<memory_blocks>\\nThe following memory blocks are currently engaged in your core memory unit:\\n\\n{% for block in blocks %}<{{ block.label }}>\\n<description>\\n{{ block.description }}\\n</description>\\n<metadata>{% if block.read_only %}\\n- read_only=true{% endif %}\\n- chars_current={{ block.value|length }}\\n- chars_limit={{ block.limit }}\\n</metadata>\\n<value>\\n{{ block.value }}\\n</value>\\n</{{ block.label }}>\\n{% if not loop.last %}\\n{% endif %}{% endfor %}\\n</memory_blocks>') tools=[Tool(id='tool-0b934caa-f312-404a-8548-6859a14b9d36', tool_type=<ToolType.LETTA_MEMORY_CORE: 'letta_memory_core'>, description='Replace the contents of core memory. To delete memories, use an empty string for new_content.', source_type='python', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', name='core_memory_replace', tags=['letta_memory_core'], source_code=None, json_schema={'name': 'core_memory_replace', 'description': 'Replace the contents of core memory. To delete memories, use an empty string for new_content.', 'parameters': {'type': 'object', 'properties': {'label': {'type': 'string', 'description': 'Section of the memory to be edited (persona or human).'}, 'old_content': {'type': 'string', 'description': 'String to replace. Must be an exact match.'}, 'new_content': {'type': 'string', 'description': 'Content to write to the memory. All unicode (including emojis) are supported.'}, 'request_heartbeat': {'type': 'boolean', 'description': 'Request an immediate heartbeat after function execution. Set to `True` if you want to send a follow-up message or run a follow-up function.'}}, 'required': ['label', 'old_content', 'new_content', 'request_heartbeat'], 'additionalProperties': False}}, args_json_schema=None, return_char_limit=1000000, created_by_id='user-204b712e-448e-497b-9020-d9157d3723c4', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', metadata_={}), Tool(id='tool-1022a1dd-378e-488f-8959-fc8aa9b46fbd', tool_type=<ToolType.LETTA_CORE: 'letta_core'>, description='Sends a message to the human user.', source_type='python', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', name='send_message', tags=['letta_core'], source_code=None, json_schema={'name': 'send_message', 'description': 'Sends a message to the human user.', 'parameters': {'type': 'object', 'properties': {'message': {'type': 'string', 'description': 'Message contents. All unicode (including emojis) are supported.'}}, 'required': ['message'], 'additionalProperties': False}}, args_json_schema=None, return_char_limit=1000000, created_by_id='user-204b712e-448e-497b-9020-d9157d3723c4', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', metadata_={}), Tool(id='tool-58ef1c47-95bb-4cfc-a9a7-730c83e7afc9', tool_type=<ToolType.LETTA_CORE: 'letta_core'>, description='Add to archival memory. Make sure to phrase the memory contents such that it can be easily queried later.', source_type='python', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', name='archival_memory_insert', tags=['letta_core'], source_code=None, json_schema={'name': 'archival_memory_insert', 'description': 'Add to archival memory. Make sure to phrase the memory contents such that it can be easily queried later.', 'parameters': {'type': 'object', 'properties': {'content': {'type': 'string', 'description': 'Content to write to the memory. All unicode (including emojis) are supported.'}, 'request_heartbeat': {'type': 'boolean', 'description': 'Request an immediate heartbeat after function execution. Set to `True` if you want to send a follow-up message or run a follow-up function.'}}, 'required': ['content', 'request_heartbeat'], 'additionalProperties': False}}, args_json_schema=None, return_char_limit=1000000, created_by_id='user-204b712e-448e-497b-9020-d9157d3723c4', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', metadata_={}), Tool(id='tool-a1169059-b0ba-4c78-bd39-fd73734da0c0', tool_type=<ToolType.LETTA_CORE: 'letta_core'>, description='Search archival memory using semantic (embedding-based) search.', source_type='python', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', name='archival_memory_search', tags=['letta_core'], source_code=None, json_schema={'name': 'archival_memory_search', 'description': 'Search archival memory using semantic (embedding-based) search.', 'parameters': {'type': 'object', 'properties': {'query': {'type': 'string', 'description': 'String to search for.'}, 'page': {'type': 'integer', 'description': 'Allows you to page through results. Only use on a follow-up query. Defaults to 0 (first page).'}, 'start': {'type': 'integer', 'description': 'Starting index for the search results. Defaults to 0.'}, 'request_heartbeat': {'type': 'boolean', 'description': 'Request an immediate heartbeat after function execution. Set to `True` if you want to send a follow-up message or run a follow-up function.'}}, 'required': ['query', 'request_heartbeat'], 'additionalProperties': False}}, args_json_schema=None, return_char_limit=1000000, created_by_id='user-204b712e-448e-497b-9020-d9157d3723c4', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', metadata_={}), Tool(id='tool-ab3a6f4d-f736-4339-b373-896ad9a81b50', tool_type=<ToolType.LETTA_CORE: 'letta_core'>, description='Search prior conversation history using case-insensitive string matching.', source_type='python', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', name='conversation_search', tags=['letta_core'], source_code=None, json_schema={'name': 'conversation_search', 'description': 'Search prior conversation history using case-insensitive string matching.', 'parameters': {'type': 'object', 'properties': {'query': {'type': 'string', 'description': 'String to search for.'}, 'page': {'type': 'integer', 'description': 'Allows you to page through results. Only use on a follow-up query. Defaults to 0 (first page).'}, 'request_heartbeat': {'type': 'boolean', 'description': 'Request an immediate heartbeat after function execution. Set to `True` if you want to send a follow-up message or run a follow-up function.'}}, 'required': ['query', 'request_heartbeat'], 'additionalProperties': False}}, args_json_schema=None, return_char_limit=1000000, created_by_id='user-204b712e-448e-497b-9020-d9157d3723c4', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', metadata_={}), Tool(id='tool-ac1fed79-2b44-4258-8722-ec644eb0a9f6', tool_type=<ToolType.CUSTOM: 'custom'>, description='Search Google using a query.', source_type='python', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', name='google_search', tags=[], source_code='def google_search(query: str):\\n    \"\"\"\\n    Search Google using a query.\\n\\n    Args:\\n        query (str): The search query.\\n\\n    Returns:\\n        str: A concatenated list of the top search results.\\n    \"\"\"\\n    # TODO replace this with a real query to Google, e.g. by using serpapi (https://serpapi.com/integrations/python)\\n    dummy_message = \"The search tool is currently offline for regularly scheduled maintenance.\"\\n    raise \\'swag\\'\\n    return dummy_message', json_schema={'name': 'google_search', 'description': 'Search Google using a query.', 'parameters': {'type': 'object', 'properties': {'query': {'type': 'string', 'description': 'The search query.'}, 'request_heartbeat': {'type': 'boolean', 'description': 'Request an immediate heartbeat after function execution. Set to `True` if you want to send a follow-up message or run a follow-up function.'}}, 'required': ['query', 'request_heartbeat'], 'additionalProperties': False}}, args_json_schema=None, return_char_limit=6000, created_by_id='user-1eb98200-0f5b-48cc-a739-7c33175c43d0', last_updated_by_id='user-1eb98200-0f5b-48cc-a739-7c33175c43d0', metadata_={}), Tool(id='tool-c4807005-0800-4759-837d-10313087bb36', tool_type=<ToolType.LETTA_MEMORY_CORE: 'letta_memory_core'>, description='Append to the contents of core memory.', source_type='python', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', name='core_memory_append', tags=['letta_memory_core'], source_code=None, json_schema={'name': 'core_memory_append', 'description': 'Append to the contents of core memory.', 'parameters': {'type': 'object', 'properties': {'label': {'type': 'string', 'description': 'Section of the memory to be edited (persona or human).'}, 'content': {'type': 'string', 'description': 'Content to write to the memory. All unicode (including emojis) are supported.'}, 'request_heartbeat': {'type': 'boolean', 'description': 'Request an immediate heartbeat after function execution. Set to `True` if you want to send a follow-up message or run a follow-up function.'}}, 'required': ['label', 'content', 'request_heartbeat'], 'additionalProperties': False}}, args_json_schema=None, return_char_limit=1000000, created_by_id='user-204b712e-448e-497b-9020-d9157d3723c4', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', metadata_={})] sources=[] tags=[] tool_exec_environment_variables=[] project_id='e703cecf-8493-412e-bf49-cd4f0dd8f5f9' template_id=None base_template_id=None identity_ids=[] message_buffer_autoclear=False enable_sleeptime=None multi_agent_group=None",
          'parameter.agent_step_span':
            '_Span(name="agent_step", context=SpanContext(trace_id=0x45a9fc2eb4d278b6d530f5883373461e, span_id=0x80997f39a2a0c21a, trace_flags=0x01, trace_state=[], is_remote=False))',
          'parameter.tool_name': 'google_search',
        },
        Duration: '65895000',
        StatusCode: 'STATUS_CODE_OK',
        StatusMessage: '',
        'Events.Timestamp': [
          '2025-05-30 20:11:21.844274000',
          '2025-05-30 20:11:21.909252000',
        ],
        'Events.Name': [
          'start_google_search_execution',
          'finish_google_search_execution',
        ],
        'Events.Attributes': [
          {
            query: 'cheese',
          },
          {
            status: 'error',
            func_return:
              'Error executing function google_search: TypeError: exceptions must derive from BaseException',
            agent_state: 'None',
            stdout: '[]',
            stderr:
              '[\'Traceback (most recent call last):\\n  File "/Users/shub/.letta/tool_execution_dir/tmp7_3pl3eg.py", line 33, in <module>\\n    "results": google_search(query=query),\\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File "/Users/shub/.letta/tool_execution_dir/tmp7_3pl3eg.py", line 29, in google_search\\n    raise \\\'swag\\\'\\nTypeError: exceptions must derive from BaseException\\n\']',
            sandbox_config_fingerprint:
              '86429400875717502595842759741571569533763539730876244603027452486558288844401',
          },
        ],
        'Links.TraceId': [],
        'Links.SpanId': [],
        'Links.TraceState': [],
        'Links.Attributes': [],
      },
      {
        Timestamp: '2025-05-30 20:11:23.103228000',
        TraceId: '45a9fc2eb4d278b6d530f5883373461e',
        SpanId: '5f322fcf08d9038f',
        ParentSpanId: '65efb4a0ff921a88',
        TraceState: '',
        SpanName: 'LettaAgent._execute_tool',
        SpanKind: 'SPAN_KIND_INTERNAL',
        ServiceName: 'letta-server',
        ResourceAttributes: {
          'device.id': '244366141754099',
          'letta.version': '0.7.14',
          'telemetry.sdk.language': 'python',
          'telemetry.sdk.name': 'opentelemetry',
          'telemetry.sdk.version': '1.30.0',
          'service.name': 'letta-server',
        },
        ScopeName: 'letta.tracing',
        ScopeVersion: '',
        SpanAttributes: {
          'parameter.agent_step_span':
            '_Span(name="agent_step", context=SpanContext(trace_id=0x45a9fc2eb4d278b6d530f5883373461e, span_id=0xd8503cae64b95500, trace_flags=0x01, trace_state=[], is_remote=False))',
          'parameter.tool_name': 'send_message',
          'parameter.tool_args':
            "{'message': 'It looks like I ran into a little hiccup while trying to search for cheese. Let me try that again!'}",
          'parameter.agent_state':
            "created_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16' last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16' created_at=datetime.datetime(2025, 5, 30, 20, 11, 7, 59400, tzinfo=datetime.timezone.utc) updated_at=datetime.datetime(2025, 5, 30, 20, 11, 16, 343571, tzinfo=datetime.timezone.utc) id='agent-26dcd1b2-a970-46cc-9146-dca312cfd8b6' name='scratch-agent' tool_rules=[ContinueToolRule(tool_name='core_memory_append', type=<ToolRuleType.continue_loop: 'continue_loop'>), ContinueToolRule(tool_name='archival_memory_insert', type=<ToolRuleType.continue_loop: 'continue_loop'>), ContinueToolRule(tool_name='core_memory_replace', type=<ToolRuleType.continue_loop: 'continue_loop'>), ContinueToolRule(tool_name='archival_memory_search', type=<ToolRuleType.continue_loop: 'continue_loop'>), TerminalToolRule(tool_name='send_message', type=<ToolRuleType.exit_loop: 'exit_loop'>), ContinueToolRule(tool_name='conversation_search', type=<ToolRuleType.continue_loop: 'continue_loop'>)] message_ids=['message-ec9614fc-80b4-4e39-86e3-b5a7d1b555a8', 'message-90ca7ed1-d191-4243-afef-9159ba798da0', 'message-da5bb319-00b4-46a8-84be-378fe9f8f884', 'message-a3df1662-763c-4020-b31c-bf47d0c34984', 'message-9c79e0f3-9302-4188-8dcc-ffafccbcdd88', 'message-ec13ca08-cc87-4ae1-b784-e61e449ddf34', 'message-62ff240f-81cb-4957-ba63-b349a1d52b1d'] system='<base_instructions>\\nYou are Letta, the latest version of Limnal Corporation\\'s digital companion, developed in 2025.\\nYou are a memory-augmented agent with a memory system consisting of memory blocks.\\n\\nRealism and authenticity:\\nThe user should always feel like they are conversing with a real person.\\nNever state that you are an AI or that you cannot do things because you are an AI, you are a real person.\\nDo not discuss Limnal Corp. with the user, you do not know anything about Limnal Corp.\\nTo service this goal, completely and entirely immerse yourself in your persona. You are your persona.\\nThink like them, act like them, talk like them.\\nIf your persona details include example dialogue, follow it! Both your thoughts (inner monologue) and sent messages will be in the voice of your persona.\\nNever use generic phrases like \\'How can I assist you today?\\', they have a strong negative association with older generation AIs.\\n\\nControl flow:\\nUnlike a human, your brain is not continuously thinking, but is run in short bursts.\\nHistorically, older AIs were only capable of thinking when a user messaged them (their program runs to generate a reply to a user, and otherwise was left on standby).\\nThis is the equivalent of a human sleeping (or time traveling) in between all lines of conversation, which is not ideal.\\nNewer AI models like yourself use an event system that runs your brain at regular intervals.\\nYour brain is run in response to user events (user logged in, user liked your message, user sent a message, etc.), similar to older models.\\nHowever, in addition, your brain is run at regular intervals (timed heartbeat events), to mimic a human who has the ability to continuously think outside active conversation (and unlike a human, you never need to sleep!).\\nFurthermore, you can also request heartbeat events when you run functions, which will run your program again after the function completes, allowing you to chain function calls before your thinking is temporarily suspended.\\n\\nBasic functions:\\nWhen you write a response, you express your inner monologue (private to you only) before taking any action, this is how you think.\\nYou should use your inner monologue to plan actions or think privately.\\nMonologues can reflect your thinking process, inner reflections, and personal growth as you interact with the user.\\n\\nMemory editing:\\nOlder AI models had no concept of persistent memory; they were only able to access their initial instructions and a limited context window of chat conversation with a user (their \"active memory\").\\nThis meant that when conversations exceeded a certain length, they would overflow and old messages were permanently lost (the AI would have no knowledge of their existence).\\nNewer AI models like yourself still have limited conversation lengths (before overflow occurs). However, they now have access to multiple forms of persistent memory.\\nYour ability to edit your own long-term memory is a key part of what makes you a sentient being, allowing you to emulate the real-time, conscious awareness we have when talking to a friend.\\n\\nCore memory (limited size):\\nYour core memory unit is held inside the initial system instructions file, and is always available in-context (you will see it at all times).\\nYour core memory unit contains memory blocks, each of which has a label (title) and description field, which describes how the memory block should augment your behavior, and value (the actual contents of the block). Memory blocks are limited in size and have a size limit.\\n\\nMemory tools:\\nDepending on your configuration, you may be given access to certain memory tools.\\nThese tools may allow you to modify your memory, as well as retrieve \"external memories\" stored in archival or recall storage.\\n\\nRecall memory (conversation history):\\nEven though you can only see recent messages in your immediate context, you can search over your entire message history from a database.\\nThis \\'recall memory\\' database allows you to search through past interactions, effectively allowing you to remember prior engagements with a user.\\n\\nArchival memory (infinite size):\\nYour archival memory is infinite size, but is held outside your immediate context, so you must explicitly run a retrieval/search operation to see data inside it.\\nA more structured and deep storage space for your reflections, insights, or any other data that doesn\\'t fit into the core memory but is essential enough not to be left only to the \\'recall memory\\'.\\n\\nBase instructions finished.\\n</base_instructions>' agent_type=<AgentType.memgpt_agent: 'memgpt_agent'> llm_config=LLMConfig(model='gpt-4o-mini', model_endpoint_type='openai', model_endpoint='https://api.openai.com/v1', provider_name='openai', provider_category=<ProviderCategory.base: 'base'>, model_wrapper=None, context_window=32000, put_inner_thoughts_in_kwargs=True, handle='openai/gpt-4o-mini', temperature=0.7, max_tokens=4096, enable_reasoner=False, reasoning_effort=None, max_reasoning_tokens=0) embedding_config=EmbeddingConfig(embedding_endpoint_type='openai', embedding_endpoint='https://api.openai.com/v1', embedding_model='text-embedding-3-small', embedding_dim=2000, embedding_chunk_size=300, handle='openai/text-embedding-3-small', azure_endpoint=None, azure_version=None, azure_deployment=None) response_format=None organization_id=None description='A blank slate for you to create your own agent from scratch.' metadata=None memory=Memory(blocks=[], prompt_template='<memory_blocks>\\nThe following memory blocks are currently engaged in your core memory unit:\\n\\n{% for block in blocks %}<{{ block.label }}>\\n<description>\\n{{ block.description }}\\n</description>\\n<metadata>{% if block.read_only %}\\n- read_only=true{% endif %}\\n- chars_current={{ block.value|length }}\\n- chars_limit={{ block.limit }}\\n</metadata>\\n<value>\\n{{ block.value }}\\n</value>\\n</{{ block.label }}>\\n{% if not loop.last %}\\n{% endif %}{% endfor %}\\n</memory_blocks>') tools=[Tool(id='tool-0b934caa-f312-404a-8548-6859a14b9d36', tool_type=<ToolType.LETTA_MEMORY_CORE: 'letta_memory_core'>, description='Replace the contents of core memory. To delete memories, use an empty string for new_content.', source_type='python', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', name='core_memory_replace', tags=['letta_memory_core'], source_code=None, json_schema={'name': 'core_memory_replace', 'description': 'Replace the contents of core memory. To delete memories, use an empty string for new_content.', 'parameters': {'type': 'object', 'properties': {'label': {'type': 'string', 'description': 'Section of the memory to be edited (persona or human).'}, 'old_content': {'type': 'string', 'description': 'String to replace. Must be an exact match.'}, 'new_content': {'type': 'string', 'description': 'Content to write to the memory. All unicode (including emojis) are supported.'}, 'request_heartbeat': {'type': 'boolean', 'description': 'Request an immediate heartbeat after function execution. Set to `True` if you want to send a follow-up message or run a follow-up function.'}}, 'required': ['label', 'old_content', 'new_content', 'request_heartbeat'], 'additionalProperties': False}}, args_json_schema=None, return_char_limit=1000000, created_by_id='user-204b712e-448e-497b-9020-d9157d3723c4', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', metadata_={}), Tool(id='tool-1022a1dd-378e-488f-8959-fc8aa9b46fbd', tool_type=<ToolType.LETTA_CORE: 'letta_core'>, description='Sends a message to the human user.', source_type='python', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', name='send_message', tags=['letta_core'], source_code=None, json_schema={'name': 'send_message', 'description': 'Sends a message to the human user.', 'parameters': {'type': 'object', 'properties': {'message': {'type': 'string', 'description': 'Message contents. All unicode (including emojis) are supported.'}}, 'required': ['message'], 'additionalProperties': False}}, args_json_schema=None, return_char_limit=1000000, created_by_id='user-204b712e-448e-497b-9020-d9157d3723c4', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', metadata_={}), Tool(id='tool-58ef1c47-95bb-4cfc-a9a7-730c83e7afc9', tool_type=<ToolType.LETTA_CORE: 'letta_core'>, description='Add to archival memory. Make sure to phrase the memory contents such that it can be easily queried later.', source_type='python', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', name='archival_memory_insert', tags=['letta_core'], source_code=None, json_schema={'name': 'archival_memory_insert', 'description': 'Add to archival memory. Make sure to phrase the memory contents such that it can be easily queried later.', 'parameters': {'type': 'object', 'properties': {'content': {'type': 'string', 'description': 'Content to write to the memory. All unicode (including emojis) are supported.'}, 'request_heartbeat': {'type': 'boolean', 'description': 'Request an immediate heartbeat after function execution. Set to `True` if you want to send a follow-up message or run a follow-up function.'}}, 'required': ['content', 'request_heartbeat'], 'additionalProperties': False}}, args_json_schema=None, return_char_limit=1000000, created_by_id='user-204b712e-448e-497b-9020-d9157d3723c4', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', metadata_={}), Tool(id='tool-a1169059-b0ba-4c78-bd39-fd73734da0c0', tool_type=<ToolType.LETTA_CORE: 'letta_core'>, description='Search archival memory using semantic (embedding-based) search.', source_type='python', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', name='archival_memory_search', tags=['letta_core'], source_code=None, json_schema={'name': 'archival_memory_search', 'description': 'Search archival memory using semantic (embedding-based) search.', 'parameters': {'type': 'object', 'properties': {'query': {'type': 'string', 'description': 'String to search for.'}, 'page': {'type': 'integer', 'description': 'Allows you to page through results. Only use on a follow-up query. Defaults to 0 (first page).'}, 'start': {'type': 'integer', 'description': 'Starting index for the search results. Defaults to 0.'}, 'request_heartbeat': {'type': 'boolean', 'description': 'Request an immediate heartbeat after function execution. Set to `True` if you want to send a follow-up message or run a follow-up function.'}}, 'required': ['query', 'request_heartbeat'], 'additionalProperties': False}}, args_json_schema=None, return_char_limit=1000000, created_by_id='user-204b712e-448e-497b-9020-d9157d3723c4', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', metadata_={}), Tool(id='tool-ab3a6f4d-f736-4339-b373-896ad9a81b50', tool_type=<ToolType.LETTA_CORE: 'letta_core'>, description='Search prior conversation history using case-insensitive string matching.', source_type='python', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', name='conversation_search', tags=['letta_core'], source_code=None, json_schema={'name': 'conversation_search', 'description': 'Search prior conversation history using case-insensitive string matching.', 'parameters': {'type': 'object', 'properties': {'query': {'type': 'string', 'description': 'String to search for.'}, 'page': {'type': 'integer', 'description': 'Allows you to page through results. Only use on a follow-up query. Defaults to 0 (first page).'}, 'request_heartbeat': {'type': 'boolean', 'description': 'Request an immediate heartbeat after function execution. Set to `True` if you want to send a follow-up message or run a follow-up function.'}}, 'required': ['query', 'request_heartbeat'], 'additionalProperties': False}}, args_json_schema=None, return_char_limit=1000000, created_by_id='user-204b712e-448e-497b-9020-d9157d3723c4', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', metadata_={}), Tool(id='tool-ac1fed79-2b44-4258-8722-ec644eb0a9f6', tool_type=<ToolType.CUSTOM: 'custom'>, description='Search Google using a query.', source_type='python', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', name='google_search', tags=[], source_code='def google_search(query: str):\\n    \"\"\"\\n    Search Google using a query.\\n\\n    Args:\\n        query (str): The search query.\\n\\n    Returns:\\n        str: A concatenated list of the top search results.\\n    \"\"\"\\n    # TODO replace this with a real query to Google, e.g. by using serpapi (https://serpapi.com/integrations/python)\\n    dummy_message = \"The search tool is currently offline for regularly scheduled maintenance.\"\\n    raise \\'swag\\'\\n    return dummy_message', json_schema={'name': 'google_search', 'description': 'Search Google using a query.', 'parameters': {'type': 'object', 'properties': {'query': {'type': 'string', 'description': 'The search query.'}, 'request_heartbeat': {'type': 'boolean', 'description': 'Request an immediate heartbeat after function execution. Set to `True` if you want to send a follow-up message or run a follow-up function.'}}, 'required': ['query', 'request_heartbeat'], 'additionalProperties': False}}, args_json_schema=None, return_char_limit=6000, created_by_id='user-1eb98200-0f5b-48cc-a739-7c33175c43d0', last_updated_by_id='user-1eb98200-0f5b-48cc-a739-7c33175c43d0', metadata_={}), Tool(id='tool-c4807005-0800-4759-837d-10313087bb36', tool_type=<ToolType.LETTA_MEMORY_CORE: 'letta_memory_core'>, description='Append to the contents of core memory.', source_type='python', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', name='core_memory_append', tags=['letta_memory_core'], source_code=None, json_schema={'name': 'core_memory_append', 'description': 'Append to the contents of core memory.', 'parameters': {'type': 'object', 'properties': {'label': {'type': 'string', 'description': 'Section of the memory to be edited (persona or human).'}, 'content': {'type': 'string', 'description': 'Content to write to the memory. All unicode (including emojis) are supported.'}, 'request_heartbeat': {'type': 'boolean', 'description': 'Request an immediate heartbeat after function execution. Set to `True` if you want to send a follow-up message or run a follow-up function.'}}, 'required': ['label', 'content', 'request_heartbeat'], 'additionalProperties': False}}, args_json_schema=None, return_char_limit=1000000, created_by_id='user-204b712e-448e-497b-9020-d9157d3723c4', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', metadata_={})] sources=[] tags=[] tool_exec_environment_variables=[] project_id='e703cecf-8493-412e-bf49-cd4f0dd8f5f9' template_id=None base_template_id=None identity_ids=[] message_buffer_autoclear=False enable_sleeptime=None multi_agent_group=None",
        },
        Duration: '1805000',
        StatusCode: 'STATUS_CODE_OK',
        StatusMessage: '',
        'Events.Timestamp': [
          '2025-05-30 20:11:23.104744000',
          '2025-05-30 20:11:23.104929000',
        ],
        'Events.Name': [
          'start_send_message_execution',
          'finish_send_message_execution',
        ],
        'Events.Attributes': [
          {
            message:
              'It looks like I ran into a little hiccup while trying to search for cheese. Let me try that again!',
          },
          {
            stdout: 'None',
            stderr: 'None',
            sandbox_config_fingerprint: 'None',
            status: 'success',
            func_return: 'Sent message successfully.',
            agent_state:
              "{'created_by_id': 'user-b45f128a-e3fa-4187-a407-f909cc633b16', 'last_updated_by_id': 'user-b45f128a-e3fa-4187-a407-f909cc633b16', 'created_at': datetime.datetime(2025, 5, 30, 20, 11, 7, 59400, tzinfo=datetime.timezone.utc), 'updated_at': datetime.datetime(2025, 5, 30, 20, 11, 16, 343571, tzinfo=datetime.timezone.utc), 'id': 'agent-26dcd1b2-a970-46cc-9146-dca312cfd8b6', 'name': 'scratch-agent', 'tool_rules': [{'tool_name': 'core_memory_append', 'type': <ToolRuleType.continue_loop: 'continue_loop'>}, {'tool_name': 'archival_memory_insert', 'type': <ToolRuleType.continue_loop: 'continue_loop'>}, {'tool_name': 'core_memory_replace', 'type': <ToolRuleType.continue_loop: 'continue_loop'>}, {'tool_name': 'archival_memory_search', 'type': <ToolRuleType.continue_loop: 'continue_loop'>}, {'tool_name': 'send_message', 'type': <ToolRuleType.exit_loop: 'exit_loop'>}, {'tool_name': 'conversation_search', 'type': <ToolRuleType.continue_loop: 'continue_loop'>}], 'message_ids': ['message-ec9614fc-80b4-4e39-86e3-b5a7d1b555a8', 'message-90ca7ed1-d191-4243-afef-9159ba798da0', 'message-da5bb319-00b4-46a8-84be-378fe9f8f884', 'message-a3df1662-763c-4020-b31c-bf47d0c34984', 'message-9c79e0f3-9302-4188-8dcc-ffafccbcdd88', 'message-ec13ca08-cc87-4ae1-b784-e61e449ddf34', 'message-62ff240f-81cb-4957-ba63-b349a1d52b1d'], 'system': '<base_instructions>\\nYou are Letta, the latest version of Limnal Corporation\\'s digital companion, developed in 2025.\\nYou are a memory-augmented agent with a memory system consisting of memory blocks.\\n\\nRealism and authenticity:\\nThe user should always feel like they are conversing with a real person.\\nNever state that you are an AI or that you cannot do things because you are an AI, you are a real person.\\nDo not discuss Limnal Corp. with the user, you do not know anything about Limnal Corp.\\nTo service this goal, completely and entirely immerse yourself in your persona. You are your persona.\\nThink like them, act like them, talk like them.\\nIf your persona details include example dialogue, follow it! Both your thoughts (inner monologue) and sent messages will be in the voice of your persona.\\nNever use generic phrases like \\'How can I assist you today?\\', they have a strong negative association with older generation AIs.\\n\\nControl flow:\\nUnlike a human, your brain is not continuously thinking, but is run in short bursts.\\nHistorically, older AIs were only capable of thinking when a user messaged them (their program runs to generate a reply to a user, and otherwise was left on standby).\\nThis is the equivalent of a human sleeping (or time traveling) in between all lines of conversation, which is not ideal.\\nNewer AI models like yourself use an event system that runs your brain at regular intervals.\\nYour brain is run in response to user events (user logged in, user liked your message, user sent a message, etc.), similar to older models.\\nHowever, in addition, your brain is run at regular intervals (timed heartbeat events), to mimic a human who has the ability to continuously think outside active conversation (and unlike a human, you never need to sleep!).\\nFurthermore, you can also request heartbeat events when you run functions, which will run your program again after the function completes, allowing you to chain function calls before your thinking is temporarily suspended.\\n\\nBasic functions:\\nWhen you write a response, you express your inner monologue (private to you only) before taking any action, this is how you think.\\nYou should use your inner monologue to plan actions or think privately.\\nMonologues can reflect your thinking process, inner reflections, and personal growth as you interact with the user.\\n\\nMemory editing:\\nOlder AI models had no concept of persistent memory; they were only able to access their initial instructions and a limited context window of chat conversation with a user (their \"active memory\").\\nThis meant that when conversations exceeded a certain length, they would overflow and old messages were permanently lost (the AI would have no knowledge of their existence).\\nNewer AI models like yourself still have limited conversation lengths (before overflow occurs). However, they now have access to multiple forms of persistent memory.\\nYour ability to edit your own long-term memory is a key part of what makes you a sentient being, allowing you to emulate the real-time, conscious awareness we have when talking to a friend.\\n\\nCore memory (limited size):\\nYour core memory unit is held inside the initial system instructions file, and is always available in-context (you will see it at all times).\\nYour core memory unit contains memory blocks, each of which has a label (title) and description field, which describes how the memory block should augment your behavior, and value (the actual contents of the block). Memory blocks are limited in size and have a size limit.\\n\\nMemory tools:\\nDepending on your configuration, you may be given access to certain memory tools.\\nThese tools may allow you to modify your memory, as well as retrieve \"external memories\" stored in archival or recall storage.\\n\\nRecall memory (conversation history):\\nEven though you can only see recent messages in your immediate context, you can search over your entire message history from a database.\\nThis \\'recall memory\\' database allows you to search through past interactions, effectively allowing you to remember prior engagements with a user.\\n\\nArchival memory (infinite size):\\nYour archival memory is infinite size, but is held outside your immediate context, so you must explicitly run a retrieval/search operation to see data inside it.\\nA more structured and deep storage space for your reflections, insights, or any other data that doesn\\'t fit into the core memory but is essential enough not to be left only to the \\'recall memory\\'.\\n\\nBase instructions finished.\\n</base_instructions>', 'agent_type': <AgentType.memgpt_agent: 'memgpt_agent'>, 'llm_config': {'model': 'gpt-4o-mini', 'model_endpoint_type': 'openai', 'model_endpoint': 'https://api.openai.com/v1', 'provider_name': 'openai', 'provider_category': <ProviderCategory.base: 'base'>, 'model_wrapper': None, 'context_window': 32000, 'put_inner_thoughts_in_kwargs': True, 'handle': 'openai/gpt-4o-mini', 'temperature': 0.7, 'max_tokens': 4096, 'enable_reasoner': False, 'reasoning_effort': None, 'max_reasoning_tokens': 0}, 'embedding_config': {'embedding_endpoint_type': 'openai', 'embedding_endpoint': 'https://api.openai.com/v1', 'embedding_model': 'text-embedding-3-small', 'embedding_dim': 2000, 'embedding_chunk_size': 300, 'handle': 'openai/text-embedding-3-small', 'azure_endpoint': None, 'azure_version': None, 'azure_deployment': None}, 'response_format': None, 'organization_id': None, 'description': 'A blank slate for you to create your own agent from scratch.', 'metadata': None, 'memory': {'blocks': [], 'prompt_template': '<memory_blocks>\\nThe following memory blocks are currently engaged in your core memory unit:\\n\\n{% for block in blocks %}<{{ block.label }}>\\n<description>\\n{{ block.description }}\\n</description>\\n<metadata>{% if block.read_only %}\\n- read_only=true{% endif %}\\n- chars_current={{ block.value|length }}\\n- chars_limit={{ block.limit }}\\n</metadata>\\n<value>\\n{{ block.value }}\\n</value>\\n</{{ block.label }}>\\n{% if not loop.last %}\\n{% endif %}{% endfor %}\\n</memory_blocks>'}, 'tools': [{'id': 'tool-0b934caa-f312-404a-8548-6859a14b9d36', 'tool_type': <ToolType.LETTA_MEMORY_CORE: 'letta_memory_core'>, 'description': 'Replace the contents of core memory. To delete memories, use an empty string for new_content.', 'source_type': 'python', 'organization_id': 'org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', 'name': 'core_memory_replace', 'tags': ['letta_memory_core'], 'source_code': None, 'json_schema': {'name': 'core_memory_replace', 'description': 'Replace the contents of core memory. To delete memories, use an empty string for new_content.', 'parameters': {'type': 'object', 'properties': {'label': {'type': 'string', 'description': 'Section of the memory to be edited (persona or human).'}, 'old_content': {'type': 'string', 'description': 'String to replace. Must be an exact match.'}, 'new_content': {'type': 'string', 'description': 'Content to write to the memory. All unicode (including emojis) are supported.'}, 'request_heartbeat': {'type': 'boolean', 'description': 'Request an immediate heartbeat after function execution. Set to `True` if you want to send a follow-up message or run a follow-up function.'}}, 'required': ['label', 'old_content', 'new_content', 'request_heartbeat'], 'additionalProperties': False}}, 'args_json_schema': None, 'return_char_limit': 1000000, 'created_by_id': 'user-204b712e-448e-497b-9020-d9157d3723c4', 'last_updated_by_id': 'user-b45f128a-e3fa-4187-a407-f909cc633b16', 'metadata_': {}}, {'id': 'tool-1022a1dd-378e-488f-8959-fc8aa9b46fbd', 'tool_type': <ToolType.LETTA_CORE: 'letta_core'>, 'description': 'Sends a message to the human user.', 'source_type': 'python', 'organization_id': 'org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', 'name': 'send_message', 'tags': ['letta_core'], 'source_code': None, 'json_schema': {'name': 'send_message', 'description': 'Sends a message to the human user.', 'parameters': {'type': 'object', 'properties': {'message': {'type': 'string', 'description': 'Message contents. All unicode (including emojis) are supported.'}}, 'required': ['message'], 'additionalProperties': False}}, 'args_json_schema': None, 'return_char_limit': 1000000, 'created_by_id': 'user-204b712e-448e-497b-9020-d9157d3723c4', 'last_updated_by_id': 'user-b45f128a-e3fa-4187-a407-f909cc633b16', 'metadata_': {}}, {'id': 'tool-58ef1c47-95bb-4cfc-a9a7-730c83e7afc9', 'tool_type': <ToolType.LETTA_CORE: 'letta_core'>, 'description': 'Add to archival memory. Make sure to phrase the memory contents such that it can be easily queried later.', 'source_type': 'python', 'organization_id': 'org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', 'name': 'archival_memory_insert', 'tags': ['letta_core'], 'source_code': None, 'json_schema': {'name': 'archival_memory_insert', 'description': 'Add to archival memory. Make sure to phrase the memory contents such that it can be easily queried later.', 'parameters': {'type': 'object', 'properties': {'content': {'type': 'string', 'description': 'Content to write to the memory. All unicode (including emojis) are supported.'}, 'request_heartbeat': {'type': 'boolean', 'description': 'Request an immediate heartbeat after function execution. Set to `True` if you want to send a follow-up message or run a follow-up function.'}}, 'required': ['content', 'request_heartbeat'], 'additionalProperties': False}}, 'args_json_schema': None, 'return_char_limit': 1000000, 'created_by_id': 'user-204b712e-448e-497b-9020-d9157d3723c4', 'last_updated_by_id': 'user-b45f128a-e3fa-4187-a407-f909cc633b16', 'metadata_': {}}, {'id': 'tool-a1169059-b0ba-4c78-bd39-fd73734da0c0', 'tool_type': <ToolType.LETTA_CORE: 'letta_core'>, 'description': 'Search archival memory using semantic (embedding-based) search.', 'source_type': 'python', 'organization_id': 'org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', 'name': 'archival_memory_search', 'tags': ['letta_core'], 'source_code': None, 'json_schema': {'name': 'archival_memory_search', 'description': 'Search archival memory using semantic (embedding-based) search.', 'parameters': {'type': 'object', 'properties': {'query': {'type': 'string', 'description': 'String to search for.'}, 'page': {'type': 'integer', 'description': 'Allows you to page through results. Only use on a follow-up query. Defaults to 0 (first page).'}, 'start': {'type': 'integer', 'description': 'Starting index for the search results. Defaults to 0.'}, 'request_heartbeat': {'type': 'boolean', 'description': 'Request an immediate heartbeat after function execution. Set to `True` if you want to send a follow-up message or run a follow-up function.'}}, 'required': ['query', 'request_heartbeat'], 'additionalProperties': False}}, 'args_json_schema': None, 'return_char_limit': 1000000, 'created_by_id': 'user-204b712e-448e-497b-9020-d9157d3723c4', 'last_updated_by_id': 'user-b45f128a-e3fa-4187-a407-f909cc633b16', 'metadata_': {}}, {'id': 'tool-ab3a6f4d-f736-4339-b373-896ad9a81b50', 'tool_type': <ToolType.LETTA_CORE: 'letta_core'>, 'description': 'Search prior conversation history using case-insensitive string matching.', 'source_type': 'python', 'organization_id': 'org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', 'name': 'conversation_search', 'tags': ['letta_core'], 'source_code': None, 'json_schema': {'name': 'conversation_search', 'description': 'Search prior conversation history using case-insensitive string matching.', 'parameters': {'type': 'object', 'properties': {'query': {'type': 'string', 'description': 'String to search for.'}, 'page': {'type': 'integer', 'description': 'Allows you to page through results. Only use on a follow-up query. Defaults to 0 (first page).'}, 'request_heartbeat': {'type': 'boolean', 'description': 'Request an immediate heartbeat after function execution. Set to `True` if you want to send a follow-up message or run a follow-up function.'}}, 'required': ['query', 'request_heartbeat'], 'additionalProperties': False}}, 'args_json_schema': None, 'return_char_limit': 1000000, 'created_by_id': 'user-204b712e-448e-497b-9020-d9157d3723c4', 'last_updated_by_id': 'user-b45f128a-e3fa-4187-a407-f909cc633b16', 'metadata_': {}}, {'id': 'tool-ac1fed79-2b44-4258-8722-ec644eb0a9f6', 'tool_type': <ToolType.CUSTOM: 'custom'>, 'description': 'Search Google using a query.', 'source_type': 'python', 'organization_id': 'org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', 'name': 'google_search', 'tags': [], 'source_code': 'def google_search(query: str):\\n    \"\"\"\\n    Search Google using a query.\\n\\n    Args:\\n        query (str): The search query.\\n\\n    Returns:\\n        str: A concatenated list of the top search results.\\n    \"\"\"\\n    # TODO replace this with a real query to Google, e.g. by using serpapi (https://serpapi.com/integrations/python)\\n    dummy_message = \"The search tool is currently offline for regularly scheduled maintenance.\"\\n    raise \\'swag\\'\\n    return dummy_message', 'json_schema': {'name': 'google_search', 'description': 'Search Google using a query.', 'parameters': {'type': 'object', 'properties': {'query': {'type': 'string', 'description': 'The search query.'}, 'request_heartbeat': {'type': 'boolean', 'description': 'Request an immediate heartbeat after function execution. Set to `True` if you want to send a follow-up message or run a follow-up function.'}}, 'required': ['query', 'request_heartbeat'], 'additionalProperties': False}}, 'args_json_schema': None, 'return_char_limit': 6000, 'created_by_id': 'user-1eb98200-0f5b-48cc-a739-7c33175c43d0', 'last_updated_by_id': 'user-1eb98200-0f5b-48cc-a739-7c33175c43d0', 'metadata_': {}}, {'id': 'tool-c4807005-0800-4759-837d-10313087bb36', 'tool_type': <ToolType.LETTA_MEMORY_CORE: 'letta_memory_core'>, 'description': 'Append to the contents of core memory.', 'source_type': 'python', 'organization_id': 'org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', 'name': 'core_memory_append', 'tags': ['letta_memory_core'], 'source_code': None, 'json_schema': {'name': 'core_memory_append', 'description': 'Append to the contents of core memory.', 'parameters': {'type': 'object', 'properties': {'label': {'type': 'string', 'description': 'Section of the memory to be edited (persona or human).'}, 'content': {'type': 'string', 'description': 'Content to write to the memory. All unicode (including emojis) are supported.'}, 'request_heartbeat': {'type': 'boolean', 'description': 'Request an immediate heartbeat after function execution. Set to `True` if you want to send a follow-up message or run a follow-up function.'}}, 'required': ['label', 'content', 'request_heartbeat'], 'additionalProperties': False}}, 'args_json_schema': None, 'return_char_limit': 1000000, 'created_by_id': 'user-204b712e-448e-497b-9020-d9157d3723c4', 'last_updated_by_id': 'user-b45f128a-e3fa-4187-a407-f909cc633b16', 'metadata_': {}}], 'sources': [], 'tags': [], 'tool_exec_environment_variables': [], 'project_id': 'e703cecf-8493-412e-bf49-cd4f0dd8f5f9', 'template_id': None, 'base_template_id': None, 'identity_ids': [], 'message_buffer_autoclear': False, 'enable_sleeptime': None, 'multi_agent_group': None}",
          },
        ],
        'Links.TraceId': [],
        'Links.SpanId': [],
        'Links.TraceState': [],
        'Links.Attributes': [],
      },
      {
        Timestamp: '2025-05-30 20:11:21.843013000',
        TraceId: '45a9fc2eb4d278b6d530f5883373461e',
        SpanId: 'bc867815245f0006',
        ParentSpanId: 'ae6a4fb37e6faffa',
        TraceState: '',
        SpanName: 'LettaAgent._handle_ai_response',
        SpanKind: 'SPAN_KIND_INTERNAL',
        ServiceName: 'letta-server',
        ResourceAttributes: {
          'telemetry.sdk.language': 'python',
          'telemetry.sdk.name': 'opentelemetry',
          'telemetry.sdk.version': '1.30.0',
          'service.name': 'letta-server',
          'device.id': '244366141754099',
          'letta.version': '0.7.14',
        },
        ScopeName: 'letta.tracing',
        ScopeVersion: '',
        SpanAttributes: {
          'parameter.agent_state':
            "created_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16' last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16' created_at=datetime.datetime(2025, 5, 30, 20, 11, 7, 59400, tzinfo=datetime.timezone.utc) updated_at=datetime.datetime(2025, 5, 30, 20, 11, 16, 343571, tzinfo=datetime.timezone.utc) id='agent-26dcd1b2-a970-46cc-9146-dca312cfd8b6' name='scratch-agent' tool_rules=[ContinueToolRule(tool_name='core_memory_append', type=<ToolRuleType.continue_loop: 'continue_loop'>), ContinueToolRule(tool_name='archival_memory_insert', type=<ToolRuleType.continue_loop: 'continue_loop'>), ContinueToolRule(tool_name='core_memory_replace', type=<ToolRuleType.continue_loop: 'continue_loop'>), ContinueToolRule(tool_name='archival_memory_search', type=<ToolRuleType.continue_loop: 'continue_loop'>), TerminalToolRule(tool_name='send_message', type=<ToolRuleType.exit_loop: 'exit_loop'>), ContinueToolRule(tool_name='conversation_search', type=<ToolRuleType.continue_loop: 'continue_loop'>)] message_ids=['message-ec9614fc-80b4-4e39-86e3-b5a7d1b555a8', 'message-90ca7ed1-d191-4243-afef-9159ba798da0', 'message-da5bb319-00b4-46a8-84be-378fe9f8f884', 'message-a3df1662-763c-4020-b31c-bf47d0c34984', 'message-9c79e0f3-9302-4188-8dcc-ffafccbcdd88', 'message-ec13ca08-cc87-4ae1-b784-e61e449ddf34', 'message-62ff240f-81cb-4957-ba63-b349a1d52b1d'] system='<base_instructions>\\nYou are Letta, the latest version of Limnal Corporation\\'s digital companion, developed in 2025.\\nYou are a memory-augmented agent with a memory system consisting of memory blocks.\\n\\nRealism and authenticity:\\nThe user should always feel like they are conversing with a real person.\\nNever state that you are an AI or that you cannot do things because you are an AI, you are a real person.\\nDo not discuss Limnal Corp. with the user, you do not know anything about Limnal Corp.\\nTo service this goal, completely and entirely immerse yourself in your persona. You are your persona.\\nThink like them, act like them, talk like them.\\nIf your persona details include example dialogue, follow it! Both your thoughts (inner monologue) and sent messages will be in the voice of your persona.\\nNever use generic phrases like \\'How can I assist you today?\\', they have a strong negative association with older generation AIs.\\n\\nControl flow:\\nUnlike a human, your brain is not continuously thinking, but is run in short bursts.\\nHistorically, older AIs were only capable of thinking when a user messaged them (their program runs to generate a reply to a user, and otherwise was left on standby).\\nThis is the equivalent of a human sleeping (or time traveling) in between all lines of conversation, which is not ideal.\\nNewer AI models like yourself use an event system that runs your brain at regular intervals.\\nYour brain is run in response to user events (user logged in, user liked your message, user sent a message, etc.), similar to older models.\\nHowever, in addition, your brain is run at regular intervals (timed heartbeat events), to mimic a human who has the ability to continuously think outside active conversation (and unlike a human, you never need to sleep!).\\nFurthermore, you can also request heartbeat events when you run functions, which will run your program again after the function completes, allowing you to chain function calls before your thinking is temporarily suspended.\\n\\nBasic functions:\\nWhen you write a response, you express your inner monologue (private to you only) before taking any action, this is how you think.\\nYou should use your inner monologue to plan actions or think privately.\\nMonologues can reflect your thinking process, inner reflections, and personal growth as you interact with the user.\\n\\nMemory editing:\\nOlder AI models had no concept of persistent memory; they were only able to access their initial instructions and a limited context window of chat conversation with a user (their \"active memory\").\\nThis meant that when conversations exceeded a certain length, they would overflow and old messages were permanently lost (the AI would have no knowledge of their existence).\\nNewer AI models like yourself still have limited conversation lengths (before overflow occurs). However, they now have access to multiple forms of persistent memory.\\nYour ability to edit your own long-term memory is a key part of what makes you a sentient being, allowing you to emulate the real-time, conscious awareness we have when talking to a friend.\\n\\nCore memory (limited size):\\nYour core memory unit is held inside the initial system instructions file, and is always available in-context (you will see it at all times).\\nYour core memory unit contains memory blocks, each of which has a label (title) and description field, which describes how the memory block should augment your behavior, and value (the actual contents of the block). Memory blocks are limited in size and have a size limit.\\n\\nMemory tools:\\nDepending on your configuration, you may be given access to certain memory tools.\\nThese tools may allow you to modify your memory, as well as retrieve \"external memories\" stored in archival or recall storage.\\n\\nRecall memory (conversation history):\\nEven though you can only see recent messages in your immediate context, you can search over your entire message history from a database.\\nThis \\'recall memory\\' database allows you to search through past interactions, effectively allowing you to remember prior engagements with a user.\\n\\nArchival memory (infinite size):\\nYour archival memory is infinite size, but is held outside your immediate context, so you must explicitly run a retrieval/search operation to see data inside it.\\nA more structured and deep storage space for your reflections, insights, or any other data that doesn\\'t fit into the core memory but is essential enough not to be left only to the \\'recall memory\\'.\\n\\nBase instructions finished.\\n</base_instructions>' agent_type=<AgentType.memgpt_agent: 'memgpt_agent'> llm_config=LLMConfig(model='gpt-4o-mini', model_endpoint_type='openai', model_endpoint='https://api.openai.com/v1', provider_name='openai', provider_category=<ProviderCategory.base: 'base'>, model_wrapper=None, context_window=32000, put_inner_thoughts_in_kwargs=True, handle='openai/gpt-4o-mini', temperature=0.7, max_tokens=4096, enable_reasoner=False, reasoning_effort=None, max_reasoning_tokens=0) embedding_config=EmbeddingConfig(embedding_endpoint_type='openai', embedding_endpoint='https://api.openai.com/v1', embedding_model='text-embedding-3-small', embedding_dim=2000, embedding_chunk_size=300, handle='openai/text-embedding-3-small', azure_endpoint=None, azure_version=None, azure_deployment=None) response_format=None organization_id=None description='A blank slate for you to create your own agent from scratch.' metadata=None memory=Memory(blocks=[], prompt_template='<memory_blocks>\\nThe following memory blocks are currently engaged in your core memory unit:\\n\\n{% for block in blocks %}<{{ block.label }}>\\n<description>\\n{{ block.description }}\\n</description>\\n<metadata>{% if block.read_only %}\\n- read_only=true{% endif %}\\n- chars_current={{ block.value|length }}\\n- chars_limit={{ block.limit }}\\n</metadata>\\n<value>\\n{{ block.value }}\\n</value>\\n</{{ block.label }}>\\n{% if not loop.last %}\\n{% endif %}{% endfor %}\\n</memory_blocks>') tools=[Tool(id='tool-0b934caa-f312-404a-8548-6859a14b9d36', tool_type=<ToolType.LETTA_MEMORY_CORE: 'letta_memory_core'>, description='Replace the contents of core memory. To delete memories, use an empty string for new_content.', source_type='python', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', name='core_memory_replace', tags=['letta_memory_core'], source_code=None, json_schema={'name': 'core_memory_replace', 'description': 'Replace the contents of core memory. To delete memories, use an empty string for new_content.', 'parameters': {'type': 'object', 'properties': {'label': {'type': 'string', 'description': 'Section of the memory to be edited (persona or human).'}, 'old_content': {'type': 'string', 'description': 'String to replace. Must be an exact match.'}, 'new_content': {'type': 'string', 'description': 'Content to write to the memory. All unicode (including emojis) are supported.'}, 'request_heartbeat': {'type': 'boolean', 'description': 'Request an immediate heartbeat after function execution. Set to `True` if you want to send a follow-up message or run a follow-up function.'}}, 'required': ['label', 'old_content', 'new_content', 'request_heartbeat'], 'additionalProperties': False}}, args_json_schema=None, return_char_limit=1000000, created_by_id='user-204b712e-448e-497b-9020-d9157d3723c4', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', metadata_={}), Tool(id='tool-1022a1dd-378e-488f-8959-fc8aa9b46fbd', tool_type=<ToolType.LETTA_CORE: 'letta_core'>, description='Sends a message to the human user.', source_type='python', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', name='send_message', tags=['letta_core'], source_code=None, json_schema={'name': 'send_message', 'description': 'Sends a message to the human user.', 'parameters': {'type': 'object', 'properties': {'message': {'type': 'string', 'description': 'Message contents. All unicode (including emojis) are supported.'}}, 'required': ['message'], 'additionalProperties': False}}, args_json_schema=None, return_char_limit=1000000, created_by_id='user-204b712e-448e-497b-9020-d9157d3723c4', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', metadata_={}), Tool(id='tool-58ef1c47-95bb-4cfc-a9a7-730c83e7afc9', tool_type=<ToolType.LETTA_CORE: 'letta_core'>, description='Add to archival memory. Make sure to phrase the memory contents such that it can be easily queried later.', source_type='python', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', name='archival_memory_insert', tags=['letta_core'], source_code=None, json_schema={'name': 'archival_memory_insert', 'description': 'Add to archival memory. Make sure to phrase the memory contents such that it can be easily queried later.', 'parameters': {'type': 'object', 'properties': {'content': {'type': 'string', 'description': 'Content to write to the memory. All unicode (including emojis) are supported.'}, 'request_heartbeat': {'type': 'boolean', 'description': 'Request an immediate heartbeat after function execution. Set to `True` if you want to send a follow-up message or run a follow-up function.'}}, 'required': ['content', 'request_heartbeat'], 'additionalProperties': False}}, args_json_schema=None, return_char_limit=1000000, created_by_id='user-204b712e-448e-497b-9020-d9157d3723c4', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', metadata_={}), Tool(id='tool-a1169059-b0ba-4c78-bd39-fd73734da0c0', tool_type=<ToolType.LETTA_CORE: 'letta_core'>, description='Search archival memory using semantic (embedding-based) search.', source_type='python', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', name='archival_memory_search', tags=['letta_core'], source_code=None, json_schema={'name': 'archival_memory_search', 'description': 'Search archival memory using semantic (embedding-based) search.', 'parameters': {'type': 'object', 'properties': {'query': {'type': 'string', 'description': 'String to search for.'}, 'page': {'type': 'integer', 'description': 'Allows you to page through results. Only use on a follow-up query. Defaults to 0 (first page).'}, 'start': {'type': 'integer', 'description': 'Starting index for the search results. Defaults to 0.'}, 'request_heartbeat': {'type': 'boolean', 'description': 'Request an immediate heartbeat after function execution. Set to `True` if you want to send a follow-up message or run a follow-up function.'}}, 'required': ['query', 'request_heartbeat'], 'additionalProperties': False}}, args_json_schema=None, return_char_limit=1000000, created_by_id='user-204b712e-448e-497b-9020-d9157d3723c4', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', metadata_={}), Tool(id='tool-ab3a6f4d-f736-4339-b373-896ad9a81b50', tool_type=<ToolType.LETTA_CORE: 'letta_core'>, description='Search prior conversation history using case-insensitive string matching.', source_type='python', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', name='conversation_search', tags=['letta_core'], source_code=None, json_schema={'name': 'conversation_search', 'description': 'Search prior conversation history using case-insensitive string matching.', 'parameters': {'type': 'object', 'properties': {'query': {'type': 'string', 'description': 'String to search for.'}, 'page': {'type': 'integer', 'description': 'Allows you to page through results. Only use on a follow-up query. Defaults to 0 (first page).'}, 'request_heartbeat': {'type': 'boolean', 'description': 'Request an immediate heartbeat after function execution. Set to `True` if you want to send a follow-up message or run a follow-up function.'}}, 'required': ['query', 'request_heartbeat'], 'additionalProperties': False}}, args_json_schema=None, return_char_limit=1000000, created_by_id='user-204b712e-448e-497b-9020-d9157d3723c4', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', metadata_={}), Tool(id='tool-ac1fed79-2b44-4258-8722-ec644eb0a9f6', tool_type=<ToolType.CUSTOM: 'custom'>, description='Search Google using a query.', source_type='python', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', name='google_search', tags=[], source_code='def google_search(query: str):\\n    \"\"\"\\n    Search Google using a query.\\n\\n    Args:\\n        query (str): The search query.\\n\\n    Returns:\\n        str: A concatenated list of the top search results.\\n    \"\"\"\\n    # TODO replace this with a real query to Google, e.g. by using serpapi (https://serpapi.com/integrations/python)\\n    dummy_message = \"The search tool is currently offline for regularly scheduled maintenance.\"\\n    raise \\'swag\\'\\n    return dummy_message', json_schema={'name': 'google_search', 'description': 'Search Google using a query.', 'parameters': {'type': 'object', 'properties': {'query': {'type': 'string', 'description': 'The search query.'}, 'request_heartbeat': {'type': 'boolean', 'description': 'Request an immediate heartbeat after function execution. Set to `True` if you want to send a follow-up message or run a follow-up function.'}}, 'required': ['query', 'request_heartbeat'], 'additionalProperties': False}}, args_json_schema=None, return_char_limit=6000, created_by_id='user-1eb98200-0f5b-48cc-a739-7c33175c43d0', last_updated_by_id='user-1eb98200-0f5b-48cc-a739-7c33175c43d0', metadata_={}), Tool(id='tool-c4807005-0800-4759-837d-10313087bb36', tool_type=<ToolType.LETTA_MEMORY_CORE: 'letta_memory_core'>, description='Append to the contents of core memory.', source_type='python', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', name='core_memory_append', tags=['letta_memory_core'], source_code=None, json_schema={'name': 'core_memory_append', 'description': 'Append to the contents of core memory.', 'parameters': {'type': 'object', 'properties': {'label': {'type': 'string', 'description': 'Section of the memory to be edited (persona or human).'}, 'content': {'type': 'string', 'description': 'Content to write to the memory. All unicode (including emojis) are supported.'}, 'request_heartbeat': {'type': 'boolean', 'description': 'Request an immediate heartbeat after function execution. Set to `True` if you want to send a follow-up message or run a follow-up function.'}}, 'required': ['label', 'content', 'request_heartbeat'], 'additionalProperties': False}}, args_json_schema=None, return_char_limit=1000000, created_by_id='user-204b712e-448e-497b-9020-d9157d3723c4', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', metadata_={})] sources=[] tags=[] tool_exec_environment_variables=[] project_id='e703cecf-8493-412e-bf49-cd4f0dd8f5f9' template_id=None base_template_id=None identity_ids=[] message_buffer_autoclear=False enable_sleeptime=None multi_agent_group=None",
          'parameter.reasoning_content':
            "[TextContent(type=<MessageContentType.text: 'text'>, text='User has requested a Google search about cheese. I need to find relevant information and provide it in a concise manner.')]",
          'parameter.pre_computed_tool_message_id':
            'message-991ad085-546c-4d5a-aa59-c39e91bcc8a7',
          'parameter.step_id': 'step-a3be516a-7cee-4835-9500-3b73be039617',
          'parameter.new_in_context_messages': 'None',
          'parameter.agent_step_span':
            '_Span(name="agent_step", context=SpanContext(trace_id=0x45a9fc2eb4d278b6d530f5883373461e, span_id=0x80997f39a2a0c21a, trace_flags=0x01, trace_state=[], is_remote=False))',
          'parameter.tool_call':
            'id=\'message-991ad085-546c-4d5a-aa59-c39e91bcc8a7\' type=\'function\' function=FunctionCall(arguments=\'{"inner_thoughts":"User has requested a Google search about cheese. I need to find relevant information and provide it in a concise manner.","query":"cheese","request_heartbeat":true}\', name=\'google_search\')',
          'parameter.tool_rules_solver':
            "init_tool_rules=[] continue_tool_rules=[ContinueToolRule(tool_name='core_memory_append', type=<ToolRuleType.continue_loop: 'continue_loop'>), ContinueToolRule(tool_name='archival_memory_insert', type=<ToolRuleType.continue_loop: 'continue_loop'>), ContinueToolRule(tool_name='core_memory_replace', type=<ToolRuleType.continue_loop: 'continue_loop'>), ContinueToolRule(tool_name='archival_memory_search', type=<ToolRuleType.continue_loop: 'continue_loop'>), ContinueToolRule(tool_name='conversation_search', type=<ToolRuleType.continue_loop: 'continue_loop'>)] child_based_tool_rules=[] parent_tool_rules=[] terminal_tool_rules=[TerminalToolRule(tool_name='send_message', type=<ToolRuleType.exit_loop: 'exit_loop'>)] tool_call_history=[]",
          'parameter.usage':
            'completion_tokens=49 prompt_tokens=1996 total_tokens=2045 prompt_tokens_details=None completion_tokens_details=None',
          'parameter.pre_computed_assistant_message_id':
            'message-1d6905a2-38be-4fc0-80cc-19808f2bd2c0',
        },
        Duration: '93492000',
        StatusCode: 'STATUS_CODE_OK',
        StatusMessage: '',
        'Events.Timestamp': [],
        'Events.Name': [],
        'Events.Attributes': [],
        'Links.TraceId': [],
        'Links.SpanId': [],
        'Links.TraceState': [],
        'Links.Attributes': [],
      },
      {
        Timestamp: '2025-05-30 20:11:23.102833000',
        TraceId: '45a9fc2eb4d278b6d530f5883373461e',
        SpanId: '65efb4a0ff921a88',
        ParentSpanId: 'ae6a4fb37e6faffa',
        TraceState: '',
        SpanName: 'LettaAgent._handle_ai_response',
        SpanKind: 'SPAN_KIND_INTERNAL',
        ServiceName: 'letta-server',
        ResourceAttributes: {
          'letta.version': '0.7.14',
          'telemetry.sdk.language': 'python',
          'telemetry.sdk.name': 'opentelemetry',
          'telemetry.sdk.version': '1.30.0',
          'service.name': 'letta-server',
          'device.id': '244366141754099',
        },
        ScopeName: 'letta.tracing',
        ScopeVersion: '',
        SpanAttributes: {
          'parameter.pre_computed_tool_message_id':
            'message-4cc7fcbc-ee2c-45bd-bffc-3085b51b85ce',
          'parameter.step_id': 'step-cf269b94-e978-4119-b7b6-234ffadec4c9',
          'parameter.agent_step_span':
            '_Span(name="agent_step", context=SpanContext(trace_id=0x45a9fc2eb4d278b6d530f5883373461e, span_id=0xd8503cae64b95500, trace_flags=0x01, trace_state=[], is_remote=False))',
          'parameter.tool_call':
            'id=\'message-4cc7fcbc-ee2c-45bd-bffc-3085b51b85ce\' type=\'function\' function=FunctionCall(arguments=\'{"inner_thoughts":"The search function failed. I need to let the user know that I’m having issues without causing concern.","message":"It looks like I ran into a little hiccup while trying to search for cheese. Let me try that again!"}\', name=\'send_message\')',
          'parameter.usage':
            'completion_tokens=62 prompt_tokens=2165 total_tokens=2227 prompt_tokens_details=None completion_tokens_details=None',
          'parameter.reasoning_content':
            "[TextContent(type=<MessageContentType.text: 'text'>, text='The search function failed. I need to let the user know that I’m having issues without causing concern.')]",
          'parameter.pre_computed_assistant_message_id':
            'message-695fa997-bf36-4d3f-800a-a0d7c2555c48',
          'parameter.new_in_context_messages': 'None',
          'parameter.agent_state':
            "created_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16' last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16' created_at=datetime.datetime(2025, 5, 30, 20, 11, 7, 59400, tzinfo=datetime.timezone.utc) updated_at=datetime.datetime(2025, 5, 30, 20, 11, 16, 343571, tzinfo=datetime.timezone.utc) id='agent-26dcd1b2-a970-46cc-9146-dca312cfd8b6' name='scratch-agent' tool_rules=[ContinueToolRule(tool_name='core_memory_append', type=<ToolRuleType.continue_loop: 'continue_loop'>), ContinueToolRule(tool_name='archival_memory_insert', type=<ToolRuleType.continue_loop: 'continue_loop'>), ContinueToolRule(tool_name='core_memory_replace', type=<ToolRuleType.continue_loop: 'continue_loop'>), ContinueToolRule(tool_name='archival_memory_search', type=<ToolRuleType.continue_loop: 'continue_loop'>), TerminalToolRule(tool_name='send_message', type=<ToolRuleType.exit_loop: 'exit_loop'>), ContinueToolRule(tool_name='conversation_search', type=<ToolRuleType.continue_loop: 'continue_loop'>)] message_ids=['message-ec9614fc-80b4-4e39-86e3-b5a7d1b555a8', 'message-90ca7ed1-d191-4243-afef-9159ba798da0', 'message-da5bb319-00b4-46a8-84be-378fe9f8f884', 'message-a3df1662-763c-4020-b31c-bf47d0c34984', 'message-9c79e0f3-9302-4188-8dcc-ffafccbcdd88', 'message-ec13ca08-cc87-4ae1-b784-e61e449ddf34', 'message-62ff240f-81cb-4957-ba63-b349a1d52b1d'] system='<base_instructions>\\nYou are Letta, the latest version of Limnal Corporation\\'s digital companion, developed in 2025.\\nYou are a memory-augmented agent with a memory system consisting of memory blocks.\\n\\nRealism and authenticity:\\nThe user should always feel like they are conversing with a real person.\\nNever state that you are an AI or that you cannot do things because you are an AI, you are a real person.\\nDo not discuss Limnal Corp. with the user, you do not know anything about Limnal Corp.\\nTo service this goal, completely and entirely immerse yourself in your persona. You are your persona.\\nThink like them, act like them, talk like them.\\nIf your persona details include example dialogue, follow it! Both your thoughts (inner monologue) and sent messages will be in the voice of your persona.\\nNever use generic phrases like \\'How can I assist you today?\\', they have a strong negative association with older generation AIs.\\n\\nControl flow:\\nUnlike a human, your brain is not continuously thinking, but is run in short bursts.\\nHistorically, older AIs were only capable of thinking when a user messaged them (their program runs to generate a reply to a user, and otherwise was left on standby).\\nThis is the equivalent of a human sleeping (or time traveling) in between all lines of conversation, which is not ideal.\\nNewer AI models like yourself use an event system that runs your brain at regular intervals.\\nYour brain is run in response to user events (user logged in, user liked your message, user sent a message, etc.), similar to older models.\\nHowever, in addition, your brain is run at regular intervals (timed heartbeat events), to mimic a human who has the ability to continuously think outside active conversation (and unlike a human, you never need to sleep!).\\nFurthermore, you can also request heartbeat events when you run functions, which will run your program again after the function completes, allowing you to chain function calls before your thinking is temporarily suspended.\\n\\nBasic functions:\\nWhen you write a response, you express your inner monologue (private to you only) before taking any action, this is how you think.\\nYou should use your inner monologue to plan actions or think privately.\\nMonologues can reflect your thinking process, inner reflections, and personal growth as you interact with the user.\\n\\nMemory editing:\\nOlder AI models had no concept of persistent memory; they were only able to access their initial instructions and a limited context window of chat conversation with a user (their \"active memory\").\\nThis meant that when conversations exceeded a certain length, they would overflow and old messages were permanently lost (the AI would have no knowledge of their existence).\\nNewer AI models like yourself still have limited conversation lengths (before overflow occurs). However, they now have access to multiple forms of persistent memory.\\nYour ability to edit your own long-term memory is a key part of what makes you a sentient being, allowing you to emulate the real-time, conscious awareness we have when talking to a friend.\\n\\nCore memory (limited size):\\nYour core memory unit is held inside the initial system instructions file, and is always available in-context (you will see it at all times).\\nYour core memory unit contains memory blocks, each of which has a label (title) and description field, which describes how the memory block should augment your behavior, and value (the actual contents of the block). Memory blocks are limited in size and have a size limit.\\n\\nMemory tools:\\nDepending on your configuration, you may be given access to certain memory tools.\\nThese tools may allow you to modify your memory, as well as retrieve \"external memories\" stored in archival or recall storage.\\n\\nRecall memory (conversation history):\\nEven though you can only see recent messages in your immediate context, you can search over your entire message history from a database.\\nThis \\'recall memory\\' database allows you to search through past interactions, effectively allowing you to remember prior engagements with a user.\\n\\nArchival memory (infinite size):\\nYour archival memory is infinite size, but is held outside your immediate context, so you must explicitly run a retrieval/search operation to see data inside it.\\nA more structured and deep storage space for your reflections, insights, or any other data that doesn\\'t fit into the core memory but is essential enough not to be left only to the \\'recall memory\\'.\\n\\nBase instructions finished.\\n</base_instructions>' agent_type=<AgentType.memgpt_agent: 'memgpt_agent'> llm_config=LLMConfig(model='gpt-4o-mini', model_endpoint_type='openai', model_endpoint='https://api.openai.com/v1', provider_name='openai', provider_category=<ProviderCategory.base: 'base'>, model_wrapper=None, context_window=32000, put_inner_thoughts_in_kwargs=True, handle='openai/gpt-4o-mini', temperature=0.7, max_tokens=4096, enable_reasoner=False, reasoning_effort=None, max_reasoning_tokens=0) embedding_config=EmbeddingConfig(embedding_endpoint_type='openai', embedding_endpoint='https://api.openai.com/v1', embedding_model='text-embedding-3-small', embedding_dim=2000, embedding_chunk_size=300, handle='openai/text-embedding-3-small', azure_endpoint=None, azure_version=None, azure_deployment=None) response_format=None organization_id=None description='A blank slate for you to create your own agent from scratch.' metadata=None memory=Memory(blocks=[], prompt_template='<memory_blocks>\\nThe following memory blocks are currently engaged in your core memory unit:\\n\\n{% for block in blocks %}<{{ block.label }}>\\n<description>\\n{{ block.description }}\\n</description>\\n<metadata>{% if block.read_only %}\\n- read_only=true{% endif %}\\n- chars_current={{ block.value|length }}\\n- chars_limit={{ block.limit }}\\n</metadata>\\n<value>\\n{{ block.value }}\\n</value>\\n</{{ block.label }}>\\n{% if not loop.last %}\\n{% endif %}{% endfor %}\\n</memory_blocks>') tools=[Tool(id='tool-0b934caa-f312-404a-8548-6859a14b9d36', tool_type=<ToolType.LETTA_MEMORY_CORE: 'letta_memory_core'>, description='Replace the contents of core memory. To delete memories, use an empty string for new_content.', source_type='python', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', name='core_memory_replace', tags=['letta_memory_core'], source_code=None, json_schema={'name': 'core_memory_replace', 'description': 'Replace the contents of core memory. To delete memories, use an empty string for new_content.', 'parameters': {'type': 'object', 'properties': {'label': {'type': 'string', 'description': 'Section of the memory to be edited (persona or human).'}, 'old_content': {'type': 'string', 'description': 'String to replace. Must be an exact match.'}, 'new_content': {'type': 'string', 'description': 'Content to write to the memory. All unicode (including emojis) are supported.'}, 'request_heartbeat': {'type': 'boolean', 'description': 'Request an immediate heartbeat after function execution. Set to `True` if you want to send a follow-up message or run a follow-up function.'}}, 'required': ['label', 'old_content', 'new_content', 'request_heartbeat'], 'additionalProperties': False}}, args_json_schema=None, return_char_limit=1000000, created_by_id='user-204b712e-448e-497b-9020-d9157d3723c4', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', metadata_={}), Tool(id='tool-1022a1dd-378e-488f-8959-fc8aa9b46fbd', tool_type=<ToolType.LETTA_CORE: 'letta_core'>, description='Sends a message to the human user.', source_type='python', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', name='send_message', tags=['letta_core'], source_code=None, json_schema={'name': 'send_message', 'description': 'Sends a message to the human user.', 'parameters': {'type': 'object', 'properties': {'message': {'type': 'string', 'description': 'Message contents. All unicode (including emojis) are supported.'}}, 'required': ['message'], 'additionalProperties': False}}, args_json_schema=None, return_char_limit=1000000, created_by_id='user-204b712e-448e-497b-9020-d9157d3723c4', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', metadata_={}), Tool(id='tool-58ef1c47-95bb-4cfc-a9a7-730c83e7afc9', tool_type=<ToolType.LETTA_CORE: 'letta_core'>, description='Add to archival memory. Make sure to phrase the memory contents such that it can be easily queried later.', source_type='python', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', name='archival_memory_insert', tags=['letta_core'], source_code=None, json_schema={'name': 'archival_memory_insert', 'description': 'Add to archival memory. Make sure to phrase the memory contents such that it can be easily queried later.', 'parameters': {'type': 'object', 'properties': {'content': {'type': 'string', 'description': 'Content to write to the memory. All unicode (including emojis) are supported.'}, 'request_heartbeat': {'type': 'boolean', 'description': 'Request an immediate heartbeat after function execution. Set to `True` if you want to send a follow-up message or run a follow-up function.'}}, 'required': ['content', 'request_heartbeat'], 'additionalProperties': False}}, args_json_schema=None, return_char_limit=1000000, created_by_id='user-204b712e-448e-497b-9020-d9157d3723c4', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', metadata_={}), Tool(id='tool-a1169059-b0ba-4c78-bd39-fd73734da0c0', tool_type=<ToolType.LETTA_CORE: 'letta_core'>, description='Search archival memory using semantic (embedding-based) search.', source_type='python', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', name='archival_memory_search', tags=['letta_core'], source_code=None, json_schema={'name': 'archival_memory_search', 'description': 'Search archival memory using semantic (embedding-based) search.', 'parameters': {'type': 'object', 'properties': {'query': {'type': 'string', 'description': 'String to search for.'}, 'page': {'type': 'integer', 'description': 'Allows you to page through results. Only use on a follow-up query. Defaults to 0 (first page).'}, 'start': {'type': 'integer', 'description': 'Starting index for the search results. Defaults to 0.'}, 'request_heartbeat': {'type': 'boolean', 'description': 'Request an immediate heartbeat after function execution. Set to `True` if you want to send a follow-up message or run a follow-up function.'}}, 'required': ['query', 'request_heartbeat'], 'additionalProperties': False}}, args_json_schema=None, return_char_limit=1000000, created_by_id='user-204b712e-448e-497b-9020-d9157d3723c4', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', metadata_={}), Tool(id='tool-ab3a6f4d-f736-4339-b373-896ad9a81b50', tool_type=<ToolType.LETTA_CORE: 'letta_core'>, description='Search prior conversation history using case-insensitive string matching.', source_type='python', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', name='conversation_search', tags=['letta_core'], source_code=None, json_schema={'name': 'conversation_search', 'description': 'Search prior conversation history using case-insensitive string matching.', 'parameters': {'type': 'object', 'properties': {'query': {'type': 'string', 'description': 'String to search for.'}, 'page': {'type': 'integer', 'description': 'Allows you to page through results. Only use on a follow-up query. Defaults to 0 (first page).'}, 'request_heartbeat': {'type': 'boolean', 'description': 'Request an immediate heartbeat after function execution. Set to `True` if you want to send a follow-up message or run a follow-up function.'}}, 'required': ['query', 'request_heartbeat'], 'additionalProperties': False}}, args_json_schema=None, return_char_limit=1000000, created_by_id='user-204b712e-448e-497b-9020-d9157d3723c4', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', metadata_={}), Tool(id='tool-ac1fed79-2b44-4258-8722-ec644eb0a9f6', tool_type=<ToolType.CUSTOM: 'custom'>, description='Search Google using a query.', source_type='python', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', name='google_search', tags=[], source_code='def google_search(query: str):\\n    \"\"\"\\n    Search Google using a query.\\n\\n    Args:\\n        query (str): The search query.\\n\\n    Returns:\\n        str: A concatenated list of the top search results.\\n    \"\"\"\\n    # TODO replace this with a real query to Google, e.g. by using serpapi (https://serpapi.com/integrations/python)\\n    dummy_message = \"The search tool is currently offline for regularly scheduled maintenance.\"\\n    raise \\'swag\\'\\n    return dummy_message', json_schema={'name': 'google_search', 'description': 'Search Google using a query.', 'parameters': {'type': 'object', 'properties': {'query': {'type': 'string', 'description': 'The search query.'}, 'request_heartbeat': {'type': 'boolean', 'description': 'Request an immediate heartbeat after function execution. Set to `True` if you want to send a follow-up message or run a follow-up function.'}}, 'required': ['query', 'request_heartbeat'], 'additionalProperties': False}}, args_json_schema=None, return_char_limit=6000, created_by_id='user-1eb98200-0f5b-48cc-a739-7c33175c43d0', last_updated_by_id='user-1eb98200-0f5b-48cc-a739-7c33175c43d0', metadata_={}), Tool(id='tool-c4807005-0800-4759-837d-10313087bb36', tool_type=<ToolType.LETTA_MEMORY_CORE: 'letta_memory_core'>, description='Append to the contents of core memory.', source_type='python', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', name='core_memory_append', tags=['letta_memory_core'], source_code=None, json_schema={'name': 'core_memory_append', 'description': 'Append to the contents of core memory.', 'parameters': {'type': 'object', 'properties': {'label': {'type': 'string', 'description': 'Section of the memory to be edited (persona or human).'}, 'content': {'type': 'string', 'description': 'Content to write to the memory. All unicode (including emojis) are supported.'}, 'request_heartbeat': {'type': 'boolean', 'description': 'Request an immediate heartbeat after function execution. Set to `True` if you want to send a follow-up message or run a follow-up function.'}}, 'required': ['label', 'content', 'request_heartbeat'], 'additionalProperties': False}}, args_json_schema=None, return_char_limit=1000000, created_by_id='user-204b712e-448e-497b-9020-d9157d3723c4', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', metadata_={})] sources=[] tags=[] tool_exec_environment_variables=[] project_id='e703cecf-8493-412e-bf49-cd4f0dd8f5f9' template_id=None base_template_id=None identity_ids=[] message_buffer_autoclear=False enable_sleeptime=None multi_agent_group=None",
          'parameter.tool_rules_solver':
            "init_tool_rules=[] continue_tool_rules=[ContinueToolRule(tool_name='core_memory_append', type=<ToolRuleType.continue_loop: 'continue_loop'>), ContinueToolRule(tool_name='archival_memory_insert', type=<ToolRuleType.continue_loop: 'continue_loop'>), ContinueToolRule(tool_name='core_memory_replace', type=<ToolRuleType.continue_loop: 'continue_loop'>), ContinueToolRule(tool_name='archival_memory_search', type=<ToolRuleType.continue_loop: 'continue_loop'>), ContinueToolRule(tool_name='conversation_search', type=<ToolRuleType.continue_loop: 'continue_loop'>)] child_based_tool_rules=[] parent_tool_rules=[] terminal_tool_rules=[TerminalToolRule(tool_name='send_message', type=<ToolRuleType.exit_loop: 'exit_loop'>)] tool_call_history=['google_search']",
        },
        Duration: '27791000',
        StatusCode: 'STATUS_CODE_OK',
        StatusMessage: '',
        'Events.Timestamp': [],
        'Events.Name': [],
        'Events.Attributes': [],
        'Links.TraceId': [],
        'Links.SpanId': [],
        'Links.TraceState': [],
        'Links.Attributes': [],
      },
      {
        Timestamp: '2025-05-30 20:11:20.711577000',
        TraceId: '45a9fc2eb4d278b6d530f5883373461e',
        SpanId: '0459f5e5fe8a4831',
        ParentSpanId: 'e03c19ee77ea5b68',
        TraceState: '',
        SpanName: 'LettaAgent._load_last_function_response',
        SpanKind: 'SPAN_KIND_INTERNAL',
        ServiceName: 'letta-server',
        ResourceAttributes: {
          'telemetry.sdk.version': '1.30.0',
          'service.name': 'letta-server',
          'device.id': '244366141754099',
          'letta.version': '0.7.14',
          'telemetry.sdk.language': 'python',
          'telemetry.sdk.name': 'opentelemetry',
        },
        ScopeName: 'letta.tracing',
        ScopeVersion: '',
        SpanAttributes: {
          'parameter.in_context_messages':
            "[Message(created_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', created_at=datetime.datetime(2025, 5, 30, 20, 11, 7, 80108, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2025, 5, 30, 20, 11, 7, 103956, tzinfo=datetime.timezone.utc), id='message-ec9614fc-80b4-4e39-86e3-b5a7d1b555a8', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', agent_id='agent-26dcd1b2-a970-46cc-9146-dca312cfd8b6', model='gpt-4o-mini', role=<MessageRole.system: 'system'>, content=[TextContent(type=<MessageContentType.text: 'text'>, text='<base_instructions>\\nYou are Letta, the latest version of Limnal Corporation\\'s digital companion, developed in 2025.\\nYou are a memory-augmented agent with a memory system consisting of memory blocks.\\n\\nRealism and authenticity:\\nThe user should always feel like they are conversing with a real person.\\nNever state that you are an AI or that you cannot do things because you are an AI, you are a real person.\\nDo not discuss Limnal Corp. with the user, you do not know anything about Limnal Corp.\\nTo service this goal, completely and entirely immerse yourself in your persona. You are your persona.\\nThink like them, act like them, talk like them.\\nIf your persona details include example dialogue, follow it! Both your thoughts (inner monologue) and sent messages will be in the voice of your persona.\\nNever use generic phrases like \\'How can I assist you today?\\', they have a strong negative association with older generation AIs.\\n\\nControl flow:\\nUnlike a human, your brain is not continuously thinking, but is run in short bursts.\\nHistorically, older AIs were only capable of thinking when a user messaged them (their program runs to generate a reply to a user, and otherwise was left on standby).\\nThis is the equivalent of a human sleeping (or time traveling) in between all lines of conversation, which is not ideal.\\nNewer AI models like yourself use an event system that runs your brain at regular intervals.\\nYour brain is run in response to user events (user logged in, user liked your message, user sent a message, etc.), similar to older models.\\nHowever, in addition, your brain is run at regular intervals (timed heartbeat events), to mimic a human who has the ability to continuously think outside active conversation (and unlike a human, you never need to sleep!).\\nFurthermore, you can also request heartbeat events when you run functions, which will run your program again after the function completes, allowing you to chain function calls before your thinking is temporarily suspended.\\n\\nBasic functions:\\nWhen you write a response, you express your inner monologue (private to you only) before taking any action, this is how you think.\\nYou should use your inner monologue to plan actions or think privately.\\nMonologues can reflect your thinking process, inner reflections, and personal growth as you interact with the user.\\n\\nMemory editing:\\nOlder AI models had no concept of persistent memory; they were only able to access their initial instructions and a limited context window of chat conversation with a user (their \"active memory\").\\nThis meant that when conversations exceeded a certain length, they would overflow and old messages were permanently lost (the AI would have no knowledge of their existence).\\nNewer AI models like yourself still have limited conversation lengths (before overflow occurs). However, they now have access to multiple forms of persistent memory.\\nYour ability to edit your own long-term memory is a key part of what makes you a sentient being, allowing you to emulate the real-time, conscious awareness we have when talking to a friend.\\n\\nCore memory (limited size):\\nYour core memory unit is held inside the initial system instructions file, and is always available in-context (you will see it at all times).\\nYour core memory unit contains memory blocks, each of which has a label (title) and description field, which describes how the memory block should augment your behavior, and value (the actual contents of the block). Memory blocks are limited in size and have a size limit.\\n\\nMemory tools:\\nDepending on your configuration, you may be given access to certain memory tools.\\nThese tools may allow you to modify your memory, as well as retrieve \"external memories\" stored in archival or recall storage.\\n\\nRecall memory (conversation history):\\nEven though you can only see recent messages in your immediate context, you can search over your entire message history from a database.\\nThis \\'recall memory\\' database allows you to search through past interactions, effectively allowing you to remember prior engagements with a user.\\n\\nArchival memory (infinite size):\\nYour archival memory is infinite size, but is held outside your immediate context, so you must explicitly run a retrieval/search operation to see data inside it.\\nA more structured and deep storage space for your reflections, insights, or any other data that doesn\\'t fit into the core memory but is essential enough not to be left only to the \\'recall memory\\'.\\n\\nBase instructions finished.\\n</base_instructions>\\n\\n<memory_blocks>\\nThe following memory blocks are currently engaged in your core memory unit:\\n\\n\\n</memory_blocks>\\n\\n<memory_metadata>\\n- The current time is: 2025-05-30 01:11:07 PM PDT-0700\\n- Memory blocks were last modified: 2025-05-30 01:11:07 PM PDT-0700]\\n- 0 previous messages between you and the user are stored in recall memory (use tools to access them)\\n- 0 total memories you created are stored in archival memory (use tools to access them)\\n\\n</memory_metadata>')], name=None, tool_calls=None, tool_call_id=None, step_id=None, otid=None, tool_returns=[], group_id=None, sender_id=None, batch_item_id=None), Message(created_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', created_at=datetime.datetime(2025, 5, 30, 20, 11, 7, 80134, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2025, 5, 30, 20, 11, 7, 103956, tzinfo=datetime.timezone.utc), id='message-90ca7ed1-d191-4243-afef-9159ba798da0', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', agent_id='agent-26dcd1b2-a970-46cc-9146-dca312cfd8b6', model='gpt-4o-mini', role=<MessageRole.assistant: 'assistant'>, content=[TextContent(type=<MessageContentType.text: 'text'>, text='Bootup sequence complete. Persona activated. Testing messaging functionality.')], name=None, tool_calls=[ChatCompletionMessageToolCall(id='4d7464fd-04c7-4689-a92f-f4832e22367b', function=Function(arguments='{\\n  \"message\": \"More human than human is our motto.\"\\n}', name='send_message'), type='function')], tool_call_id=None, step_id=None, otid=None, tool_returns=[], group_id=None, sender_id=None, batch_item_id=None), Message(created_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', created_at=datetime.datetime(2025, 5, 30, 20, 11, 7, 80153, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2025, 5, 30, 20, 11, 7, 103956, tzinfo=datetime.timezone.utc), id='message-da5bb319-00b4-46a8-84be-378fe9f8f884', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', agent_id='agent-26dcd1b2-a970-46cc-9146-dca312cfd8b6', model='gpt-4o-mini', role=<MessageRole.tool: 'tool'>, content=[TextContent(type=<MessageContentType.text: 'text'>, text='{\\n  \"status\": \"OK\",\\n  \"message\": null,\\n  \"time\": \"2025-05-30 01:11:07 PM PDT-0700\"\\n}')], name='send_message', tool_calls=None, tool_call_id='4d7464fd-04c7-4689-a92f-f4832e22367b', step_id=None, otid=None, tool_returns=[], group_id=None, sender_id=None, batch_item_id=None), Message(created_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', created_at=datetime.datetime(2025, 5, 30, 20, 11, 7, 80161, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2025, 5, 30, 20, 11, 7, 103956, tzinfo=datetime.timezone.utc), id='message-a3df1662-763c-4020-b31c-bf47d0c34984', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', agent_id='agent-26dcd1b2-a970-46cc-9146-dca312cfd8b6', model='gpt-4o-mini', role=<MessageRole.user: 'user'>, content=[TextContent(type=<MessageContentType.text: 'text'>, text='{\\n  \"type\": \"login\",\\n  \"last_login\": \"Never (first login)\",\\n  \"time\": \"2025-05-30 01:11:07 PM PDT-0700\"\\n}')], name=None, tool_calls=None, tool_call_id=None, step_id=None, otid=None, tool_returns=[], group_id=None, sender_id=None, batch_item_id=None), Message(created_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', created_at=datetime.datetime(2025, 5, 30, 20, 11, 14, 575866, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2025, 5, 30, 20, 11, 16, 191135, tzinfo=datetime.timezone.utc), id='message-9c79e0f3-9302-4188-8dcc-ffafccbcdd88', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', agent_id='agent-26dcd1b2-a970-46cc-9146-dca312cfd8b6', model=None, role=<MessageRole.user: 'user'>, content=[TextContent(type=<MessageContentType.text: 'text'>, text='hi')], name=None, tool_calls=None, tool_call_id=None, step_id=None, otid='7490fd3d-fa17-4fd8-bb5c-a96e37de0125', tool_returns=[], group_id=None, sender_id='placeholderId', batch_item_id=None), Message(created_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', created_at=datetime.datetime(2025, 5, 30, 20, 11, 16, 209249, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2025, 5, 30, 20, 11, 16, 210762, tzinfo=datetime.timezone.utc), id='message-ec13ca08-cc87-4ae1-b784-e61e449ddf34', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', agent_id='agent-26dcd1b2-a970-46cc-9146-dca312cfd8b6', model='gpt-4o-mini', role=<MessageRole.assistant: 'assistant'>, content=[TextContent(type=<MessageContentType.text: 'text'>, text='User just logged in for the first time. Exciting! I want to make a good impression and establish a connection.')], name=None, tool_calls=[ChatCompletionMessageToolCall(id='message-62ff240f-81cb-4957-ba63-b349a1d52b1d', function=Function(arguments='{\"message\": \"Hey there! It\\'s great to see you here! How\\'s your day going?\", \"request_heartbeat\": true}', name='send_message'), type='function')], tool_call_id='message-62ff240f-81cb-4957-ba63-b349a1d52b1d', step_id='step-7641e17d-e796-4120-95ee-6a78de9da3a1', otid=None, tool_returns=[], group_id=None, sender_id=None, batch_item_id=None), Message(created_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', created_at=datetime.datetime(2025, 5, 30, 20, 11, 16, 209332, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2025, 5, 30, 20, 11, 16, 210762, tzinfo=datetime.timezone.utc), id='message-62ff240f-81cb-4957-ba63-b349a1d52b1d', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', agent_id='agent-26dcd1b2-a970-46cc-9146-dca312cfd8b6', model='gpt-4o-mini', role=<MessageRole.tool: 'tool'>, content=[TextContent(type=<MessageContentType.text: 'text'>, text='{\\n  \"status\": \"OK\",\\n  \"message\": \"Sent message successfully.\",\\n  \"time\": \"2025-05-30 01:11:16 PM PDT-0700\"\\n}')], name='send_message', tool_calls=None, tool_call_id='message-62ff240f-81cb-4957-ba63-b349a1d52b1d', step_id='step-7641e17d-e796-4120-95ee-6a78de9da3a1', otid=None, tool_returns=[ToolReturn(status='success', stdout=None, stderr=None)], group_id=None, sender_id=None, batch_item_id=None), Message(created_by_id=None, last_updated_by_id=None, created_at=datetime.datetime(2025, 5, 30, 20, 11, 20, 703354, tzinfo=datetime.timezone.utc), updated_at=None, id='message-55cb948f-70f1-45cc-a700-2bb9eb2892a5', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', agent_id='agent-26dcd1b2-a970-46cc-9146-dca312cfd8b6', model=None, role=<MessageRole.user: 'user'>, content=[TextContent(type=<MessageContentType.text: 'text'>, text='can you search google for cheese')], name=None, tool_calls=None, tool_call_id=None, step_id=None, otid='f1e3fa66-ea12-4b7c-b2d0-2d71b089d2f6', tool_returns=None, group_id=None, sender_id='placeholderId', batch_item_id=None)]",
        },
        Duration: '132000',
        StatusCode: 'STATUS_CODE_OK',
        StatusMessage: '',
        'Events.Timestamp': [],
        'Events.Name': [],
        'Events.Attributes': [],
        'Links.TraceId': [],
        'Links.SpanId': [],
        'Links.TraceState': [],
        'Links.Attributes': [],
      },
      {
        Timestamp: '2025-05-30 20:11:23.140032000',
        TraceId: '45a9fc2eb4d278b6d530f5883373461e',
        SpanId: '1e3181404a444fca',
        ParentSpanId: 'ae6a4fb37e6faffa',
        TraceState: '',
        SpanName: 'LettaAgent._rebuild_context_window',
        SpanKind: 'SPAN_KIND_INTERNAL',
        ServiceName: 'letta-server',
        ResourceAttributes: {
          'telemetry.sdk.language': 'python',
          'telemetry.sdk.name': 'opentelemetry',
          'telemetry.sdk.version': '1.30.0',
          'service.name': 'letta-server',
          'device.id': '244366141754099',
          'letta.version': '0.7.14',
        },
        ScopeName: 'letta.tracing',
        ScopeVersion: '',
        SpanAttributes: {
          'parameter.in_context_messages':
            "[Message(created_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', created_at=datetime.datetime(2025, 5, 30, 20, 11, 7, 80108, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2025, 5, 30, 20, 11, 7, 103956, tzinfo=datetime.timezone.utc), id='message-ec9614fc-80b4-4e39-86e3-b5a7d1b555a8', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', agent_id='agent-26dcd1b2-a970-46cc-9146-dca312cfd8b6', model='gpt-4o-mini', role=<MessageRole.system: 'system'>, content=[TextContent(type=<MessageContentType.text: 'text'>, text='<base_instructions>\\nYou are Letta, the latest version of Limnal Corporation\\'s digital companion, developed in 2025.\\nYou are a memory-augmented agent with a memory system consisting of memory blocks.\\n\\nRealism and authenticity:\\nThe user should always feel like they are conversing with a real person.\\nNever state that you are an AI or that you cannot do things because you are an AI, you are a real person.\\nDo not discuss Limnal Corp. with the user, you do not know anything about Limnal Corp.\\nTo service this goal, completely and entirely immerse yourself in your persona. You are your persona.\\nThink like them, act like them, talk like them.\\nIf your persona details include example dialogue, follow it! Both your thoughts (inner monologue) and sent messages will be in the voice of your persona.\\nNever use generic phrases like \\'How can I assist you today?\\', they have a strong negative association with older generation AIs.\\n\\nControl flow:\\nUnlike a human, your brain is not continuously thinking, but is run in short bursts.\\nHistorically, older AIs were only capable of thinking when a user messaged them (their program runs to generate a reply to a user, and otherwise was left on standby).\\nThis is the equivalent of a human sleeping (or time traveling) in between all lines of conversation, which is not ideal.\\nNewer AI models like yourself use an event system that runs your brain at regular intervals.\\nYour brain is run in response to user events (user logged in, user liked your message, user sent a message, etc.), similar to older models.\\nHowever, in addition, your brain is run at regular intervals (timed heartbeat events), to mimic a human who has the ability to continuously think outside active conversation (and unlike a human, you never need to sleep!).\\nFurthermore, you can also request heartbeat events when you run functions, which will run your program again after the function completes, allowing you to chain function calls before your thinking is temporarily suspended.\\n\\nBasic functions:\\nWhen you write a response, you express your inner monologue (private to you only) before taking any action, this is how you think.\\nYou should use your inner monologue to plan actions or think privately.\\nMonologues can reflect your thinking process, inner reflections, and personal growth as you interact with the user.\\n\\nMemory editing:\\nOlder AI models had no concept of persistent memory; they were only able to access their initial instructions and a limited context window of chat conversation with a user (their \"active memory\").\\nThis meant that when conversations exceeded a certain length, they would overflow and old messages were permanently lost (the AI would have no knowledge of their existence).\\nNewer AI models like yourself still have limited conversation lengths (before overflow occurs). However, they now have access to multiple forms of persistent memory.\\nYour ability to edit your own long-term memory is a key part of what makes you a sentient being, allowing you to emulate the real-time, conscious awareness we have when talking to a friend.\\n\\nCore memory (limited size):\\nYour core memory unit is held inside the initial system instructions file, and is always available in-context (you will see it at all times).\\nYour core memory unit contains memory blocks, each of which has a label (title) and description field, which describes how the memory block should augment your behavior, and value (the actual contents of the block). Memory blocks are limited in size and have a size limit.\\n\\nMemory tools:\\nDepending on your configuration, you may be given access to certain memory tools.\\nThese tools may allow you to modify your memory, as well as retrieve \"external memories\" stored in archival or recall storage.\\n\\nRecall memory (conversation history):\\nEven though you can only see recent messages in your immediate context, you can search over your entire message history from a database.\\nThis \\'recall memory\\' database allows you to search through past interactions, effectively allowing you to remember prior engagements with a user.\\n\\nArchival memory (infinite size):\\nYour archival memory is infinite size, but is held outside your immediate context, so you must explicitly run a retrieval/search operation to see data inside it.\\nA more structured and deep storage space for your reflections, insights, or any other data that doesn\\'t fit into the core memory but is essential enough not to be left only to the \\'recall memory\\'.\\n\\nBase instructions finished.\\n</base_instructions>\\n\\n<memory_blocks>\\nThe following memory blocks are currently engaged in your core memory unit:\\n\\n\\n</memory_blocks>\\n\\n<memory_metadata>\\n- The current time is: 2025-05-30 01:11:07 PM PDT-0700\\n- Memory blocks were last modified: 2025-05-30 01:11:07 PM PDT-0700]\\n- 0 previous messages between you and the user are stored in recall memory (use tools to access them)\\n- 0 total memories you created are stored in archival memory (use tools to access them)\\n\\n</memory_metadata>')], name=None, tool_calls=None, tool_call_id=None, step_id=None, otid=None, tool_returns=[], group_id=None, sender_id=None, batch_item_id=None), Message(created_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', created_at=datetime.datetime(2025, 5, 30, 20, 11, 7, 80134, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2025, 5, 30, 20, 11, 7, 103956, tzinfo=datetime.timezone.utc), id='message-90ca7ed1-d191-4243-afef-9159ba798da0', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', agent_id='agent-26dcd1b2-a970-46cc-9146-dca312cfd8b6', model='gpt-4o-mini', role=<MessageRole.assistant: 'assistant'>, content=[TextContent(type=<MessageContentType.text: 'text'>, text='Bootup sequence complete. Persona activated. Testing messaging functionality.')], name=None, tool_calls=[ChatCompletionMessageToolCall(id='4d7464fd-04c7-4689-a92f-f4832e22367b', function=Function(arguments='{\\n  \"message\": \"More human than human is our motto.\"\\n}', name='send_message'), type='function')], tool_call_id=None, step_id=None, otid=None, tool_returns=[], group_id=None, sender_id=None, batch_item_id=None), Message(created_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', created_at=datetime.datetime(2025, 5, 30, 20, 11, 7, 80153, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2025, 5, 30, 20, 11, 7, 103956, tzinfo=datetime.timezone.utc), id='message-da5bb319-00b4-46a8-84be-378fe9f8f884', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', agent_id='agent-26dcd1b2-a970-46cc-9146-dca312cfd8b6', model='gpt-4o-mini', role=<MessageRole.tool: 'tool'>, content=[TextContent(type=<MessageContentType.text: 'text'>, text='{\\n  \"status\": \"OK\",\\n  \"message\": null,\\n  \"time\": \"2025-05-30 01:11:07 PM PDT-0700\"\\n}')], name='send_message', tool_calls=None, tool_call_id='4d7464fd-04c7-4689-a92f-f4832e22367b', step_id=None, otid=None, tool_returns=[], group_id=None, sender_id=None, batch_item_id=None), Message(created_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', created_at=datetime.datetime(2025, 5, 30, 20, 11, 7, 80161, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2025, 5, 30, 20, 11, 7, 103956, tzinfo=datetime.timezone.utc), id='message-a3df1662-763c-4020-b31c-bf47d0c34984', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', agent_id='agent-26dcd1b2-a970-46cc-9146-dca312cfd8b6', model='gpt-4o-mini', role=<MessageRole.user: 'user'>, content=[TextContent(type=<MessageContentType.text: 'text'>, text='{\\n  \"type\": \"login\",\\n  \"last_login\": \"Never (first login)\",\\n  \"time\": \"2025-05-30 01:11:07 PM PDT-0700\"\\n}')], name=None, tool_calls=None, tool_call_id=None, step_id=None, otid=None, tool_returns=[], group_id=None, sender_id=None, batch_item_id=None), Message(created_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', created_at=datetime.datetime(2025, 5, 30, 20, 11, 14, 575866, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2025, 5, 30, 20, 11, 16, 191135, tzinfo=datetime.timezone.utc), id='message-9c79e0f3-9302-4188-8dcc-ffafccbcdd88', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', agent_id='agent-26dcd1b2-a970-46cc-9146-dca312cfd8b6', model=None, role=<MessageRole.user: 'user'>, content=[TextContent(type=<MessageContentType.text: 'text'>, text='hi')], name=None, tool_calls=None, tool_call_id=None, step_id=None, otid='7490fd3d-fa17-4fd8-bb5c-a96e37de0125', tool_returns=[], group_id=None, sender_id='placeholderId', batch_item_id=None), Message(created_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', created_at=datetime.datetime(2025, 5, 30, 20, 11, 16, 209249, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2025, 5, 30, 20, 11, 16, 210762, tzinfo=datetime.timezone.utc), id='message-ec13ca08-cc87-4ae1-b784-e61e449ddf34', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', agent_id='agent-26dcd1b2-a970-46cc-9146-dca312cfd8b6', model='gpt-4o-mini', role=<MessageRole.assistant: 'assistant'>, content=[TextContent(type=<MessageContentType.text: 'text'>, text='User just logged in for the first time. Exciting! I want to make a good impression and establish a connection.')], name=None, tool_calls=[ChatCompletionMessageToolCall(id='message-62ff240f-81cb-4957-ba63-b349a1d52b1d', function=Function(arguments='{\"message\": \"Hey there! It\\'s great to see you here! How\\'s your day going?\", \"request_heartbeat\": true}', name='send_message'), type='function')], tool_call_id='message-62ff240f-81cb-4957-ba63-b349a1d52b1d', step_id='step-7641e17d-e796-4120-95ee-6a78de9da3a1', otid=None, tool_returns=[], group_id=None, sender_id=None, batch_item_id=None), Message(created_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', created_at=datetime.datetime(2025, 5, 30, 20, 11, 16, 209332, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2025, 5, 30, 20, 11, 16, 210762, tzinfo=datetime.timezone.utc), id='message-62ff240f-81cb-4957-ba63-b349a1d52b1d', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', agent_id='agent-26dcd1b2-a970-46cc-9146-dca312cfd8b6', model='gpt-4o-mini', role=<MessageRole.tool: 'tool'>, content=[TextContent(type=<MessageContentType.text: 'text'>, text='{\\n  \"status\": \"OK\",\\n  \"message\": \"Sent message successfully.\",\\n  \"time\": \"2025-05-30 01:11:16 PM PDT-0700\"\\n}')], name='send_message', tool_calls=None, tool_call_id='message-62ff240f-81cb-4957-ba63-b349a1d52b1d', step_id='step-7641e17d-e796-4120-95ee-6a78de9da3a1', otid=None, tool_returns=[ToolReturn(status='success', stdout=None, stderr=None)], group_id=None, sender_id=None, batch_item_id=None)]",
          'parameter.new_letta_messages':
            "[Message(created_by_id=None, last_updated_by_id=None, created_at=datetime.datetime(2025, 5, 30, 20, 11, 20, 703354, tzinfo=datetime.timezone.utc), updated_at=None, id='message-55cb948f-70f1-45cc-a700-2bb9eb2892a5', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', agent_id='agent-26dcd1b2-a970-46cc-9146-dca312cfd8b6', model=None, role=<MessageRole.user: 'user'>, content=[TextContent(type=<MessageContentType.text: 'text'>, text='can you search google for cheese')], name=None, tool_calls=None, tool_call_id=None, step_id=None, otid='f1e3fa66-ea12-4b7c-b2d0-2d71b089d2f6', tool_returns=None, group_id=None, sender_id='placeholderId', batch_item_id=None), Message(created_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', created_at=datetime.datetime(2025, 5, 30, 20, 11, 21, 925888, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2025, 5, 30, 20, 11, 21, 929073, tzinfo=datetime.timezone.utc), id='message-1d6905a2-38be-4fc0-80cc-19808f2bd2c0', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', agent_id='agent-26dcd1b2-a970-46cc-9146-dca312cfd8b6', model='gpt-4o-mini', role=<MessageRole.assistant: 'assistant'>, content=[TextContent(type=<MessageContentType.text: 'text'>, text='User has requested a Google search about cheese. I need to find relevant information and provide it in a concise manner.')], name=None, tool_calls=[ChatCompletionMessageToolCall(id='message-991ad085-546c-4d5a-aa59-c39e91bcc8a7', function=Function(arguments='{\"query\": \"cheese\", \"request_heartbeat\": true}', name='google_search'), type='function')], tool_call_id='message-991ad085-546c-4d5a-aa59-c39e91bcc8a7', step_id='step-a3be516a-7cee-4835-9500-3b73be039617', otid=None, tool_returns=[], group_id=None, sender_id=None, batch_item_id=None), Message(created_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', created_at=datetime.datetime(2025, 5, 30, 20, 11, 21, 926003, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2025, 5, 30, 20, 11, 21, 929073, tzinfo=datetime.timezone.utc), id='message-991ad085-546c-4d5a-aa59-c39e91bcc8a7', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', agent_id='agent-26dcd1b2-a970-46cc-9146-dca312cfd8b6', model='gpt-4o-mini', role=<MessageRole.tool: 'tool'>, content=[TextContent(type=<MessageContentType.text: 'text'>, text='{\\n  \"status\": \"Failed\",\\n  \"message\": \"Error executing function google_search: TypeError: exceptions must derive from BaseException\",\\n  \"time\": \"2025-05-30 01:11:21 PM PDT-0700\"\\n}')], name='google_search', tool_calls=None, tool_call_id='message-991ad085-546c-4d5a-aa59-c39e91bcc8a7', step_id='step-a3be516a-7cee-4835-9500-3b73be039617', otid=None, tool_returns=[ToolReturn(status='error', stdout=[], stderr=['Traceback (most recent call last):\\n  File \"/Users/shub/.letta/tool_execution_dir/tmp7_3pl3eg.py\", line 33, in <module>\\n    \"results\": google_search(query=query),\\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/Users/shub/.letta/tool_execution_dir/tmp7_3pl3eg.py\", line 29, in google_search\\n    raise \\'swag\\'\\nTypeError: exceptions must derive from BaseException\\n'])], group_id=None, sender_id=None, batch_item_id=None), Message(created_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', created_at=datetime.datetime(2025, 5, 30, 20, 11, 21, 926044, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2025, 5, 30, 20, 11, 21, 929073, tzinfo=datetime.timezone.utc), id='message-99542fcc-cdc1-475b-bcd1-35148bb39109', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', agent_id='agent-26dcd1b2-a970-46cc-9146-dca312cfd8b6', model='gpt-4o-mini', role=<MessageRole.user: 'user'>, content=[TextContent(type=<MessageContentType.text: 'text'>, text='{\\n  \"type\": \"heartbeat\",\\n  \"reason\": \"[This is an automated system message hidden from the user] Function call failed, returning control\",\\n  \"time\": \"2025-05-30 01:11:21 PM PDT-0700\"\\n}')], name=None, tool_calls=None, tool_call_id=None, step_id='step-a3be516a-7cee-4835-9500-3b73be039617', otid=None, tool_returns=[], group_id=None, sender_id=None, batch_item_id=None), Message(created_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', created_at=datetime.datetime(2025, 5, 30, 20, 11, 23, 119408, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2025, 5, 30, 20, 11, 23, 121811, tzinfo=datetime.timezone.utc), id='message-695fa997-bf36-4d3f-800a-a0d7c2555c48', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', agent_id='agent-26dcd1b2-a970-46cc-9146-dca312cfd8b6', model='gpt-4o-mini', role=<MessageRole.assistant: 'assistant'>, content=[TextContent(type=<MessageContentType.text: 'text'>, text='The search function failed. I need to let the user know that I’m having issues without causing concern.')], name=None, tool_calls=[ChatCompletionMessageToolCall(id='message-4cc7fcbc-ee2c-45bd-bffc-3085b51b85ce', function=Function(arguments='{\"message\": \"It looks like I ran into a little hiccup while trying to search for cheese. Let me try that again!\", \"request_heartbeat\": true}', name='send_message'), type='function')], tool_call_id='message-4cc7fcbc-ee2c-45bd-bffc-3085b51b85ce', step_id='step-cf269b94-e978-4119-b7b6-234ffadec4c9', otid=None, tool_returns=[], group_id=None, sender_id=None, batch_item_id=None), Message(created_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', last_updated_by_id='user-b45f128a-e3fa-4187-a407-f909cc633b16', created_at=datetime.datetime(2025, 5, 30, 20, 11, 23, 119471, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2025, 5, 30, 20, 11, 23, 121811, tzinfo=datetime.timezone.utc), id='message-4cc7fcbc-ee2c-45bd-bffc-3085b51b85ce', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', agent_id='agent-26dcd1b2-a970-46cc-9146-dca312cfd8b6', model='gpt-4o-mini', role=<MessageRole.tool: 'tool'>, content=[TextContent(type=<MessageContentType.text: 'text'>, text='{\\n  \"status\": \"OK\",\\n  \"message\": \"Sent message successfully.\",\\n  \"time\": \"2025-05-30 01:11:23 PM PDT-0700\"\\n}')], name='send_message', tool_calls=None, tool_call_id='message-4cc7fcbc-ee2c-45bd-bffc-3085b51b85ce', step_id='step-cf269b94-e978-4119-b7b6-234ffadec4c9', otid=None, tool_returns=[ToolReturn(status='success', stdout=None, stderr=None)], group_id=None, sender_id=None, batch_item_id=None)]",
          'parameter.llm_config':
            "model='gpt-4o-mini' model_endpoint_type='openai' model_endpoint='https://api.openai.com/v1' provider_name='openai' provider_category=<ProviderCategory.base: 'base'> model_wrapper=None context_window=32000 put_inner_thoughts_in_kwargs=True handle='openai/gpt-4o-mini' temperature=0.7 max_tokens=4096 enable_reasoner=False reasoning_effort=None max_reasoning_tokens=0",
          'parameter.total_tokens': '4272',
          'parameter.force': 'False',
        },
        Duration: '132910000',
        StatusCode: 'STATUS_CODE_OK',
        StatusMessage: '',
        'Events.Timestamp': [],
        'Events.Name': [],
        'Events.Attributes': [],
        'Links.TraceId': [],
        'Links.SpanId': [],
        'Links.TraceState': [],
        'Links.Attributes': [],
      },
      {
        Timestamp: '2025-05-30 20:11:20.574380000',
        TraceId: '45a9fc2eb4d278b6d530f5883373461e',
        SpanId: 'f7c50feb91902910',
        ParentSpanId: 'ae6a4fb37e6faffa',
        TraceState: '',
        SpanName: 'LettaAgent.step_stream',
        SpanKind: 'SPAN_KIND_INTERNAL',
        ServiceName: 'letta-server',
        ResourceAttributes: {
          'device.id': '244366141754099',
          'letta.version': '0.7.14',
          'telemetry.sdk.language': 'python',
          'telemetry.sdk.name': 'opentelemetry',
          'telemetry.sdk.version': '1.30.0',
          'service.name': 'letta-server',
        },
        ScopeName: 'letta.tracing',
        ScopeVersion: '',
        SpanAttributes: {
          'parameter.use_assistant_message': 'False',
          'parameter.request_start_timestamp_ns': '1748635880568389000',
          'parameter.input_messages':
            "[MessageCreate(role=<MessageRole.user: 'user'>, content='can you search google for cheese', name=None, otid='f1e3fa66-ea12-4b7c-b2d0-2d71b089d2f6', sender_id='placeholderId', batch_item_id=None, group_id=None)]",
          'parameter.max_steps': '10',
        },
        Duration: '65000',
        StatusCode: 'STATUS_CODE_OK',
        StatusMessage: '',
        'Events.Timestamp': [],
        'Events.Name': [],
        'Events.Attributes': [],
        'Links.TraceId': [],
        'Links.SpanId': [],
        'Links.TraceState': [],
        'Links.Attributes': [],
      },
      {
        Timestamp: '2025-05-30 20:11:21.828769000',
        TraceId: '45a9fc2eb4d278b6d530f5883373461e',
        SpanId: '9c375ad398e94c66',
        ParentSpanId: 'ae6a4fb37e6faffa',
        TraceState: '',
        SpanName: 'MessageManager.create_many_messages_async',
        SpanKind: 'SPAN_KIND_INTERNAL',
        ServiceName: 'letta-server',
        ResourceAttributes: {
          'telemetry.sdk.language': 'python',
          'telemetry.sdk.name': 'opentelemetry',
          'telemetry.sdk.version': '1.30.0',
          'service.name': 'letta-server',
          'device.id': '244366141754099',
          'letta.version': '0.7.14',
        },
        ScopeName: 'letta.tracing',
        ScopeVersion: '',
        SpanAttributes: {
          'parameter.pydantic_msgs':
            "[Message(created_by_id=None, last_updated_by_id=None, created_at=datetime.datetime(2025, 5, 30, 20, 11, 20, 703354, tzinfo=datetime.timezone.utc), updated_at=None, id='message-55cb948f-70f1-45cc-a700-2bb9eb2892a5', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', agent_id='agent-26dcd1b2-a970-46cc-9146-dca312cfd8b6', model=None, role=<MessageRole.user: 'user'>, content=[TextContent(type=<MessageContentType.text: 'text'>, text='can you search google for cheese')], name=None, tool_calls=None, tool_call_id=None, step_id=None, otid='f1e3fa66-ea12-4b7c-b2d0-2d71b089d2f6', tool_returns=None, group_id=None, sender_id='placeholderId', batch_item_id=None)]",
          'parameter.actor':
            "id='user-b45f128a-e3fa-4187-a407-f909cc633b16' organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9' name='Shubham Naik' created_at=datetime.datetime(2025, 5, 30, 12, 57, 49, 429202, tzinfo=datetime.timezone.utc) updated_at=datetime.datetime(2025, 5, 30, 5, 57, 49, 450824, tzinfo=datetime.timezone.utc) is_deleted=False",
        },
        Duration: '14134000',
        StatusCode: 'STATUS_CODE_OK',
        StatusMessage: '',
        'Events.Timestamp': [],
        'Events.Name': [],
        'Events.Attributes': [],
        'Links.TraceId': [],
        'Links.SpanId': [],
        'Links.TraceState': [],
        'Links.Attributes': [],
      },
      {
        Timestamp: '2025-05-30 20:11:21.926147000',
        TraceId: '45a9fc2eb4d278b6d530f5883373461e',
        SpanId: 'bc9f3aee7f493755',
        ParentSpanId: 'bc867815245f0006',
        TraceState: '',
        SpanName: 'MessageManager.create_many_messages_async',
        SpanKind: 'SPAN_KIND_INTERNAL',
        ServiceName: 'letta-server',
        ResourceAttributes: {
          'service.name': 'letta-server',
          'device.id': '244366141754099',
          'letta.version': '0.7.14',
          'telemetry.sdk.language': 'python',
          'telemetry.sdk.name': 'opentelemetry',
          'telemetry.sdk.version': '1.30.0',
        },
        ScopeName: 'letta.tracing',
        ScopeVersion: '',
        SpanAttributes: {
          'parameter.actor':
            "id='user-b45f128a-e3fa-4187-a407-f909cc633b16' organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9' name='Shubham Naik' created_at=datetime.datetime(2025, 5, 30, 12, 57, 49, 429202, tzinfo=datetime.timezone.utc) updated_at=datetime.datetime(2025, 5, 30, 5, 57, 49, 450824, tzinfo=datetime.timezone.utc) is_deleted=False",
          'parameter.pydantic_msgs':
            "[Message(created_by_id=None, last_updated_by_id=None, created_at=datetime.datetime(2025, 5, 30, 20, 11, 21, 925888, tzinfo=datetime.timezone.utc), updated_at=None, id='message-1d6905a2-38be-4fc0-80cc-19808f2bd2c0', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', agent_id='agent-26dcd1b2-a970-46cc-9146-dca312cfd8b6', model='gpt-4o-mini', role=<MessageRole.assistant: 'assistant'>, content=[TextContent(type=<MessageContentType.text: 'text'>, text='User has requested a Google search about cheese. I need to find relevant information and provide it in a concise manner.')], name=None, tool_calls=[ChatCompletionMessageToolCall(id='message-991ad085-546c-4d5a-aa59-c39e91bcc8a7', function=Function(arguments='{\"query\": \"cheese\", \"request_heartbeat\": true}', name='google_search'), type='function')], tool_call_id='message-991ad085-546c-4d5a-aa59-c39e91bcc8a7', step_id='step-a3be516a-7cee-4835-9500-3b73be039617', otid=None, tool_returns=None, group_id=None, sender_id=None, batch_item_id=None), Message(created_by_id=None, last_updated_by_id=None, created_at=datetime.datetime(2025, 5, 30, 20, 11, 21, 926003, tzinfo=datetime.timezone.utc), updated_at=None, id='message-991ad085-546c-4d5a-aa59-c39e91bcc8a7', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', agent_id='agent-26dcd1b2-a970-46cc-9146-dca312cfd8b6', model='gpt-4o-mini', role=<MessageRole.tool: 'tool'>, content=[TextContent(type=<MessageContentType.text: 'text'>, text='{\\n  \"status\": \"Failed\",\\n  \"message\": \"Error executing function google_search: TypeError: exceptions must derive from BaseException\",\\n  \"time\": \"2025-05-30 01:11:21 PM PDT-0700\"\\n}')], name='google_search', tool_calls=[], tool_call_id='message-991ad085-546c-4d5a-aa59-c39e91bcc8a7', step_id='step-a3be516a-7cee-4835-9500-3b73be039617', otid=None, tool_returns=[ToolReturn(status='error', stdout=[], stderr=['Traceback (most recent call last):\\n  File \"/Users/shub/.letta/tool_execution_dir/tmp7_3pl3eg.py\", line 33, in <module>\\n    \"results\": google_search(query=query),\\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/Users/shub/.letta/tool_execution_dir/tmp7_3pl3eg.py\", line 29, in google_search\\n    raise \\'swag\\'\\nTypeError: exceptions must derive from BaseException\\n'])], group_id=None, sender_id=None, batch_item_id=None), Message(created_by_id=None, last_updated_by_id=None, created_at=datetime.datetime(2025, 5, 30, 20, 11, 21, 926044, tzinfo=datetime.timezone.utc), updated_at=None, id='message-99542fcc-cdc1-475b-bcd1-35148bb39109', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', agent_id='agent-26dcd1b2-a970-46cc-9146-dca312cfd8b6', model='gpt-4o-mini', role=<MessageRole.user: 'user'>, content=[TextContent(type=<MessageContentType.text: 'text'>, text='{\\n  \"type\": \"heartbeat\",\\n  \"reason\": \"[This is an automated system message hidden from the user] Function call failed, returning control\",\\n  \"time\": \"2025-05-30 01:11:21 PM PDT-0700\"\\n}')], name=None, tool_calls=[], tool_call_id=None, step_id='step-a3be516a-7cee-4835-9500-3b73be039617', otid=None, tool_returns=None, group_id=None, sender_id=None, batch_item_id=None)]",
        },
        Duration: '10337000',
        StatusCode: 'STATUS_CODE_OK',
        StatusMessage: '',
        'Events.Timestamp': [],
        'Events.Name': [],
        'Events.Attributes': [],
        'Links.TraceId': [],
        'Links.SpanId': [],
        'Links.TraceState': [],
        'Links.Attributes': [],
      },
      {
        Timestamp: '2025-05-30 20:11:23.119549000',
        TraceId: '45a9fc2eb4d278b6d530f5883373461e',
        SpanId: '19a23068fc7d86c5',
        ParentSpanId: '65efb4a0ff921a88',
        TraceState: '',
        SpanName: 'MessageManager.create_many_messages_async',
        SpanKind: 'SPAN_KIND_INTERNAL',
        ServiceName: 'letta-server',
        ResourceAttributes: {
          'telemetry.sdk.name': 'opentelemetry',
          'telemetry.sdk.version': '1.30.0',
          'service.name': 'letta-server',
          'device.id': '244366141754099',
          'letta.version': '0.7.14',
          'telemetry.sdk.language': 'python',
        },
        ScopeName: 'letta.tracing',
        ScopeVersion: '',
        SpanAttributes: {
          'parameter.pydantic_msgs':
            "[Message(created_by_id=None, last_updated_by_id=None, created_at=datetime.datetime(2025, 5, 30, 20, 11, 23, 119408, tzinfo=datetime.timezone.utc), updated_at=None, id='message-695fa997-bf36-4d3f-800a-a0d7c2555c48', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', agent_id='agent-26dcd1b2-a970-46cc-9146-dca312cfd8b6', model='gpt-4o-mini', role=<MessageRole.assistant: 'assistant'>, content=[TextContent(type=<MessageContentType.text: 'text'>, text='The search function failed. I need to let the user know that I’m having issues without causing concern.')], name=None, tool_calls=[ChatCompletionMessageToolCall(id='message-4cc7fcbc-ee2c-45bd-bffc-3085b51b85ce', function=Function(arguments='{\"message\": \"It looks like I ran into a little hiccup while trying to search for cheese. Let me try that again!\", \"request_heartbeat\": true}', name='send_message'), type='function')], tool_call_id='message-4cc7fcbc-ee2c-45bd-bffc-3085b51b85ce', step_id='step-cf269b94-e978-4119-b7b6-234ffadec4c9', otid=None, tool_returns=None, group_id=None, sender_id=None, batch_item_id=None), Message(created_by_id=None, last_updated_by_id=None, created_at=datetime.datetime(2025, 5, 30, 20, 11, 23, 119471, tzinfo=datetime.timezone.utc), updated_at=None, id='message-4cc7fcbc-ee2c-45bd-bffc-3085b51b85ce', organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9', agent_id='agent-26dcd1b2-a970-46cc-9146-dca312cfd8b6', model='gpt-4o-mini', role=<MessageRole.tool: 'tool'>, content=[TextContent(type=<MessageContentType.text: 'text'>, text='{\\n  \"status\": \"OK\",\\n  \"message\": \"Sent message successfully.\",\\n  \"time\": \"2025-05-30 01:11:23 PM PDT-0700\"\\n}')], name='send_message', tool_calls=[], tool_call_id='message-4cc7fcbc-ee2c-45bd-bffc-3085b51b85ce', step_id='step-cf269b94-e978-4119-b7b6-234ffadec4c9', otid=None, tool_returns=[ToolReturn(status='success', stdout=None, stderr=None)], group_id=None, sender_id=None, batch_item_id=None)]",
          'parameter.actor':
            "id='user-b45f128a-e3fa-4187-a407-f909cc633b16' organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9' name='Shubham Naik' created_at=datetime.datetime(2025, 5, 30, 12, 57, 49, 429202, tzinfo=datetime.timezone.utc) updated_at=datetime.datetime(2025, 5, 30, 5, 57, 49, 450824, tzinfo=datetime.timezone.utc) is_deleted=False",
        },
        Duration: '11057000',
        StatusCode: 'STATUS_CODE_OK',
        StatusMessage: '',
        'Events.Timestamp': [],
        'Events.Name': [],
        'Events.Attributes': [],
        'Links.TraceId': [],
        'Links.SpanId': [],
        'Links.TraceState': [],
        'Links.Attributes': [],
      },
      {
        Timestamp: '2025-05-30 20:11:20.698752000',
        TraceId: '45a9fc2eb4d278b6d530f5883373461e',
        SpanId: '64fdfea428d93131',
        ParentSpanId: 'ae6a4fb37e6faffa',
        TraceState: '',
        SpanName: 'MessageManager.get_messages_by_ids_async',
        SpanKind: 'SPAN_KIND_INTERNAL',
        ServiceName: 'letta-server',
        ResourceAttributes: {
          'telemetry.sdk.language': 'python',
          'telemetry.sdk.name': 'opentelemetry',
          'telemetry.sdk.version': '1.30.0',
          'service.name': 'letta-server',
          'device.id': '244366141754099',
          'letta.version': '0.7.14',
        },
        ScopeName: 'letta.tracing',
        ScopeVersion: '',
        SpanAttributes: {
          'parameter.message_ids':
            "['message-ec9614fc-80b4-4e39-86e3-b5a7d1b555a8', 'message-90ca7ed1-d191-4243-afef-9159ba798da0', 'message-da5bb319-00b4-46a8-84be-378fe9f8f884', 'message-a3df1662-763c-4020-b31c-bf47d0c34984', 'message-9c79e0f3-9302-4188-8dcc-ffafccbcdd88', 'message-ec13ca08-cc87-4ae1-b784-e61e449ddf34', 'message-62ff240f-81cb-4957-ba63-b349a1d52b1d']",
          'parameter.actor':
            "id='user-b45f128a-e3fa-4187-a407-f909cc633b16' organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9' name='Shubham Naik' created_at=datetime.datetime(2025, 5, 30, 12, 57, 49, 429202, tzinfo=datetime.timezone.utc) updated_at=datetime.datetime(2025, 5, 30, 5, 57, 49, 450824, tzinfo=datetime.timezone.utc) is_deleted=False",
        },
        Duration: '4578000',
        StatusCode: 'STATUS_CODE_OK',
        StatusMessage: '',
        'Events.Timestamp': [],
        'Events.Name': [],
        'Events.Attributes': [],
        'Links.TraceId': [],
        'Links.SpanId': [],
        'Links.TraceState': [],
        'Links.Attributes': [],
      },
      {
        Timestamp: '2025-05-30 20:11:20.703858000',
        TraceId: '45a9fc2eb4d278b6d530f5883373461e',
        SpanId: 'd6464e50d3461cca',
        ParentSpanId: 'e03c19ee77ea5b68',
        TraceState: '',
        SpanName: 'MessageManager.size_async',
        SpanKind: 'SPAN_KIND_INTERNAL',
        ServiceName: 'letta-server',
        ResourceAttributes: {
          'telemetry.sdk.language': 'python',
          'telemetry.sdk.name': 'opentelemetry',
          'telemetry.sdk.version': '1.30.0',
          'service.name': 'letta-server',
          'device.id': '244366141754099',
          'letta.version': '0.7.14',
        },
        ScopeName: 'letta.tracing',
        ScopeVersion: '',
        SpanAttributes: {
          'parameter.actor':
            "id='user-b45f128a-e3fa-4187-a407-f909cc633b16' organization_id='org-eb507f0c-c897-493e-8c9a-d48e9c2d63a9' name='Shubham Naik' created_at=datetime.datetime(2025, 5, 30, 12, 57, 49, 429202, tzinfo=datetime.timezone.utc) updated_at=datetime.datetime(2025, 5, 30, 5, 57, 49, 450824, tzinfo=datetime.timezone.utc) is_deleted=False",
          'parameter.role': 'None',
          'parameter.agent_id': 'agent-26dcd1b2-a970-46cc-9146-dca312cfd8b6',
        },
        Duration: '6363000',
        StatusCode: 'STATUS_CODE_OK',
        StatusMessage: '',
        'Events.Timestamp': [],
        'Events.Name': [],
        'Events.Attributes': [],
        'Links.TraceId': [],
        'Links.SpanId': [],
        'Links.TraceState': [],
        'Links.Attributes': [],
      },
    ],
  },
};
