---
title: 'Gemini'
---


## Configuring with Gemini
<Accordion icon="square-terminal" title="CLI (pypi only)">
To configure your LLM model, modify the `[model]` section of your `~/.letta/config` file: 
```yaml ~/.letta/config
[model]
model_endpoint_type = anthropic 
model = claude-3-opus-20240229
model_endpoint = https://api.anthropic.com/v1
context_window = 200000
```
</Accordion>
<Accordion icon="python" title="Python SDK">
You can override the default LLM config (specified in `~/.letta/config`) by providing a new `LLMConfig` object to the `set_default_llm_config` method. 
```python
from memgpt import LLMConfig


# provide full config (llm config)
client.set_default_llm_config(
    LLMConfig(
        model="claude-3-opus-20240229",
        model_endpoint_type="anthropic",
        model_endpoint="https://api.anthropic.com/v1",
        context_window=200000
    )
)
```
</Accordion>

