---
title: 'Google AI (Gemini)'
---

<Tip>To enable Google AI models with Letta, set `GEMINI_API_KEY` in your environment variables. </Tip>

You can use Letta with Google AI if you have a Google API account and API key. Once you have set your `GEMINI_API_KEY` in your enviornment variables, you can select what model and configure the context window size.

## Enabling Google AI as a provider 
To enable the Google AI provider, you must set the `GEMINI_API_KEY` environment variable. When this is set, Letta will use available LLM models running on Google AI. 

<Accordion icon="square-terminal" title="CLI (pypi only)">

### Using `letta run` and `letta server` with Google AI  
To chat with an agent, run:
```bash
export GEMINI_API_KEY="..."
letta run
```
This will prompt you to select a model:
```bash
? Select LLM model: (Use arrow keys)
 » letta-free [type=openai] [ip=https://inference.memgpt.ai]
   gemini-1.0-pro-latest [type=google_ai] [ip=https://generativelanguage.googleapis.com]
   gemini-1.0-pro [type=google_ai] [ip=https://generativelanguage.googleapis.com]
   gemini-pro [type=google_ai] [ip=https://generativelanguage.googleapis.com]
   gemini-1.0-pro-001 [type=google_ai] [ip=https://generativelanguage.googleapis.com]
   gemini-1.0-pro-vision-latest [type=google_ai] [ip=https://generativelanguage.googleapis.com]
   gemini-pro-vision [type=google_ai] [ip=https://generativelanguage.googleapis.com]
   gemini-1.5-pro-latest [type=google_ai] [ip=https://generativelanguage.googleapis.com]
   gemini-1.5-pro-001 [type=google_ai] [ip=https://generativelanguage.googleapis.com]
   gemini-1.5-pro-002 [type=google_ai] [ip=https://generativelanguage.googleapis.com]
   gemini-1.5-pro [type=google_ai] [ip=https://generativelanguage.googleapis.com]
   gemini-1.5-pro-exp-0801 [type=google_ai] [ip=https://generativelanguage.googleapis.com]
   gemini-1.5-pro-exp-0827 [type=google_ai] [ip=https://generativelanguage.googleapis.com]
```
as we as an embedding model:
```
? Select embedding model: (Use arrow keys)
 » letta-free [type=hugging-face] [ip=https://embeddings.memgpt.ai]
   embedding-001 [type=google_ai] [ip=https://generativelanguage.googleapis.com]
   text-embedding-004 [type=google_ai] [ip=https://generativelanguage.googleapis.com]
```
To run the Letta server, run:
```bash
export GEMINI_API_KEY="..."
letta server
```
To select the model used by the server, use the dropdown in the ADE or specify a `LLMConfig` object in the Python SDK.
</Accordion>
<Accordion icon="docker" title="Docker Compose">
### Using the `docker compose` server with Google AI
The `compose.yaml` file will read your local enviornment variables and pass them to the Letta server running in the container. To use Google AI with the Letta server, set the `GEMINI_API_KEY` enviornment variable and run the server with `docker compose up`:
```bash
export GEMINI_API_KEY="..."
docker compose up 
```
</Accordion>





