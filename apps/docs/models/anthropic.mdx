---
title: 'Anthropic'
---

<Tip>To enable Anthropic models with Letta, set `ANTHROPIC_API_KEY` in your environment variables. </Tip>

Currently, only there are no supported embedding models for Anthropic. You will need to use a seperate provider (e.g. OpenAI) or the Letta embeddings endpoint (`letta-free`) for embeddings.

## Configuring with Anthropic
<Accordion icon="square-terminal" title="CLI (pypi only)">
To configure your LLM model, modify the `[model]` section of your `~/.letta/config` file: 
```yaml ~/.letta/config
[model]
model_endpoint_type = anthropic 
model = claude-3-opus-20240229
model_endpoint = https://api.anthropic.com/v1
context_window = 200000
```
</Accordion>
<Accordion icon="python" title="Python SDK">
You can override the default LLM config (specified in `~/.letta/config`) by providing a new `LLMConfig` object to the `set_default_llm_config` method. 
```python
from memgpt import LLMConfig


# provide full config (llm config)
client.set_default_llm_config(
    LLMConfig(
        model="claude-3-opus-20240229",
        model_endpoint_type="anthropic",
        model_endpoint="https://api.anthropic.com/v1",
        context_window=200000
    )
)
```
</Accordion>

