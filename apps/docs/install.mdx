---
title: 'Letta Server'
description: 'Install and setup Letta to run the server & ADE'
icon: "server"
iconType: "solid"
---

## Run Letta with `pip`
<iframe
  width="560"
  height="315"
  src="https://www.youtube.com/embed/EOkpFDBNyEw"
  title="Install Letta with pip"
  frameborder="0"
  allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
  allowfullscreen
></iframe>

<Steps>
  <Step title="Install using PIP">
    To install Letta, run:
    ```
    pip install letta
    ```
  </Step>
  <Step title="Configure model providers">
    Set environment variables to enable model providers, e.g. OpenAI: 
    ```bash 

    # To use OpenAI
    export OPENAI_API_KEY=...

    # To use Anthropic 
    export ANTHROPIC_API_KEY=...

    # To use with Ollama
    export OLLAMA_BASE_URL=...

    # To use with Google AI
    export GEMINI_API_KEY=...

    # To use with Azure
    export AZURE_API_KEY=...
    export AZURE_BASE_URL=...

    # To use with vLLM 
    export VLLM_API_BASE=...
    ```
  </Step>
  <Step title="Run the Letta server">
    To run the Letta server, run:
    ```sh
    letta server [--debug]
    ```
    You can now access the ADE (in your browser) and REST API server at `http://localhost:8283`.
  </Step>
</Steps>



## Run Letta with Docker
<iframe
  width="560"
  height="315"
  src="https://www.youtube.com/embed/CpBfjoaULkI"
  title="Setup Letta with docker"
  frameborder="0"
  allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
  allowfullscreen
></iframe>

<Steps>
  <Step title="Download the docker container">
    To run the docker container, first clone the reposity for pull the contianer. 
    ```sh
    git clone https://github.com/cpacker/MemGPT
    ```
  </Step>
  <Step title="Set environment variables">
    Either set the environment variables in your shell on in a `.env` file. 
  <CodeGroup>
    ```bash .env file
    # To use OpenAI
    OPENAI_API_KEY=...

    # To use Anthropic 
    ANTHROPIC_API_KEY=...

    # To use with Ollama
    OLLAMA_BASE_URL=...

    # To use with Google AI
    GEMINI_API_KEY=...

    # To use with Azure
    AZURE_API_KEY=...
    AZURE_BASE_URL=...

    # To use with vLLM 
    VLLM_API_BASE=...
    ```
    ```bash shell
    # To use OpenAI
    export OPENAI_API_KEY=...

    # To use Anthropic 
    export ANTHROPIC_API_KEY=...

    # To use with Ollama
    export OLLAMA_BASE_URL=...

    # To use with Google AI
    export GEMINI_API_KEY=...

    # To use with Azure
    export AZURE_API_KEY=...
    export AZURE_BASE_URL=...

    # To use with vLLM 
    export VLLM_API_BASE=...
    ```
  </CodeGroup>
  </Step>
  <Step title="(Optional) View and modify the compose YAML file">
    You can view and modify the `compose.yaml` file, for example, if you would like to change the default ports or `pgvector` version.
  </Step>
  <Step title="Run Docker Compose">
    To start the Letta server, we use [Docker Compose](https://docs.docker.com/compose/), which runs both the Letta container and the database container:
    ```sh
    docker compose up 
    ```
    You can now access the ADE (in your browser) and REST API server at `http://localhost:8083`.
  </Step>
</Steps>
