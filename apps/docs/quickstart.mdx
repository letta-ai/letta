---
title: 'Developer quickstart'
sidebarTitle: 'Quickstart'
description: 'Creating your first agent in Letta'
icon: "bolt"
iconType: "solid"
---

<Tip>
**Letta agents** live inside the **Letta server**, which persists them to a database. You can interact with the Letta agents inside your Letta server via the [REST API](https://docs.letta.com/api-reference) + Python / Typescript SDKs, and the [Agent Development Environment](https://app.letta.com) (a graphical interface).
</Tip>

## Install Letta and run the server
<Note>
The recommended way to use Letta is to run use Docker.
To install Docker, see [Docker's installation guide](https://docs.docker.com/get-docker/).
For issues with installing Docker, see [Docker's troubleshooting guide](https://docs.docker.com/desktop/troubleshoot-and-support/troubleshoot/).
You can also install Letta using `pip` (see instructions [here](/server/pip)).
</Note>

<AccordionGroup>
  <Accordion icon="docker" title="Installing with Docker" defaultOpen="true">
  The Letta server can be connected to various LLM API backends (see our [Docker guide](/server/docker) for more details). In this example, we'll use an OpenAI API key:
```sh
# replace `~/.letta/.persist/pgdata` with wherever you want to store your agent data
docker run \
  -v ~/.letta/.persist/pgdata:/var/lib/postgresql/data \
  -p 8283:8283 \
  -e OPENAI_API_KEY="your_openai_api_key" \
  letta/letta:latest
```

If you have many different LLM API keys, you can also set up a `.env` file instead and pass that to `docker run`:
```sh
# using a .env file instead of passing environment variables
docker run \
  -v ~/.letta/.persist/pgdata:/var/lib/postgresql/data \
  -p 8283:8283 \
  --env-file .env \
  letta/letta:latest
```

Once the Letta server is running, you can access it via port `8283` (e.g. sending REST API requests to `http://localhost:8283/v1`). You can also connect your server to the Letta ADE to access and manage your agents in a web interface.
  </Accordion>
  <Accordion icon="file-code" title="Installing from source (advanced)">
    First, install Poetry using the official instructions [here](https://python-poetry.org/docs/#installation).
    Then clone the open source repository:
    ```sh
    git clone https://github.com/letta-ai/letta.git
    ```

    Navigate to the letta directory and install the `letta` package using Poetry:
    ```sh
    cd letta
    poetry install --all-extras
    poetry shell
    ```

    Now when you want to use `letta`, make sure you first activate the poetry environment using `poetry shell`:
    ```sh
    poetry shell
    ```

    Alternatively, you can use poetry run (which will activate the poetry environment for the letta run command only):
    ```sh
    poetry run letta run
    ```
  </Accordion>
</AccordionGroup>


## Access the [Letta ADE](https://app.letta.com) (Agent Development Environment)

<Note>
The Letta ADE is a graphical user interface for creating, deploying, interacting and observing with your Letta agents.
You can access the ADE at [https://app.letta.com](https://app.letta.com).
</Note>

The ADE can connect to self-hosted Letta servers (e.g. a Letta server running on your laptop), as well as the Letta Cloud service. When connected to a self-hosted / private server, the ADE uses the Letta REST API to communicate with your server.

If you're running a Letta server to power an end-user application (such as a customer support chatbot), you can use the ADE to test, debug, and observe the agents in your server. You can also use the ADE as a general chat interface to interacting with your Letta agents.
<img className="block w-300 dark:hidden" src="https://raw.githubusercontent.com/letta-ai/letta/refs/heads/main/assets/example_ade_screenshot_light.png" />
<img className="hidden w-300 dark:block" src="https://raw.githubusercontent.com/letta-ai/letta/refs/heads/main/assets/example_ade_screenshot.png" />

To connect the ADE with your local Letta server, simply navigate to [https://app.letta.com](https://app.letta.com) and you will see "Local server" as an option in the left panel (if your server is running):
<img className="block w-300 dark:hidden" src="https://raw.githubusercontent.com/letta-ai/letta/refs/heads/main/assets/example_ade_screenshot_agents_light.png" />
<img className="hidden w-300 dark:block" src="https://raw.githubusercontent.com/letta-ai/letta/refs/heads/main/assets/example_ade_screenshot_agents.png" />

For information on how to configure the ADE with a Letta server running on a remote server, refer to [our guide on remote servers](/agent-development-environment/connect).

## Creating an agent with the Letta API
Let's create an agent via the Letta API, which we can then view in the ADE (you can also use the ADE to create agents).

To create an agent we'll send a POST request to the Letta server ([API docs](https://docs.letta.com/api-reference/agents/create-agent)):
<CodeGroup>
```sh REST API (request)
curl --request POST \
  --url http://localhost:8283/v1/agents/ \
  --header 'Content-Type: application/json' \
  --data '{
  "memory_blocks": [
    {
      "label": "human",
      "value": "The human'\''s name is Bob the Builder"
    },
    {
      "label": "persona",
      "value": "My name is Sam, the all-knowing sentient AI."
    }
  ],
  "llm_config": {
    "model": "gpt-4o-mini",
    "model_endpoint_type": "openai",
    "model_endpoint": "https://api.openai.com/v1",
    "context_window": 16000
  },
  "embedding_config": {
    "embedding_endpoint_type": "openai",
    "embedding_endpoint": "https://api.openai.com/v1",
    "embedding_model": "text-embedding-3-small",
    "embedding_dim": 8191
  },
  "tools": [
    "send_message",
    "core_memory_append",
    "core_memory_replace",
    "archival_memory_search",
    "archival_memory_insert",
    "conversation_search"
  ]
}'
```
</CodeGroup>
The response will include information about the agent:
<CodeGroup>
```sh REST API (response)
{"description":null,"metadata_":null,"id":"agent-...
```
</CodeGroup>

## Send a message to the agent with the Letta API

<Tip>
The Letta API supports streaming both agent *steps* and streaming *tokens*.
For more information on streaming, see [our guide on streaming](/agents/streaming).
</Tip>

Let's try sending a message to the new agent! We'll use the agent `id` (starting with `agent-...`) that we received in the response above in place of `agent_id` ([route documentation](https://docs.letta.com/api-reference/agents/send-message)):
<CodeGroup>
```sh REST API (request)
curl --request POST \
  --url http://localhost:8283/v1/agents/agent-a6984b2f-9ad6-43a9-b447-6d32d19a248a/messages \
  --header 'Content-Type: application/json' \
  --data '{
  "messages": [
    {
      "role": "user",
      "text": "hows it going????"
    }
  ]
}'
```
</CodeGroup>

The response contains the agent's full response to the message, which includes inner thoughts / chain-of-thought, tool calls, tool responses, and agent messages (directed at the user):
<CodeGroup>
```sh REST API (response)
{
  "messages": [
    {
      "id": "message-29d8d17e-7c50-4289-8d0e-2bab988aa01e",
      "date": "2024-12-12T17:05:56+00:00",
      "message_type": "internal_monologue",
      "internal_monologue": "Feeling energized to chat! Ready to connect and share some positive vibes with Bob the Builder."
    },
    {
      "id": "message-29d8d17e-7c50-4289-8d0e-2bab988aa01e",
      "date": "2024-12-12T17:05:56+00:00",
      "message_type": "function_call",
      "function_call": {
        "name": "send_message",
        "arguments": "{\n  \"message\": \"Hey! I'm feeling great, thanks for asking! How about you? Whatâ€™s on your mind?\"\n}",
        "function_call_id": "call_Qk0JZjoVnL4fivzQlVmJv56E"
      }
    },
    {
      "id": "message-c4295e4c-56ae-4f77-93bf-6a8c3454205b",
      "date": "2024-12-12T17:05:56+00:00",
      "message_type": "function_return",
      "function_return": "None",
      "status": "success",
      "function_call_id": "call_Qk0JZjoVnL4fivzQlVmJv56E",
    }
  ],
  "usage": {
    "completion_tokens": 56,
    "prompt_tokens": 2030,
    "total_tokens": 2086,
    "step_count": 1
  }
}
```
</CodeGroup>

## Viewing the agent in the ADE
We've created and messaged our first stateful agent. This agent exists in our Letta server, which means we can view it in the ADE (and continue the conversation there!).

If we open the ADE and click on "Agents", we should see our agent, as well as the message that we sent to it:
<img className="block w-300 dark:hidden" src="/images/ade_screenshot_chat_light.png" />
<img className="hidden w-300 dark:block" src="/images/ade_screenshot_chat.png" />

## Next steps

Congratulations! ðŸŽ‰ You just created and messaged your first stateful agent with Letta, using both the Letta ADE, API, and Python/Typescript SDKs.

Now that you've succesfully created a basic agent with Letta, you're ready to start building more complex agents and AI applications.

<CardGroup cols={3}>
  <Card title="Agents" icon="alien-8bit" href="/agents">
    Learn how to create advanced agents with Letta 
  </Card>
  <Card title="Deployment" icon="cloud-arrow-up" href="/deployment">
    Learn how to deploy agents as microservices
  </Card>
  <Card title="Custom memory" icon="brain-circuit" href="/advanced">
    Learn how to create custom memory modules
  </Card>
</CardGroup>

