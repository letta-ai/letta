---
sidebarTitle: 'Key concepts'
title: 'Key concepts'
description: 'Learn about the key concept in Letta'
icon: "cubes"
iconType: "solid"
---

<Tip>Letta was created by the same team that created MemGPT ([read more here]()), so many of the ideas in Letta are rooted in the MemGPT research paper.</Tip>


## LLM agents
Agents are LLM processes which can: 

1. Have internal state (i.e. memory)

2. Can take actions to modify their state

3. Run autonomously

Agents have existed as a concept in Reinforcement Learning for a long time. In Letta, LLM tool calling is used to both allow agents to run autonomously (by having the LLM determine whether to continue executing) as well as to edit state (by leveraging LLM tool calling.)
Letta uses a DB backend to manage the internal state of the agent, represented in the `AgentState` object. 


## Self-editing memory
The MemGPT paper introduced the idea of implementing self-editing memory in LLMs. The basic idea is to use LLM tools to allow an agent to both edit its own context window ("core memory"), as well as edit external storage (i.e. "archival memory").

## Persistence ("statefulness")
In Letta, all state is *persisted* by default. This means that each time the LLM is run, the state of the agent such as its memories, message history, and tools are all persisted to a DB backend. 

Because all state is persisted, you can always re-load agents, tools, sources, etc. at a later point in time. 
You can also load the same agent accross multiple machines or services, as long as they can can connect to the same DB backend. 


## Agent microservices ("agents-as-a-service")
Letta follows the model of treating agents as individual services. That is, you interact with agents through a REST API: 
```
POST /agents/{agent_id}/messages
```
Since agents are designed to be services, they can be *deployed* and connected to external applications. 

For example, you want to create a personalizated chatbot, you can create an agent per-user, where each agent has its own custom memory about the individual user. 


## Stateful vs stateless APIs
`ChatCompletitions` is the standard for interacting with LLMs as a service. Since it is a stateless API (no notion of sessions or identify accross requests, and no state management on the server-side), client-side applications must manage things like agent memory, user personalization, and message history, and translate this state back into the `ChatCompletitions` API format. Letta's APIs are designed to be *stateful*, so that this state management is done on the server, not the client. 


